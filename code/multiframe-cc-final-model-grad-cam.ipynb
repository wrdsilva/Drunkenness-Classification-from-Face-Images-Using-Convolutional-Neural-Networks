{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c701356",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-23T13:15:54.778505Z",
     "iopub.status.busy": "2023-05-23T13:15:54.777543Z",
     "iopub.status.idle": "2023-05-23T13:27:08.488878Z",
     "shell.execute_reply": "2023-05-23T13:27:08.487722Z"
    },
    "papermill": {
     "duration": 673.719165,
     "end_time": "2023-05-23T13:27:08.492536",
     "exception": false,
     "start_time": "2023-05-23T13:15:54.773371",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Defining random seeds to enable reproducibility\n",
    "from numpy.random import seed\n",
    "seed(1)\n",
    "\n",
    "import tensorflow as tf\n",
    "tf.random.set_seed(1)\n",
    "\n",
    "import random\n",
    "random.seed(1)\n",
    "\n",
    "import cv2\n",
    "import pickle\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "from tf_explain.core.grad_cam import GradCAM\n",
    "from tensorflow.python.client import device_lib\n",
    "from tensorflow.keras.models import load_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "print(device_lib.list_local_devices())\n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n",
    "\n",
    "\n",
    "def load_dataset():\n",
    "    \"\"\"\n",
    "    Loads the datasets encoded in .pkl files and returns its decoded form.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    list\n",
    "        A list of n-dimensional arrays representing the subjects samples that will be used to \\\\\n",
    "        train the drunkenness classification model.\n",
    "    ndarray\n",
    "        A n-dimensional array representing the samples labels.\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"Loading Sober-Drunk Face Dataset, from Patras University\")\n",
    "    \n",
    "    # Defining the sample and label sets filenames\n",
    "    sets = [\n",
    "        \"Insert the x_imbalanced.pkl file path here\",\n",
    "        \"Insert the y_imbalanced.pkl file path here\"   \n",
    "    ]\n",
    "    \n",
    "    # Defining an empty list for storing the decoded dataset\n",
    "    loaded_datasets = []\n",
    " \n",
    "    # Iterating over the dataset files\n",
    "    for set_ in sets:\n",
    "        # Opening the .pkl file in read mode\n",
    "        with open(set_, 'rb') as file:\n",
    "            # Appending the decoded dataset to the dataset list\n",
    "            loaded_datasets.append(pickle.load(file))\n",
    "    \n",
    "    # Unpacking the dataset list into individual subsets\n",
    "    x, y = loaded_datasets\n",
    "    \n",
    "    # Converting the label list to the n-dimensional array format\n",
    "    y_arr= np.array(y)\n",
    "    \n",
    "    # Printing the dataset length for sanity check\n",
    "    print(\"\\nSamples total: {0}\".format(len(x)))\n",
    "    \n",
    "    # Slicing the frame sequences of each subject for selecting the\n",
    "    # frames sampled at each 5 Hz\n",
    "    x = x[::5]\n",
    "    y_arr = y_arr[::5]\n",
    "    \n",
    "    # Printing the dataset length after slicing for sanity check\n",
    "    print(\"\\nSamples total after slicing: {0}\".format(len(x)))\n",
    "    \n",
    "    # Returning the samples set and its respective labels\n",
    "    return x, y_arr\n",
    "\n",
    "\n",
    "def min_max_norm(dataset):\n",
    "    \"\"\"\n",
    "    Normalizes the keyframes according to the minimum-maximum norm, \\\\\n",
    "    such that pixel values ranges from 0 to 1.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    dataset : list\n",
    "        A list of n-dimensional arrays representing the subjects keyframes.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    ndarray\n",
    "        A n-dimensional array representing keyframes with pixel values ranging from 0 to 1.\n",
    "    \"\"\"\n",
    "\n",
    "    # Converting the dataset type from list to n-dimensional array\n",
    "    dataset = np.asarray(dataset, dtype=\"int16\")\n",
    "\n",
    "    # Finding the keyframes minimum and maximum values\n",
    "    x_min = dataset.min(axis=(1, 2), keepdims=True)\n",
    "    x_max = dataset.max(axis=(1, 2), keepdims=True)\n",
    "\n",
    "    # Applying the minimum-maximum norm to each keyframe\n",
    "    norm_dataset = (dataset - x_min) / (x_max - x_min)\n",
    "\n",
    "    # Printing the minimum and maximum values from a given sample for sanity check\n",
    "    print(\"\\nMinMax normalization\")\n",
    "    print(\"dataset shape: \", norm_dataset.shape)\n",
    "    print(\"min: \", norm_dataset[0].min())\n",
    "    print(\"max: \", norm_dataset[0].max())\n",
    "\n",
    "    # Returning the normalized dataset\n",
    "    return norm_dataset\n",
    "\n",
    "\n",
    "def visualize_gradcam(cam, filename, operation):\n",
    "    \"\"\"\n",
    "    Displays the class activation mapping for a given test set sample.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    cam : ndarray\n",
    "        A n-dimensional array representing the class activation map.\n",
    "    filename : str\n",
    "        A string indicating the filename to save the plot.\n",
    "    operation : str\n",
    "        A string indicating the operation result to be displayed.\n",
    "    \"\"\"\n",
    "\n",
    "    # Creating a new figure\n",
    "    plt.figure()\n",
    "\n",
    "    # Getting the figure current axis\n",
    "    ax = plt.gca()\n",
    "    \n",
    "    # Displaying the class activation mapping\n",
    "    im = ax.imshow(cam, cmap='turbo', interpolation='lanczos')\n",
    "    \n",
    "    # Hidding the axis ticks\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    \n",
    "    # Defining a colorbar to interpret the class activations relevance\n",
    "    divider = make_axes_locatable(ax)\n",
    "    cax = divider.append_axes(\"right\", size=\"5%\", pad=0.05)\n",
    "    plt.colorbar(im, cax=cax)\n",
    "    \n",
    "    # Saving the given sample class activation mapping\n",
    "    plt.savefig(\"{0}_{1}.pdf\".format(filename, operation), dpi=600, bbox_inches='tight', pad_inches=0.001)\n",
    "    \n",
    "    # Showing the given sample class activation mapping\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def gradcam_frame_comparison():\n",
    "     \"\"\"\n",
    "    Performs the Gradient-weighted Class Activation Mapping visualization technique \\\\\n",
    "    for the frame sequence of a subject.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Defining the layer whose gradients will be used to highlight the predicted class \n",
    "    # discriminating features\n",
    "    LAYER_NAME = 'block5_conv3'\n",
    "    \n",
    "    # Loading the final drunkenness classification model\n",
    "    model = load_model('sober-drunk-cc_vgg16_final-model-ft_data_aug_tts_70-30_L2_405e.h5')\n",
    "    \n",
    "    # Printing the final model summary\n",
    "    model.summary()\n",
    "    \n",
    "    # Loading the Sober-Drunk Dataset samples\n",
    "    x, y = load_dataset()\n",
    "\n",
    "    # Selecting samples from the subjects 37, 38, 39, 40 and 41\n",
    "    x, y = x[-200:], y[-200:]\n",
    "\n",
    "    # Applying the min-max normalization\n",
    "    x = min_max_norm(x)\n",
    "\n",
    "    # Defining the filenames of each sample that will be analized\n",
    "    subjects = ['37_vassilisA_1_f_M_54_90',\n",
    "                '37_vassilisA_2_f_M_54_90',\n",
    "                '37_vassilisA_3_f_M_54_90',\n",
    "                '37_vassilisA_4_f_M_54_90',\n",
    "                '38_christos_1_f_M_33_76',\n",
    "                '38_christos_2_f_M_33_76',\n",
    "                '38_christos_3_f_M_33_76',\n",
    "                '38_christos_4_f_M_33_76',\n",
    "                '39_anna_1_f_F_46_59',\n",
    "                '39_anna_2_f_F_46_59',\n",
    "                '39_anna_3_f_F_46_59',\n",
    "                '39_anna_4_f_F_46_59',\n",
    "                '40_spiliop_1_f_M_43_74',\n",
    "                '40_spiliop_2_f_M_43_74',\n",
    "                '40_spiliop_3_f_M_43_74',\n",
    "                '40_spiliop_4_f_M_43_74',\n",
    "                '41_kalp_1_f_M_62_95',\n",
    "                '41_kalp_2_f_M_62_95',\n",
    "                '41_kalp_3_f_M_62_95',\n",
    "                '41_kalp_4_f_M_62_95']\n",
    "\n",
    "    # Defining a list of indexes for the frame sequence\n",
    "    frame_idx = 0\n",
    "    frame_list = range(0,50,5)\n",
    "    \n",
    "    # Defining the index of subject 38 filename\n",
    "    subject_idx = 4\n",
    "\n",
    "    # Iterating over the subject 38 samples\n",
    "    for sample in x[40:80]:\n",
    "        # Reshaping the input image format\n",
    "        input_img = np.expand_dims(sample, axis=0)        \n",
    "        data = (input_img, None)\n",
    "\n",
    "        print(\"Subject {0}, frame {1}\".format(subjects[subject_idx], frame_list[frame_idx]))\n",
    "\n",
    "        # Instantiating the Grad-CAM explainer object\n",
    "        explainer = GradCAM()\n",
    "\n",
    "        # Running the Grad-CAM explainer\n",
    "        cam = explainer.explain(data, model, class_index=-1, colormap=cv2.COLORMAP_TURBO, image_weight=0.0)\n",
    "\n",
    "        # Displaying the raw class activation map\n",
    "        visualize_gradcam(cam, \"{0}_frame-{1}\".format(subjects[subject_idx], frame_list[frame_idx]), 'turbo', 'cam')\n",
    "\n",
    "        # Normalizing the input image\n",
    "        input_img = sample \n",
    "        input_img = cv2.normalize(input_img,  np.zeros((128, 160)), 0, 255, cv2.NORM_MINMAX, dtype=cv2.CV_8U)\n",
    "\n",
    "        # Defining the transparency weights\n",
    "        alpha = 0.5\n",
    "        beta = 1 - alpha\n",
    "        gamma = 0\n",
    "        \n",
    "        # Superimposing the class activation map over the input image\n",
    "        overlayed_img = cv2.addWeighted(input_img, alpha, cam, beta, gamma)\n",
    "\n",
    "        # Displaying the overlaid class activation mapping\n",
    "        visualize_gradcam(overlayed_img, \"{0}_frame-{1}\".format(subjects[subject_idx], frame_list[frame_idx]), 'turbo', 'grad-cam_blending')\n",
    "\n",
    "        # Increasing the frame index \n",
    "        frame_idx += 1\n",
    "\n",
    "        # Checking if the frame index is equal or higher than the number\n",
    "        # of frames in the frame sequence\n",
    "        if frame_idx >= 10:\n",
    "            # Resetting the frame index for the next sequence\n",
    "            frame_idx = 0\n",
    "            # Increasing the subject index\n",
    "            subject_idx += 1\n",
    "\n",
    "\n",
    "def gradcam_subject_analysis():\n",
    "    \"\"\"\n",
    "    Performs the Gradient-weighted Class Activation Mapping visualization technique \\\\\n",
    "    for the first frame of each subject.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Defining the layer whose gradients will be used to highlight the predicted class \n",
    "    # discriminating features\n",
    "    LAYER_NAME = 'block5_conv3'\n",
    "    \n",
    "    # Loading the final drunkenness classification model\n",
    "    model = load_model('sober-drunk-cc_vgg16_final-model-ft_data_aug_tts_70-30_L2_405e.h5')\n",
    "    \n",
    "    # Printing the final model summary\n",
    "    model.summary()\n",
    "    \n",
    "    # Loading the Sober-Drunk Dataset samples\n",
    "    x, y = load_dataset()\n",
    "\n",
    "    # Selecting samples from the subjects 37, 38, 39, 40 and 41\n",
    "    x, y = x[-200:], y[-200:]\n",
    "\n",
    "    # Applying the min-max normalization\n",
    "    x = min_max_norm(x)   \n",
    "    \n",
    "    # Defining the filenames of each sample that will be analized\n",
    "    subjects = ['37_vassilisA_1_f_M_54_90',\n",
    "                '37_vassilisA_2_f_M_54_90',\n",
    "                '37_vassilisA_3_f_M_54_90',\n",
    "                '37_vassilisA_4_f_M_54_90',\n",
    "                '38_christos_1_f_M_33_76',\n",
    "                '38_christos_2_f_M_33_76',\n",
    "                '38_christos_3_f_M_33_76',\n",
    "                '38_christos_4_f_M_33_76',\n",
    "                '39_anna_1_f_F_46_59',\n",
    "                '39_anna_2_f_F_46_59',\n",
    "                '39_anna_3_f_F_46_59',\n",
    "                '39_anna_4_f_F_46_59',\n",
    "                '40_spiliop_1_f_M_43_74',\n",
    "                '40_spiliop_2_f_M_43_74',\n",
    "                '40_spiliop_3_f_M_43_74',\n",
    "                '40_spiliop_4_f_M_43_74',\n",
    "                '41_kalp_1_f_M_62_95',\n",
    "                '41_kalp_2_f_M_62_95',\n",
    "                '41_kalp_3_f_M_62_95',\n",
    "                '41_kalp_4_f_M_62_95']\n",
    "    \n",
    "    # Selecting the 1st frame of each frame sequence\n",
    "    subject_samples = x[::10]\n",
    "    \n",
    "    # Iterating over the subject samples\n",
    "    for i in range(len(subject_samples)):\n",
    "        # Reshaping the input image format\n",
    "        input_img = np.expand_dims(subject_samples[i], axis=0)        \n",
    "        data = (input_img, None)\n",
    "        \n",
    "        print(\"Subject {0}\".format(subjects[i]))\n",
    "        \n",
    "        # Instantiating the Grad-CAM explainer object\n",
    "        explainer = GradCAM()\n",
    "        \n",
    "        # Running the Grad-CAM explainer\n",
    "        cam = explainer.explain(data, model, class_index=-1, colormap=cv2.COLORMAP_TURBO, image_weight=0.0)\n",
    "        \n",
    "        # Displaying the raw class activation map\n",
    "        visualize_gradcam(cam, subjects[i], 'turbo', 'cam')\n",
    "        \n",
    "        # Normalizing the input image\n",
    "        input_img = subject_samples[i] \n",
    "        input_img = cv2.normalize(input_img,  np.zeros((128, 160)), 0, 255, cv2.NORM_MINMAX, dtype=cv2.CV_8U)\n",
    "        \n",
    "        # Defining the transparency weights\n",
    "        alpha = 0.5\n",
    "        beta = 1 - alpha\n",
    "        gamma = 0\n",
    "        \n",
    "        # Superimposing the class activation map over the input image\n",
    "        overlayed_img = cv2.addWeighted(input_img, alpha, cam, beta, gamma)\n",
    "       \n",
    "        # Displaying the overlaid class activation mapping\n",
    "        visualize_gradcam(overlayed_img, subjects[i], 'turbo', 'grad-cam_blending')\n",
    "\n",
    "\n",
    "# Revising the final model extracted features\n",
    "gradcam_subject_analysis\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 702.61974,
   "end_time": "2023-05-23T13:27:11.638037",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-05-23T13:15:29.018297",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
