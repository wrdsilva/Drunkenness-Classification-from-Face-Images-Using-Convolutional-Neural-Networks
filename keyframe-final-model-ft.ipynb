{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b56788b8",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2022-06-30T17:27:09.353004Z",
     "iopub.status.busy": "2022-06-30T17:27:09.352434Z",
     "iopub.status.idle": "2022-06-30T17:29:19.841568Z",
     "shell.execute_reply": "2022-06-30T17:29:19.840778Z"
    },
    "papermill": {
     "duration": 130.495806,
     "end_time": "2022-06-30T17:29:19.843977",
     "exception": false,
     "start_time": "2022-06-30T17:27:09.348171",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-30 17:27:15.842965: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-06-30 17:27:15.899970: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-06-30 17:27:16.034689: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-06-30 17:27:16.035542: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-06-30 17:27:18.142079: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-06-30 17:27:18.142962: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-06-30 17:27:18.143609: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-06-30 17:27:18.144193: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /device:GPU:0 with 15403 MB memory:  -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n",
      "2022-06-30 17:27:18.148874: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-06-30 17:27:18.149598: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-06-30 17:27:18.150321: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 116576201204818462\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 16152002560\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 16429926067452593588\n",
      "physical_device_desc: \"device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\"\n",
      "]\n",
      "Num GPUs Available:  1\n",
      "Loading Sober-Drunk Face Dataset, from Patras University\n",
      "\n",
      "Samples total: 160\n",
      "\n",
      "Dataset splitting: \n",
      "\n",
      "Training set: 140\n",
      "Test set: 20\n",
      "\n",
      "MinMax normalization\n",
      "dataset shape:  (140, 128, 160, 3)\n",
      "min:  0.0\n",
      "max:  1.0\n",
      "\n",
      "MinMax normalization\n",
      "dataset shape:  (20, 128, 160, 3)\n",
      "min:  0.0\n",
      "max:  1.0\n",
      "\n",
      " Loading pre-trained model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-30 17:27:18.561472: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-06-30 17:27:18.562453: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-06-30 17:27:18.563356: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-06-30 17:27:18.564200: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-06-30 17:27:18.564972: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-06-30 17:27:18.565612: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 15403 MB memory:  -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "block1_conv1 (Conv2D)        (None, 128, 160, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 128, 160, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 64, 80, 64)        0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 64, 80, 128)       73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 64, 80, 128)       147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 32, 40, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 32, 40, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 32, 40, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 32, 40, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 16, 20, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 16, 20, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 16, 20, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 16, 20, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 8, 10, 512)        0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 8, 10, 512)        2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 8, 10, 512)        2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 8, 10, 512)        2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 4, 5, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 10240)             0         \n",
      "_________________________________________________________________\n",
      "dense_layer_1 (Dense)        (None, 10)                102410    \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 14,817,109\n",
      "Trainable params: 102,421\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n",
      "block1_conv1: False\n",
      "block1_conv2: False\n",
      "block1_pool: False\n",
      "block2_conv1: False\n",
      "block2_conv2: False\n",
      "block2_pool: False\n",
      "block3_conv1: False\n",
      "block3_conv2: False\n",
      "block3_conv3: False\n",
      "block3_pool: False\n",
      "block4_conv1: True\n",
      "block4_conv2: True\n",
      "block4_conv3: True\n",
      "block4_pool: True\n",
      "block5_conv1: True\n",
      "block5_conv2: True\n",
      "block5_conv3: True\n",
      "block5_pool: True\n",
      "flatten: True\n",
      "dense_layer_1: True\n",
      "output: True\n",
      "\n",
      "Re-compiling model...\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "block1_conv1 (Conv2D)        (None, 128, 160, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 128, 160, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 64, 80, 64)        0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 64, 80, 128)       73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 64, 80, 128)       147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 32, 40, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 32, 40, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 32, 40, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 32, 40, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 16, 20, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 16, 20, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 16, 20, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 16, 20, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 8, 10, 512)        0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 8, 10, 512)        2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 8, 10, 512)        2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 8, 10, 512)        2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 4, 5, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 10240)             0         \n",
      "_________________________________________________________________\n",
      "dense_layer_1 (Dense)        (None, 10)                102410    \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 14,817,109\n",
      "Trainable params: 13,081,621\n",
      "Non-trainable params: 1,735,488\n",
      "_________________________________________________________________\n",
      "\n",
      "Fitting model...\n",
      "\n",
      "Fold  0\n",
      "\n",
      "Training with 120 samples and validating with 20 samples\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-30 17:27:20.213297: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/205\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-30 17:27:21.898464: I tensorflow/stream_executor/cuda/cuda_dnn.cc:369] Loaded cuDNN version 8005\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 11s 1s/step - loss: 0.1548 - accuracy: 0.9750 - val_loss: 0.1417 - val_accuracy: 0.9500\n",
      "Epoch 2/205\n",
      "2/2 [==============================] - 0s 125ms/step - loss: 0.1539 - accuracy: 0.9750 - val_loss: 0.1417 - val_accuracy: 0.9500\n",
      "Epoch 3/205\n",
      "2/2 [==============================] - 0s 124ms/step - loss: 0.1531 - accuracy: 0.9750 - val_loss: 0.1418 - val_accuracy: 0.9500\n",
      "Epoch 4/205\n",
      "2/2 [==============================] - 0s 124ms/step - loss: 0.1523 - accuracy: 0.9750 - val_loss: 0.1418 - val_accuracy: 0.9500\n",
      "Epoch 5/205\n",
      "2/2 [==============================] - 0s 159ms/step - loss: 0.1515 - accuracy: 0.9833 - val_loss: 0.1419 - val_accuracy: 0.9500\n",
      "Epoch 6/205\n",
      "2/2 [==============================] - 0s 132ms/step - loss: 0.1508 - accuracy: 0.9833 - val_loss: 0.1419 - val_accuracy: 0.9500\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00006: early stopping\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.4061 - accuracy: 0.9500\n",
      "\n",
      "Fold  0\n",
      "\n",
      "Test accuracy:  0.949999988079071\n",
      "Test loss:  0.4060977101325989\n",
      "\n",
      "Fold  1\n",
      "\n",
      "Training with 120 samples and validating with 20 samples\n",
      "\n",
      "Epoch 1/205\n",
      "2/2 [==============================] - 0s 147ms/step - loss: 0.1543 - accuracy: 0.9667 - val_loss: 0.1273 - val_accuracy: 1.0000\n",
      "Epoch 2/205\n",
      "2/2 [==============================] - 0s 124ms/step - loss: 0.1536 - accuracy: 0.9667 - val_loss: 0.1271 - val_accuracy: 1.0000\n",
      "Epoch 3/205\n",
      "2/2 [==============================] - 0s 121ms/step - loss: 0.1529 - accuracy: 0.9667 - val_loss: 0.1269 - val_accuracy: 1.0000\n",
      "Epoch 4/205\n",
      "2/2 [==============================] - 0s 118ms/step - loss: 0.1522 - accuracy: 0.9667 - val_loss: 0.1267 - val_accuracy: 1.0000\n",
      "Epoch 5/205\n",
      "2/2 [==============================] - 0s 119ms/step - loss: 0.1515 - accuracy: 0.9750 - val_loss: 0.1266 - val_accuracy: 1.0000\n",
      "Epoch 6/205\n",
      "2/2 [==============================] - 0s 134ms/step - loss: 0.1508 - accuracy: 0.9750 - val_loss: 0.1264 - val_accuracy: 1.0000\n",
      "Epoch 7/205\n",
      "2/2 [==============================] - 0s 136ms/step - loss: 0.1501 - accuracy: 0.9750 - val_loss: 0.1263 - val_accuracy: 1.0000\n",
      "Epoch 8/205\n",
      "2/2 [==============================] - 0s 130ms/step - loss: 0.1494 - accuracy: 0.9750 - val_loss: 0.1261 - val_accuracy: 1.0000\n",
      "Epoch 9/205\n",
      "2/2 [==============================] - 0s 118ms/step - loss: 0.1487 - accuracy: 0.9750 - val_loss: 0.1259 - val_accuracy: 1.0000\n",
      "Epoch 10/205\n",
      "2/2 [==============================] - 0s 155ms/step - loss: 0.1481 - accuracy: 0.9750 - val_loss: 0.1257 - val_accuracy: 1.0000\n",
      "Epoch 11/205\n",
      "2/2 [==============================] - 0s 120ms/step - loss: 0.1474 - accuracy: 0.9750 - val_loss: 0.1255 - val_accuracy: 1.0000\n",
      "Epoch 12/205\n",
      "2/2 [==============================] - 0s 118ms/step - loss: 0.1468 - accuracy: 0.9750 - val_loss: 0.1253 - val_accuracy: 1.0000\n",
      "Epoch 13/205\n",
      "2/2 [==============================] - 0s 117ms/step - loss: 0.1461 - accuracy: 0.9750 - val_loss: 0.1251 - val_accuracy: 1.0000\n",
      "Epoch 14/205\n",
      "2/2 [==============================] - 0s 118ms/step - loss: 0.1455 - accuracy: 0.9750 - val_loss: 0.1250 - val_accuracy: 1.0000\n",
      "Epoch 15/205\n",
      "2/2 [==============================] - 0s 123ms/step - loss: 0.1449 - accuracy: 0.9750 - val_loss: 0.1248 - val_accuracy: 1.0000\n",
      "Epoch 16/205\n",
      "2/2 [==============================] - 0s 118ms/step - loss: 0.1443 - accuracy: 0.9750 - val_loss: 0.1247 - val_accuracy: 1.0000\n",
      "Epoch 17/205\n",
      "2/2 [==============================] - 0s 118ms/step - loss: 0.1437 - accuracy: 0.9750 - val_loss: 0.1245 - val_accuracy: 1.0000\n",
      "Epoch 18/205\n",
      "2/2 [==============================] - 0s 122ms/step - loss: 0.1431 - accuracy: 0.9833 - val_loss: 0.1244 - val_accuracy: 1.0000\n",
      "Epoch 19/205\n",
      "2/2 [==============================] - 0s 118ms/step - loss: 0.1425 - accuracy: 0.9833 - val_loss: 0.1242 - val_accuracy: 1.0000\n",
      "Epoch 20/205\n",
      "2/2 [==============================] - 0s 117ms/step - loss: 0.1420 - accuracy: 0.9833 - val_loss: 0.1241 - val_accuracy: 1.0000\n",
      "Epoch 21/205\n",
      "2/2 [==============================] - 0s 119ms/step - loss: 0.1414 - accuracy: 0.9833 - val_loss: 0.1240 - val_accuracy: 1.0000\n",
      "Epoch 22/205\n",
      "2/2 [==============================] - 0s 121ms/step - loss: 0.1408 - accuracy: 0.9833 - val_loss: 0.1239 - val_accuracy: 1.0000\n",
      "Epoch 23/205\n",
      "2/2 [==============================] - 0s 116ms/step - loss: 0.1403 - accuracy: 0.9833 - val_loss: 0.1238 - val_accuracy: 1.0000\n",
      "Epoch 24/205\n",
      "2/2 [==============================] - 0s 117ms/step - loss: 0.1397 - accuracy: 0.9833 - val_loss: 0.1237 - val_accuracy: 1.0000\n",
      "Epoch 25/205\n",
      "2/2 [==============================] - 0s 119ms/step - loss: 0.1392 - accuracy: 0.9833 - val_loss: 0.1235 - val_accuracy: 1.0000\n",
      "Epoch 26/205\n",
      "2/2 [==============================] - 0s 117ms/step - loss: 0.1387 - accuracy: 0.9833 - val_loss: 0.1234 - val_accuracy: 1.0000\n",
      "Epoch 27/205\n",
      "2/2 [==============================] - 0s 118ms/step - loss: 0.1382 - accuracy: 0.9833 - val_loss: 0.1234 - val_accuracy: 1.0000\n",
      "Epoch 28/205\n",
      "2/2 [==============================] - 0s 118ms/step - loss: 0.1376 - accuracy: 0.9833 - val_loss: 0.1233 - val_accuracy: 1.0000\n",
      "Epoch 29/205\n",
      "2/2 [==============================] - 0s 118ms/step - loss: 0.1371 - accuracy: 0.9833 - val_loss: 0.1232 - val_accuracy: 1.0000\n",
      "Epoch 30/205\n",
      "2/2 [==============================] - 0s 118ms/step - loss: 0.1366 - accuracy: 0.9833 - val_loss: 0.1231 - val_accuracy: 1.0000\n",
      "Epoch 31/205\n",
      "2/2 [==============================] - 0s 124ms/step - loss: 0.1361 - accuracy: 0.9833 - val_loss: 0.1230 - val_accuracy: 1.0000\n",
      "Epoch 32/205\n",
      "2/2 [==============================] - 0s 120ms/step - loss: 0.1356 - accuracy: 0.9833 - val_loss: 0.1229 - val_accuracy: 1.0000\n",
      "Epoch 33/205\n",
      "2/2 [==============================] - 0s 117ms/step - loss: 0.1351 - accuracy: 0.9833 - val_loss: 0.1228 - val_accuracy: 1.0000\n",
      "Epoch 34/205\n",
      "2/2 [==============================] - 0s 120ms/step - loss: 0.1346 - accuracy: 0.9833 - val_loss: 0.1227 - val_accuracy: 1.0000\n",
      "Epoch 35/205\n",
      "2/2 [==============================] - 0s 118ms/step - loss: 0.1341 - accuracy: 0.9833 - val_loss: 0.1227 - val_accuracy: 1.0000\n",
      "Epoch 36/205\n",
      "2/2 [==============================] - 0s 116ms/step - loss: 0.1336 - accuracy: 0.9833 - val_loss: 0.1226 - val_accuracy: 1.0000\n",
      "Epoch 37/205\n",
      "2/2 [==============================] - 0s 155ms/step - loss: 0.1332 - accuracy: 0.9833 - val_loss: 0.1225 - val_accuracy: 1.0000\n",
      "Epoch 38/205\n",
      "2/2 [==============================] - 0s 118ms/step - loss: 0.1327 - accuracy: 0.9833 - val_loss: 0.1224 - val_accuracy: 1.0000\n",
      "Epoch 39/205\n",
      "2/2 [==============================] - 0s 117ms/step - loss: 0.1322 - accuracy: 0.9833 - val_loss: 0.1224 - val_accuracy: 1.0000\n",
      "Epoch 40/205\n",
      "2/2 [==============================] - 0s 119ms/step - loss: 0.1317 - accuracy: 0.9833 - val_loss: 0.1223 - val_accuracy: 1.0000\n",
      "Epoch 41/205\n",
      "2/2 [==============================] - 0s 117ms/step - loss: 0.1313 - accuracy: 0.9833 - val_loss: 0.1222 - val_accuracy: 1.0000\n",
      "Epoch 42/205\n",
      "2/2 [==============================] - 0s 119ms/step - loss: 0.1308 - accuracy: 0.9833 - val_loss: 0.1222 - val_accuracy: 1.0000\n",
      "Epoch 43/205\n",
      "2/2 [==============================] - 0s 119ms/step - loss: 0.1303 - accuracy: 0.9833 - val_loss: 0.1221 - val_accuracy: 1.0000\n",
      "Epoch 44/205\n",
      "2/2 [==============================] - 0s 124ms/step - loss: 0.1299 - accuracy: 0.9833 - val_loss: 0.1220 - val_accuracy: 1.0000\n",
      "Epoch 45/205\n",
      "2/2 [==============================] - 0s 125ms/step - loss: 0.1294 - accuracy: 0.9833 - val_loss: 0.1220 - val_accuracy: 1.0000\n",
      "Epoch 46/205\n",
      "2/2 [==============================] - 0s 118ms/step - loss: 0.1290 - accuracy: 0.9833 - val_loss: 0.1219 - val_accuracy: 1.0000\n",
      "Epoch 47/205\n",
      "2/2 [==============================] - 0s 117ms/step - loss: 0.1285 - accuracy: 0.9833 - val_loss: 0.1218 - val_accuracy: 1.0000\n",
      "Epoch 48/205\n",
      "2/2 [==============================] - 0s 118ms/step - loss: 0.1281 - accuracy: 0.9833 - val_loss: 0.1218 - val_accuracy: 1.0000\n",
      "Epoch 49/205\n",
      "2/2 [==============================] - 0s 120ms/step - loss: 0.1276 - accuracy: 0.9833 - val_loss: 0.1217 - val_accuracy: 1.0000\n",
      "Epoch 50/205\n",
      "2/2 [==============================] - 0s 117ms/step - loss: 0.1272 - accuracy: 0.9833 - val_loss: 0.1217 - val_accuracy: 1.0000\n",
      "Epoch 51/205\n",
      "2/2 [==============================] - 0s 118ms/step - loss: 0.1267 - accuracy: 0.9833 - val_loss: 0.1216 - val_accuracy: 1.0000\n",
      "Epoch 52/205\n",
      "2/2 [==============================] - 0s 117ms/step - loss: 0.1263 - accuracy: 0.9833 - val_loss: 0.1215 - val_accuracy: 1.0000\n",
      "Epoch 53/205\n",
      "2/2 [==============================] - 0s 137ms/step - loss: 0.1259 - accuracy: 0.9833 - val_loss: 0.1214 - val_accuracy: 1.0000\n",
      "Epoch 54/205\n",
      "2/2 [==============================] - 0s 131ms/step - loss: 0.1254 - accuracy: 0.9833 - val_loss: 0.1214 - val_accuracy: 1.0000\n",
      "Epoch 55/205\n",
      "2/2 [==============================] - 0s 119ms/step - loss: 0.1250 - accuracy: 0.9833 - val_loss: 0.1213 - val_accuracy: 1.0000\n",
      "Epoch 56/205\n",
      "2/2 [==============================] - 0s 118ms/step - loss: 0.1246 - accuracy: 0.9833 - val_loss: 0.1213 - val_accuracy: 1.0000\n",
      "Epoch 57/205\n",
      "2/2 [==============================] - 0s 117ms/step - loss: 0.1241 - accuracy: 0.9833 - val_loss: 0.1212 - val_accuracy: 1.0000\n",
      "Epoch 58/205\n",
      "2/2 [==============================] - 0s 117ms/step - loss: 0.1237 - accuracy: 0.9833 - val_loss: 0.1211 - val_accuracy: 1.0000\n",
      "Epoch 59/205\n",
      "2/2 [==============================] - 0s 117ms/step - loss: 0.1233 - accuracy: 0.9833 - val_loss: 0.1210 - val_accuracy: 1.0000\n",
      "Epoch 60/205\n",
      "2/2 [==============================] - 0s 118ms/step - loss: 0.1229 - accuracy: 0.9833 - val_loss: 0.1210 - val_accuracy: 1.0000\n",
      "Epoch 61/205\n",
      "2/2 [==============================] - 0s 118ms/step - loss: 0.1225 - accuracy: 0.9833 - val_loss: 0.1209 - val_accuracy: 1.0000\n",
      "Epoch 62/205\n",
      "2/2 [==============================] - 0s 118ms/step - loss: 0.1220 - accuracy: 0.9833 - val_loss: 0.1208 - val_accuracy: 1.0000\n",
      "Epoch 63/205\n",
      "2/2 [==============================] - 0s 119ms/step - loss: 0.1216 - accuracy: 0.9833 - val_loss: 0.1208 - val_accuracy: 1.0000\n",
      "Epoch 64/205\n",
      "2/2 [==============================] - 0s 118ms/step - loss: 0.1212 - accuracy: 0.9833 - val_loss: 0.1207 - val_accuracy: 1.0000\n",
      "Epoch 65/205\n",
      "2/2 [==============================] - 0s 117ms/step - loss: 0.1208 - accuracy: 0.9833 - val_loss: 0.1206 - val_accuracy: 1.0000\n",
      "Epoch 66/205\n",
      "2/2 [==============================] - 0s 117ms/step - loss: 0.1204 - accuracy: 0.9833 - val_loss: 0.1205 - val_accuracy: 1.0000\n",
      "Epoch 67/205\n",
      "2/2 [==============================] - 0s 119ms/step - loss: 0.1200 - accuracy: 0.9833 - val_loss: 0.1205 - val_accuracy: 1.0000\n",
      "Epoch 68/205\n",
      "2/2 [==============================] - 0s 117ms/step - loss: 0.1196 - accuracy: 0.9833 - val_loss: 0.1204 - val_accuracy: 1.0000\n",
      "Epoch 69/205\n",
      "2/2 [==============================] - 0s 119ms/step - loss: 0.1192 - accuracy: 0.9833 - val_loss: 0.1203 - val_accuracy: 1.0000\n",
      "Epoch 70/205\n",
      "2/2 [==============================] - 0s 128ms/step - loss: 0.1188 - accuracy: 0.9833 - val_loss: 0.1203 - val_accuracy: 1.0000\n",
      "Epoch 71/205\n",
      "2/2 [==============================] - 0s 117ms/step - loss: 0.1184 - accuracy: 0.9833 - val_loss: 0.1202 - val_accuracy: 1.0000\n",
      "Epoch 72/205\n",
      "2/2 [==============================] - 0s 119ms/step - loss: 0.1181 - accuracy: 0.9833 - val_loss: 0.1202 - val_accuracy: 1.0000\n",
      "Epoch 73/205\n",
      "2/2 [==============================] - 0s 119ms/step - loss: 0.1177 - accuracy: 0.9833 - val_loss: 0.1201 - val_accuracy: 1.0000\n",
      "Epoch 74/205\n",
      "2/2 [==============================] - 0s 119ms/step - loss: 0.1173 - accuracy: 0.9833 - val_loss: 0.1201 - val_accuracy: 1.0000\n",
      "Epoch 75/205\n",
      "2/2 [==============================] - 0s 119ms/step - loss: 0.1169 - accuracy: 0.9833 - val_loss: 0.1200 - val_accuracy: 1.0000\n",
      "Epoch 76/205\n",
      "2/2 [==============================] - 0s 118ms/step - loss: 0.1165 - accuracy: 0.9833 - val_loss: 0.1199 - val_accuracy: 1.0000\n",
      "Epoch 77/205\n",
      "2/2 [==============================] - 0s 118ms/step - loss: 0.1162 - accuracy: 0.9833 - val_loss: 0.1199 - val_accuracy: 1.0000\n",
      "Epoch 78/205\n",
      "2/2 [==============================] - 0s 119ms/step - loss: 0.1158 - accuracy: 0.9833 - val_loss: 0.1198 - val_accuracy: 1.0000\n",
      "Epoch 79/205\n",
      "2/2 [==============================] - 0s 117ms/step - loss: 0.1154 - accuracy: 0.9833 - val_loss: 0.1198 - val_accuracy: 1.0000\n",
      "Epoch 80/205\n",
      "2/2 [==============================] - 0s 117ms/step - loss: 0.1151 - accuracy: 0.9833 - val_loss: 0.1197 - val_accuracy: 1.0000\n",
      "Epoch 81/205\n",
      "2/2 [==============================] - 0s 117ms/step - loss: 0.1147 - accuracy: 0.9833 - val_loss: 0.1197 - val_accuracy: 1.0000\n",
      "Epoch 82/205\n",
      "2/2 [==============================] - 0s 120ms/step - loss: 0.1144 - accuracy: 0.9833 - val_loss: 0.1196 - val_accuracy: 1.0000\n",
      "Epoch 83/205\n",
      "2/2 [==============================] - 0s 118ms/step - loss: 0.1140 - accuracy: 0.9833 - val_loss: 0.1196 - val_accuracy: 1.0000\n",
      "Epoch 84/205\n",
      "2/2 [==============================] - 0s 118ms/step - loss: 0.1136 - accuracy: 0.9833 - val_loss: 0.1195 - val_accuracy: 1.0000\n",
      "Epoch 85/205\n",
      "2/2 [==============================] - 0s 120ms/step - loss: 0.1133 - accuracy: 0.9833 - val_loss: 0.1195 - val_accuracy: 1.0000\n",
      "Epoch 86/205\n",
      "2/2 [==============================] - 0s 116ms/step - loss: 0.1129 - accuracy: 0.9833 - val_loss: 0.1194 - val_accuracy: 1.0000\n",
      "Epoch 87/205\n",
      "2/2 [==============================] - 0s 120ms/step - loss: 0.1126 - accuracy: 0.9833 - val_loss: 0.1194 - val_accuracy: 1.0000\n",
      "Epoch 88/205\n",
      "2/2 [==============================] - 0s 117ms/step - loss: 0.1123 - accuracy: 0.9833 - val_loss: 0.1193 - val_accuracy: 1.0000\n",
      "Epoch 89/205\n",
      "2/2 [==============================] - 0s 119ms/step - loss: 0.1119 - accuracy: 0.9833 - val_loss: 0.1193 - val_accuracy: 1.0000\n",
      "Epoch 90/205\n",
      "2/2 [==============================] - 0s 118ms/step - loss: 0.1116 - accuracy: 0.9833 - val_loss: 0.1192 - val_accuracy: 1.0000\n",
      "Epoch 91/205\n",
      "2/2 [==============================] - 0s 117ms/step - loss: 0.1112 - accuracy: 0.9833 - val_loss: 0.1192 - val_accuracy: 1.0000\n",
      "Epoch 92/205\n",
      "2/2 [==============================] - 0s 118ms/step - loss: 0.1109 - accuracy: 0.9833 - val_loss: 0.1191 - val_accuracy: 1.0000\n",
      "Epoch 93/205\n",
      "2/2 [==============================] - 0s 156ms/step - loss: 0.1106 - accuracy: 0.9833 - val_loss: 0.1190 - val_accuracy: 1.0000\n",
      "Epoch 94/205\n",
      "2/2 [==============================] - 0s 118ms/step - loss: 0.1102 - accuracy: 0.9833 - val_loss: 0.1190 - val_accuracy: 1.0000\n",
      "Epoch 95/205\n",
      "2/2 [==============================] - 0s 157ms/step - loss: 0.1099 - accuracy: 0.9833 - val_loss: 0.1189 - val_accuracy: 1.0000\n",
      "Epoch 96/205\n",
      "2/2 [==============================] - 0s 121ms/step - loss: 0.1096 - accuracy: 0.9833 - val_loss: 0.1188 - val_accuracy: 1.0000\n",
      "Epoch 97/205\n",
      "2/2 [==============================] - 0s 119ms/step - loss: 0.1093 - accuracy: 0.9833 - val_loss: 0.1188 - val_accuracy: 1.0000\n",
      "Epoch 98/205\n",
      "2/2 [==============================] - 0s 118ms/step - loss: 0.1089 - accuracy: 0.9833 - val_loss: 0.1187 - val_accuracy: 1.0000\n",
      "Epoch 99/205\n",
      "2/2 [==============================] - 0s 116ms/step - loss: 0.1086 - accuracy: 0.9833 - val_loss: 0.1186 - val_accuracy: 1.0000\n",
      "Epoch 100/205\n",
      "2/2 [==============================] - 0s 129ms/step - loss: 0.1083 - accuracy: 0.9833 - val_loss: 0.1186 - val_accuracy: 1.0000\n",
      "Epoch 101/205\n",
      "2/2 [==============================] - 0s 217ms/step - loss: 0.1080 - accuracy: 0.9833 - val_loss: 0.1185 - val_accuracy: 1.0000\n",
      "Epoch 102/205\n",
      "2/2 [==============================] - 0s 137ms/step - loss: 0.1076 - accuracy: 0.9833 - val_loss: 0.1185 - val_accuracy: 1.0000\n",
      "Epoch 103/205\n",
      "2/2 [==============================] - 0s 129ms/step - loss: 0.1073 - accuracy: 0.9833 - val_loss: 0.1184 - val_accuracy: 1.0000\n",
      "Epoch 104/205\n",
      "2/2 [==============================] - 0s 163ms/step - loss: 0.1070 - accuracy: 0.9833 - val_loss: 0.1183 - val_accuracy: 1.0000\n",
      "Epoch 105/205\n",
      "2/2 [==============================] - 0s 129ms/step - loss: 0.1067 - accuracy: 0.9833 - val_loss: 0.1183 - val_accuracy: 1.0000\n",
      "Epoch 106/205\n",
      "2/2 [==============================] - 0s 118ms/step - loss: 0.1064 - accuracy: 0.9833 - val_loss: 0.1182 - val_accuracy: 1.0000\n",
      "Epoch 107/205\n",
      "2/2 [==============================] - 0s 119ms/step - loss: 0.1061 - accuracy: 0.9833 - val_loss: 0.1182 - val_accuracy: 1.0000\n",
      "Epoch 108/205\n",
      "2/2 [==============================] - 0s 118ms/step - loss: 0.1058 - accuracy: 0.9833 - val_loss: 0.1181 - val_accuracy: 1.0000\n",
      "Epoch 109/205\n",
      "2/2 [==============================] - 0s 119ms/step - loss: 0.1054 - accuracy: 0.9833 - val_loss: 0.1180 - val_accuracy: 1.0000\n",
      "Epoch 110/205\n",
      "2/2 [==============================] - 0s 119ms/step - loss: 0.1051 - accuracy: 0.9833 - val_loss: 0.1180 - val_accuracy: 1.0000\n",
      "Epoch 111/205\n",
      "2/2 [==============================] - 0s 119ms/step - loss: 0.1048 - accuracy: 0.9833 - val_loss: 0.1179 - val_accuracy: 1.0000\n",
      "Epoch 112/205\n",
      "2/2 [==============================] - 0s 118ms/step - loss: 0.1045 - accuracy: 0.9833 - val_loss: 0.1179 - val_accuracy: 1.0000\n",
      "Epoch 113/205\n",
      "2/2 [==============================] - 0s 118ms/step - loss: 0.1042 - accuracy: 0.9833 - val_loss: 0.1178 - val_accuracy: 1.0000\n",
      "Epoch 114/205\n",
      "2/2 [==============================] - 0s 118ms/step - loss: 0.1039 - accuracy: 0.9833 - val_loss: 0.1178 - val_accuracy: 1.0000\n",
      "Epoch 115/205\n",
      "2/2 [==============================] - 0s 121ms/step - loss: 0.1036 - accuracy: 0.9833 - val_loss: 0.1177 - val_accuracy: 1.0000\n",
      "Epoch 116/205\n",
      "2/2 [==============================] - 0s 118ms/step - loss: 0.1033 - accuracy: 0.9833 - val_loss: 0.1176 - val_accuracy: 1.0000\n",
      "Epoch 117/205\n",
      "2/2 [==============================] - 0s 118ms/step - loss: 0.1030 - accuracy: 0.9833 - val_loss: 0.1176 - val_accuracy: 1.0000\n",
      "Epoch 118/205\n",
      "2/2 [==============================] - 0s 118ms/step - loss: 0.1027 - accuracy: 0.9833 - val_loss: 0.1175 - val_accuracy: 1.0000\n",
      "Epoch 119/205\n",
      "2/2 [==============================] - 0s 118ms/step - loss: 0.1024 - accuracy: 0.9833 - val_loss: 0.1175 - val_accuracy: 1.0000\n",
      "Epoch 120/205\n",
      "2/2 [==============================] - 0s 117ms/step - loss: 0.1021 - accuracy: 0.9833 - val_loss: 0.1174 - val_accuracy: 1.0000\n",
      "Epoch 121/205\n",
      "2/2 [==============================] - 0s 118ms/step - loss: 0.1018 - accuracy: 0.9833 - val_loss: 0.1174 - val_accuracy: 1.0000\n",
      "Epoch 122/205\n",
      "2/2 [==============================] - 0s 119ms/step - loss: 0.1015 - accuracy: 0.9833 - val_loss: 0.1173 - val_accuracy: 1.0000\n",
      "Epoch 123/205\n",
      "2/2 [==============================] - 0s 119ms/step - loss: 0.1012 - accuracy: 0.9833 - val_loss: 0.1173 - val_accuracy: 1.0000\n",
      "Epoch 124/205\n",
      "2/2 [==============================] - 0s 117ms/step - loss: 0.1009 - accuracy: 0.9833 - val_loss: 0.1172 - val_accuracy: 1.0000\n",
      "Epoch 125/205\n",
      "2/2 [==============================] - 0s 119ms/step - loss: 0.1006 - accuracy: 0.9833 - val_loss: 0.1171 - val_accuracy: 1.0000\n",
      "Epoch 126/205\n",
      "2/2 [==============================] - 0s 119ms/step - loss: 0.1003 - accuracy: 0.9833 - val_loss: 0.1171 - val_accuracy: 1.0000\n",
      "Epoch 127/205\n",
      "2/2 [==============================] - 0s 118ms/step - loss: 0.1001 - accuracy: 0.9833 - val_loss: 0.1170 - val_accuracy: 1.0000\n",
      "Epoch 128/205\n",
      "2/2 [==============================] - 0s 121ms/step - loss: 0.0998 - accuracy: 0.9833 - val_loss: 0.1170 - val_accuracy: 1.0000\n",
      "Epoch 129/205\n",
      "2/2 [==============================] - 0s 119ms/step - loss: 0.0995 - accuracy: 0.9833 - val_loss: 0.1169 - val_accuracy: 1.0000\n",
      "Epoch 130/205\n",
      "2/2 [==============================] - 0s 117ms/step - loss: 0.0992 - accuracy: 0.9833 - val_loss: 0.1169 - val_accuracy: 1.0000\n",
      "Epoch 131/205\n",
      "2/2 [==============================] - 0s 118ms/step - loss: 0.0989 - accuracy: 0.9833 - val_loss: 0.1168 - val_accuracy: 1.0000\n",
      "Epoch 132/205\n",
      "2/2 [==============================] - 0s 157ms/step - loss: 0.0986 - accuracy: 0.9833 - val_loss: 0.1167 - val_accuracy: 1.0000\n",
      "Epoch 133/205\n",
      "2/2 [==============================] - 0s 119ms/step - loss: 0.0984 - accuracy: 0.9833 - val_loss: 0.1167 - val_accuracy: 1.0000\n",
      "Epoch 134/205\n",
      "2/2 [==============================] - 0s 121ms/step - loss: 0.0981 - accuracy: 0.9833 - val_loss: 0.1166 - val_accuracy: 1.0000\n",
      "Epoch 135/205\n",
      "2/2 [==============================] - 0s 155ms/step - loss: 0.0978 - accuracy: 0.9833 - val_loss: 0.1166 - val_accuracy: 1.0000\n",
      "Epoch 136/205\n",
      "2/2 [==============================] - 0s 117ms/step - loss: 0.0975 - accuracy: 0.9833 - val_loss: 0.1165 - val_accuracy: 1.0000\n",
      "Epoch 137/205\n",
      "2/2 [==============================] - 0s 119ms/step - loss: 0.0972 - accuracy: 0.9833 - val_loss: 0.1165 - val_accuracy: 1.0000\n",
      "Epoch 138/205\n",
      "2/2 [==============================] - 0s 118ms/step - loss: 0.0970 - accuracy: 0.9833 - val_loss: 0.1164 - val_accuracy: 1.0000\n",
      "Epoch 139/205\n",
      "2/2 [==============================] - 0s 118ms/step - loss: 0.0967 - accuracy: 0.9833 - val_loss: 0.1163 - val_accuracy: 1.0000\n",
      "Epoch 140/205\n",
      "2/2 [==============================] - 0s 118ms/step - loss: 0.0964 - accuracy: 0.9833 - val_loss: 0.1163 - val_accuracy: 1.0000\n",
      "Epoch 141/205\n",
      "2/2 [==============================] - 0s 118ms/step - loss: 0.0961 - accuracy: 0.9833 - val_loss: 0.1162 - val_accuracy: 1.0000\n",
      "Epoch 142/205\n",
      "2/2 [==============================] - 0s 117ms/step - loss: 0.0959 - accuracy: 0.9833 - val_loss: 0.1162 - val_accuracy: 1.0000\n",
      "Epoch 143/205\n",
      "2/2 [==============================] - 0s 120ms/step - loss: 0.0956 - accuracy: 0.9833 - val_loss: 0.1161 - val_accuracy: 1.0000\n",
      "Epoch 144/205\n",
      "2/2 [==============================] - 0s 118ms/step - loss: 0.0953 - accuracy: 0.9833 - val_loss: 0.1160 - val_accuracy: 1.0000\n",
      "Epoch 145/205\n",
      "2/2 [==============================] - 0s 118ms/step - loss: 0.0951 - accuracy: 0.9833 - val_loss: 0.1159 - val_accuracy: 1.0000\n",
      "Epoch 146/205\n",
      "2/2 [==============================] - 0s 138ms/step - loss: 0.0948 - accuracy: 0.9833 - val_loss: 0.1159 - val_accuracy: 1.0000\n",
      "Epoch 147/205\n",
      "2/2 [==============================] - 0s 130ms/step - loss: 0.0945 - accuracy: 0.9833 - val_loss: 0.1158 - val_accuracy: 1.0000\n",
      "Epoch 148/205\n",
      "2/2 [==============================] - 0s 121ms/step - loss: 0.0943 - accuracy: 0.9833 - val_loss: 0.1157 - val_accuracy: 1.0000\n",
      "Epoch 149/205\n",
      "2/2 [==============================] - 0s 118ms/step - loss: 0.0940 - accuracy: 0.9833 - val_loss: 0.1156 - val_accuracy: 1.0000\n",
      "Epoch 150/205\n",
      "2/2 [==============================] - 0s 155ms/step - loss: 0.0937 - accuracy: 0.9833 - val_loss: 0.1156 - val_accuracy: 1.0000\n",
      "Epoch 151/205\n",
      "2/2 [==============================] - 0s 121ms/step - loss: 0.0935 - accuracy: 0.9833 - val_loss: 0.1155 - val_accuracy: 1.0000\n",
      "Epoch 152/205\n",
      "2/2 [==============================] - 0s 118ms/step - loss: 0.0932 - accuracy: 0.9833 - val_loss: 0.1155 - val_accuracy: 1.0000\n",
      "Epoch 153/205\n",
      "2/2 [==============================] - 0s 118ms/step - loss: 0.0930 - accuracy: 0.9833 - val_loss: 0.1154 - val_accuracy: 1.0000\n",
      "Epoch 154/205\n",
      "2/2 [==============================] - 0s 119ms/step - loss: 0.0927 - accuracy: 0.9833 - val_loss: 0.1153 - val_accuracy: 1.0000\n",
      "Epoch 155/205\n",
      "2/2 [==============================] - 0s 118ms/step - loss: 0.0924 - accuracy: 0.9833 - val_loss: 0.1152 - val_accuracy: 1.0000\n",
      "Epoch 156/205\n",
      "2/2 [==============================] - 0s 119ms/step - loss: 0.0922 - accuracy: 0.9833 - val_loss: 0.1152 - val_accuracy: 1.0000\n",
      "Epoch 157/205\n",
      "2/2 [==============================] - 0s 118ms/step - loss: 0.0919 - accuracy: 0.9833 - val_loss: 0.1151 - val_accuracy: 1.0000\n",
      "Epoch 158/205\n",
      "2/2 [==============================] - 0s 119ms/step - loss: 0.0917 - accuracy: 0.9833 - val_loss: 0.1150 - val_accuracy: 1.0000\n",
      "Epoch 159/205\n",
      "2/2 [==============================] - 0s 118ms/step - loss: 0.0914 - accuracy: 0.9833 - val_loss: 0.1150 - val_accuracy: 1.0000\n",
      "Epoch 160/205\n",
      "2/2 [==============================] - 0s 117ms/step - loss: 0.0912 - accuracy: 0.9833 - val_loss: 0.1149 - val_accuracy: 1.0000\n",
      "Epoch 161/205\n",
      "2/2 [==============================] - 0s 119ms/step - loss: 0.0909 - accuracy: 0.9833 - val_loss: 0.1148 - val_accuracy: 1.0000\n",
      "Epoch 162/205\n",
      "2/2 [==============================] - 0s 120ms/step - loss: 0.0907 - accuracy: 0.9833 - val_loss: 0.1148 - val_accuracy: 1.0000\n",
      "Epoch 163/205\n",
      "2/2 [==============================] - 0s 117ms/step - loss: 0.0904 - accuracy: 0.9833 - val_loss: 0.1147 - val_accuracy: 1.0000\n",
      "Epoch 164/205\n",
      "2/2 [==============================] - 0s 120ms/step - loss: 0.0901 - accuracy: 0.9833 - val_loss: 0.1146 - val_accuracy: 1.0000\n",
      "Epoch 165/205\n",
      "2/2 [==============================] - 0s 118ms/step - loss: 0.0899 - accuracy: 0.9833 - val_loss: 0.1145 - val_accuracy: 1.0000\n",
      "Epoch 166/205\n",
      "2/2 [==============================] - 0s 119ms/step - loss: 0.0896 - accuracy: 0.9833 - val_loss: 0.1145 - val_accuracy: 1.0000\n",
      "Epoch 167/205\n",
      "2/2 [==============================] - 0s 155ms/step - loss: 0.0894 - accuracy: 0.9833 - val_loss: 0.1144 - val_accuracy: 1.0000\n",
      "Epoch 168/205\n",
      "2/2 [==============================] - 0s 118ms/step - loss: 0.0892 - accuracy: 0.9833 - val_loss: 0.1143 - val_accuracy: 1.0000\n",
      "Epoch 169/205\n",
      "2/2 [==============================] - 0s 119ms/step - loss: 0.0889 - accuracy: 0.9833 - val_loss: 0.1142 - val_accuracy: 1.0000\n",
      "Epoch 170/205\n",
      "2/2 [==============================] - 0s 118ms/step - loss: 0.0887 - accuracy: 0.9833 - val_loss: 0.1141 - val_accuracy: 1.0000\n",
      "Epoch 171/205\n",
      "2/2 [==============================] - 0s 117ms/step - loss: 0.0884 - accuracy: 0.9833 - val_loss: 0.1141 - val_accuracy: 1.0000\n",
      "Epoch 172/205\n",
      "2/2 [==============================] - 0s 120ms/step - loss: 0.0882 - accuracy: 0.9833 - val_loss: 0.1140 - val_accuracy: 1.0000\n",
      "Epoch 173/205\n",
      "2/2 [==============================] - 0s 119ms/step - loss: 0.0879 - accuracy: 0.9833 - val_loss: 0.1139 - val_accuracy: 1.0000\n",
      "Epoch 174/205\n",
      "2/2 [==============================] - 0s 118ms/step - loss: 0.0877 - accuracy: 0.9833 - val_loss: 0.1139 - val_accuracy: 1.0000\n",
      "Epoch 175/205\n",
      "2/2 [==============================] - 0s 156ms/step - loss: 0.0874 - accuracy: 0.9833 - val_loss: 0.1138 - val_accuracy: 1.0000\n",
      "Epoch 176/205\n",
      "2/2 [==============================] - 0s 120ms/step - loss: 0.0872 - accuracy: 0.9833 - val_loss: 0.1137 - val_accuracy: 1.0000\n",
      "Epoch 177/205\n",
      "2/2 [==============================] - 0s 119ms/step - loss: 0.0870 - accuracy: 0.9833 - val_loss: 0.1136 - val_accuracy: 1.0000\n",
      "Epoch 178/205\n",
      "2/2 [==============================] - 0s 119ms/step - loss: 0.0867 - accuracy: 0.9833 - val_loss: 0.1136 - val_accuracy: 1.0000\n",
      "Epoch 179/205\n",
      "2/2 [==============================] - 0s 117ms/step - loss: 0.0865 - accuracy: 0.9833 - val_loss: 0.1135 - val_accuracy: 1.0000\n",
      "Epoch 180/205\n",
      "2/2 [==============================] - 0s 119ms/step - loss: 0.0862 - accuracy: 0.9833 - val_loss: 0.1134 - val_accuracy: 1.0000\n",
      "Epoch 181/205\n",
      "2/2 [==============================] - 0s 118ms/step - loss: 0.0860 - accuracy: 0.9833 - val_loss: 0.1134 - val_accuracy: 1.0000\n",
      "Epoch 182/205\n",
      "2/2 [==============================] - 0s 155ms/step - loss: 0.0858 - accuracy: 0.9833 - val_loss: 0.1133 - val_accuracy: 1.0000\n",
      "Epoch 183/205\n",
      "2/2 [==============================] - 0s 120ms/step - loss: 0.0855 - accuracy: 0.9833 - val_loss: 0.1132 - val_accuracy: 1.0000\n",
      "Epoch 184/205\n",
      "2/2 [==============================] - 0s 118ms/step - loss: 0.0853 - accuracy: 0.9833 - val_loss: 0.1132 - val_accuracy: 1.0000\n",
      "Epoch 185/205\n",
      "2/2 [==============================] - 0s 118ms/step - loss: 0.0851 - accuracy: 0.9833 - val_loss: 0.1131 - val_accuracy: 1.0000\n",
      "Epoch 186/205\n",
      "2/2 [==============================] - 0s 120ms/step - loss: 0.0848 - accuracy: 0.9917 - val_loss: 0.1130 - val_accuracy: 1.0000\n",
      "Epoch 187/205\n",
      "2/2 [==============================] - 0s 119ms/step - loss: 0.0846 - accuracy: 0.9917 - val_loss: 0.1130 - val_accuracy: 1.0000\n",
      "Epoch 188/205\n",
      "2/2 [==============================] - 0s 120ms/step - loss: 0.0844 - accuracy: 0.9917 - val_loss: 0.1129 - val_accuracy: 1.0000\n",
      "Epoch 189/205\n",
      "2/2 [==============================] - 0s 118ms/step - loss: 0.0841 - accuracy: 0.9917 - val_loss: 0.1128 - val_accuracy: 1.0000\n",
      "Epoch 190/205\n",
      "2/2 [==============================] - 0s 119ms/step - loss: 0.0839 - accuracy: 0.9917 - val_loss: 0.1128 - val_accuracy: 1.0000\n",
      "Epoch 191/205\n",
      "2/2 [==============================] - 0s 118ms/step - loss: 0.0837 - accuracy: 0.9917 - val_loss: 0.1127 - val_accuracy: 1.0000\n",
      "Epoch 192/205\n",
      "2/2 [==============================] - 0s 119ms/step - loss: 0.0834 - accuracy: 0.9917 - val_loss: 0.1126 - val_accuracy: 1.0000\n",
      "Epoch 193/205\n",
      "2/2 [==============================] - 0s 133ms/step - loss: 0.0832 - accuracy: 0.9917 - val_loss: 0.1126 - val_accuracy: 1.0000\n",
      "Epoch 194/205\n",
      "2/2 [==============================] - 0s 129ms/step - loss: 0.0830 - accuracy: 0.9917 - val_loss: 0.1125 - val_accuracy: 1.0000\n",
      "Epoch 195/205\n",
      "2/2 [==============================] - 0s 125ms/step - loss: 0.0827 - accuracy: 0.9917 - val_loss: 0.1124 - val_accuracy: 1.0000\n",
      "Epoch 196/205\n",
      "2/2 [==============================] - 0s 116ms/step - loss: 0.0825 - accuracy: 0.9917 - val_loss: 0.1124 - val_accuracy: 1.0000\n",
      "Epoch 197/205\n",
      "2/2 [==============================] - 0s 154ms/step - loss: 0.0823 - accuracy: 0.9917 - val_loss: 0.1123 - val_accuracy: 1.0000\n",
      "Epoch 198/205\n",
      "2/2 [==============================] - 0s 118ms/step - loss: 0.0821 - accuracy: 0.9917 - val_loss: 0.1123 - val_accuracy: 1.0000\n",
      "Epoch 199/205\n",
      "2/2 [==============================] - 0s 118ms/step - loss: 0.0818 - accuracy: 0.9917 - val_loss: 0.1122 - val_accuracy: 1.0000\n",
      "Epoch 200/205\n",
      "2/2 [==============================] - 0s 118ms/step - loss: 0.0816 - accuracy: 0.9917 - val_loss: 0.1121 - val_accuracy: 1.0000\n",
      "Epoch 201/205\n",
      "2/2 [==============================] - 0s 117ms/step - loss: 0.0814 - accuracy: 0.9917 - val_loss: 0.1121 - val_accuracy: 1.0000\n",
      "Epoch 202/205\n",
      "2/2 [==============================] - 0s 155ms/step - loss: 0.0812 - accuracy: 0.9917 - val_loss: 0.1120 - val_accuracy: 1.0000\n",
      "Epoch 203/205\n",
      "2/2 [==============================] - 0s 117ms/step - loss: 0.0809 - accuracy: 0.9917 - val_loss: 0.1119 - val_accuracy: 1.0000\n",
      "Epoch 204/205\n",
      "2/2 [==============================] - 0s 118ms/step - loss: 0.0807 - accuracy: 0.9917 - val_loss: 0.1119 - val_accuracy: 1.0000\n",
      "Epoch 205/205\n",
      "2/2 [==============================] - 0s 116ms/step - loss: 0.0805 - accuracy: 0.9917 - val_loss: 0.1118 - val_accuracy: 1.0000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.3892 - accuracy: 0.9500\n",
      "\n",
      "Fold  1\n",
      "\n",
      "Test accuracy:  0.949999988079071\n",
      "Test loss:  0.3892010748386383\n",
      "\n",
      "Fold  2\n",
      "\n",
      "Training with 120 samples and validating with 20 samples\n",
      "\n",
      "Epoch 1/205\n",
      "2/2 [==============================] - 0s 149ms/step - loss: 0.0856 - accuracy: 0.9917 - val_loss: 0.0770 - val_accuracy: 1.0000\n",
      "Epoch 2/205\n",
      "2/2 [==============================] - 0s 122ms/step - loss: 0.0854 - accuracy: 0.9917 - val_loss: 0.0768 - val_accuracy: 1.0000\n",
      "Epoch 3/205\n",
      "2/2 [==============================] - 0s 118ms/step - loss: 0.0851 - accuracy: 0.9917 - val_loss: 0.0766 - val_accuracy: 1.0000\n",
      "Epoch 4/205\n",
      "2/2 [==============================] - 0s 118ms/step - loss: 0.0848 - accuracy: 0.9917 - val_loss: 0.0765 - val_accuracy: 1.0000\n",
      "Epoch 5/205\n",
      "2/2 [==============================] - 0s 118ms/step - loss: 0.0846 - accuracy: 1.0000 - val_loss: 0.0764 - val_accuracy: 1.0000\n",
      "Epoch 6/205\n",
      "2/2 [==============================] - 0s 118ms/step - loss: 0.0843 - accuracy: 1.0000 - val_loss: 0.0763 - val_accuracy: 1.0000\n",
      "Epoch 7/205\n",
      "2/2 [==============================] - 0s 119ms/step - loss: 0.0840 - accuracy: 1.0000 - val_loss: 0.0762 - val_accuracy: 1.0000\n",
      "Epoch 8/205\n",
      "2/2 [==============================] - 0s 119ms/step - loss: 0.0837 - accuracy: 1.0000 - val_loss: 0.0762 - val_accuracy: 1.0000\n",
      "Epoch 9/205\n",
      "2/2 [==============================] - 0s 117ms/step - loss: 0.0834 - accuracy: 1.0000 - val_loss: 0.0761 - val_accuracy: 1.0000\n",
      "Epoch 10/205\n",
      "2/2 [==============================] - 0s 117ms/step - loss: 0.0831 - accuracy: 1.0000 - val_loss: 0.0761 - val_accuracy: 1.0000\n",
      "Epoch 11/205\n",
      "2/2 [==============================] - 0s 119ms/step - loss: 0.0828 - accuracy: 1.0000 - val_loss: 0.0761 - val_accuracy: 1.0000\n",
      "Epoch 12/205\n",
      "2/2 [==============================] - 0s 118ms/step - loss: 0.0826 - accuracy: 1.0000 - val_loss: 0.0761 - val_accuracy: 1.0000\n",
      "Epoch 13/205\n",
      "2/2 [==============================] - 0s 120ms/step - loss: 0.0823 - accuracy: 1.0000 - val_loss: 0.0762 - val_accuracy: 1.0000\n",
      "Epoch 14/205\n",
      "2/2 [==============================] - 0s 118ms/step - loss: 0.0820 - accuracy: 1.0000 - val_loss: 0.0762 - val_accuracy: 1.0000\n",
      "Epoch 15/205\n",
      "2/2 [==============================] - 0s 118ms/step - loss: 0.0817 - accuracy: 1.0000 - val_loss: 0.0763 - val_accuracy: 1.0000\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00015: early stopping\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.3885 - accuracy: 0.9500\n",
      "\n",
      "Fold  2\n",
      "\n",
      "Test accuracy:  0.949999988079071\n",
      "Test loss:  0.38849392533302307\n",
      "\n",
      "Fold  3\n",
      "\n",
      "Training with 120 samples and validating with 20 samples\n",
      "\n",
      "Epoch 1/205\n",
      "2/2 [==============================] - 0s 148ms/step - loss: 0.0832 - accuracy: 1.0000 - val_loss: 0.0776 - val_accuracy: 1.0000\n",
      "Epoch 2/205\n",
      "2/2 [==============================] - 0s 155ms/step - loss: 0.0829 - accuracy: 1.0000 - val_loss: 0.0776 - val_accuracy: 1.0000\n",
      "Epoch 3/205\n",
      "2/2 [==============================] - 0s 157ms/step - loss: 0.0827 - accuracy: 1.0000 - val_loss: 0.0777 - val_accuracy: 1.0000\n",
      "Epoch 4/205\n",
      "2/2 [==============================] - 0s 118ms/step - loss: 0.0824 - accuracy: 1.0000 - val_loss: 0.0778 - val_accuracy: 1.0000\n",
      "Epoch 5/205\n",
      "2/2 [==============================] - 0s 130ms/step - loss: 0.0821 - accuracy: 1.0000 - val_loss: 0.0779 - val_accuracy: 1.0000\n",
      "Epoch 6/205\n",
      "2/2 [==============================] - 0s 137ms/step - loss: 0.0818 - accuracy: 1.0000 - val_loss: 0.0781 - val_accuracy: 1.0000\n",
      "Epoch 7/205\n",
      "2/2 [==============================] - 0s 167ms/step - loss: 0.0816 - accuracy: 1.0000 - val_loss: 0.0783 - val_accuracy: 1.0000\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00007: early stopping\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.3884 - accuracy: 0.9500\n",
      "\n",
      "Fold  3\n",
      "\n",
      "Test accuracy:  0.949999988079071\n",
      "Test loss:  0.3884272277355194\n",
      "\n",
      "Fold  4\n",
      "\n",
      "Training with 120 samples and validating with 20 samples\n",
      "\n",
      "Epoch 1/205\n",
      "2/2 [==============================] - 0s 187ms/step - loss: 0.0826 - accuracy: 1.0000 - val_loss: 0.0835 - val_accuracy: 1.0000\n",
      "Epoch 2/205\n",
      "2/2 [==============================] - 0s 135ms/step - loss: 0.0824 - accuracy: 1.0000 - val_loss: 0.0835 - val_accuracy: 1.0000\n",
      "Epoch 3/205\n",
      "2/2 [==============================] - 0s 122ms/step - loss: 0.0821 - accuracy: 1.0000 - val_loss: 0.0836 - val_accuracy: 1.0000\n",
      "Epoch 4/205\n",
      "2/2 [==============================] - 0s 124ms/step - loss: 0.0818 - accuracy: 1.0000 - val_loss: 0.0838 - val_accuracy: 1.0000\n",
      "Epoch 5/205\n",
      "2/2 [==============================] - 0s 123ms/step - loss: 0.0815 - accuracy: 1.0000 - val_loss: 0.0840 - val_accuracy: 1.0000\n",
      "Epoch 6/205\n",
      "2/2 [==============================] - 0s 119ms/step - loss: 0.0813 - accuracy: 1.0000 - val_loss: 0.0842 - val_accuracy: 1.0000\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00006: early stopping\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.3884 - accuracy: 0.9500\n",
      "\n",
      "Fold  4\n",
      "\n",
      "Test accuracy:  0.949999988079071\n",
      "Test loss:  0.3884214460849762\n",
      "\n",
      "Fold  5\n",
      "\n",
      "Training with 120 samples and validating with 20 samples\n",
      "\n",
      "Epoch 1/205\n",
      "2/2 [==============================] - 0s 183ms/step - loss: 0.0827 - accuracy: 1.0000 - val_loss: 0.0741 - val_accuracy: 1.0000\n",
      "Epoch 2/205\n",
      "2/2 [==============================] - 0s 119ms/step - loss: 0.0824 - accuracy: 1.0000 - val_loss: 0.0743 - val_accuracy: 1.0000\n",
      "Epoch 3/205\n",
      "2/2 [==============================] - 0s 154ms/step - loss: 0.0821 - accuracy: 1.0000 - val_loss: 0.0745 - val_accuracy: 1.0000\n",
      "Epoch 4/205\n",
      "2/2 [==============================] - 0s 118ms/step - loss: 0.0818 - accuracy: 1.0000 - val_loss: 0.0747 - val_accuracy: 1.0000\n",
      "Epoch 5/205\n",
      "2/2 [==============================] - 0s 119ms/step - loss: 0.0815 - accuracy: 1.0000 - val_loss: 0.0749 - val_accuracy: 1.0000\n",
      "Epoch 6/205\n",
      "2/2 [==============================] - 0s 118ms/step - loss: 0.0813 - accuracy: 1.0000 - val_loss: 0.0751 - val_accuracy: 1.0000\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00006: early stopping\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.3885 - accuracy: 0.9500\n",
      "\n",
      "Fold  5\n",
      "\n",
      "Test accuracy:  0.949999988079071\n",
      "Test loss:  0.3884642422199249\n",
      "\n",
      "Fold  6\n",
      "\n",
      "Training with 120 samples and validating with 20 samples\n",
      "\n",
      "Epoch 1/205\n",
      "2/2 [==============================] - 0s 144ms/step - loss: 0.0808 - accuracy: 1.0000 - val_loss: 0.0659 - val_accuracy: 1.0000\n",
      "Epoch 2/205\n",
      "2/2 [==============================] - 0s 117ms/step - loss: 0.0806 - accuracy: 1.0000 - val_loss: 0.0658 - val_accuracy: 1.0000\n",
      "Epoch 3/205\n",
      "2/2 [==============================] - 0s 118ms/step - loss: 0.0804 - accuracy: 1.0000 - val_loss: 0.0658 - val_accuracy: 1.0000\n",
      "Epoch 4/205\n",
      "2/2 [==============================] - 0s 119ms/step - loss: 0.0801 - accuracy: 1.0000 - val_loss: 0.0658 - val_accuracy: 1.0000\n",
      "Epoch 5/205\n",
      "2/2 [==============================] - 0s 118ms/step - loss: 0.0799 - accuracy: 1.0000 - val_loss: 0.0658 - val_accuracy: 1.0000\n",
      "Epoch 6/205\n",
      "2/2 [==============================] - 0s 118ms/step - loss: 0.0796 - accuracy: 1.0000 - val_loss: 0.0659 - val_accuracy: 1.0000\n",
      "Epoch 7/205\n",
      "2/2 [==============================] - 0s 118ms/step - loss: 0.0793 - accuracy: 1.0000 - val_loss: 0.0659 - val_accuracy: 1.0000\n",
      "Epoch 8/205\n",
      "2/2 [==============================] - 0s 117ms/step - loss: 0.0790 - accuracy: 1.0000 - val_loss: 0.0660 - val_accuracy: 1.0000\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00008: early stopping\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.3885 - accuracy: 0.9500\n",
      "\n",
      "Fold  6\n",
      "\n",
      "Test accuracy:  0.949999988079071\n",
      "Test loss:  0.3885282278060913\n",
      "\n",
      "K-Fold accuracy:  [0.949999988079071, 0.949999988079071, 0.949999988079071, 0.949999988079071, 0.949999988079071, 0.949999988079071, 0.949999988079071]\n",
      "\n",
      "Average accuracy:  0.949999988079071\n",
      "K-Fold Standard deviation:  0.0\n",
      "\n",
      "Classification report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       sober       1.00      0.80      0.89         5\n",
      "       drunk       0.94      1.00      0.97        15\n",
      "\n",
      "    accuracy                           0.95        20\n",
      "   macro avg       0.97      0.90      0.93        20\n",
      "weighted avg       0.95      0.95      0.95        20\n",
      "\n",
      "\n",
      "AUC ROC: \n",
      "0.8800000000000001\n",
      "\n",
      "Confusion Matrix: \n",
      "[[ 4  1]\n",
      " [ 0 15]]\n",
      "\n",
      "True Negatives:  4\n",
      "False Positives:  1\n",
      "False Negatives:  0\n",
      "True Positives:  15\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEWCAYAAAB8LwAVAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAAsTAAALEwEAmpwYAAAoXklEQVR4nO3de5xcdX3/8dd7d5NNSMIlFygkkIBQIPyMhF9EEZUA2gJeIqhIShWK/SFU+lNbiqBWEbVqRUuptBUrYryQH0WxWMGAQASLF4KEaMBAwAAJEEIwCUg22cvn98f5zmYyzMxuyJ49u3vez8djHztzLjPf75yZ7+d8v59zUURgZmZWq6XoApiZ2dDkAGFmZnU5QJiZWV0OEGZmVpcDhJmZ1eUAYWZmdTlAjDCSZkgKSW39WPZMST8djHINdZKukfS2ossxkCRdLOlb6fF+kp6X1NrXsi/xvZZLmvtS12/yuosl/WWDeU3rNFgkzZJ0V5FlyIsDRIEkrZK0VdLkmun3pkZ+RkFFKxVJs4BXAP9VdFnyEhGPRcT4iOje2deSdLWkT9e8/mERsXhnX3tH9LdOee8IRcQyYIOkt+T1HkVxgCje74D5lSeSXg7sUlxxhob+9IAG0PuAb8cOnjU6yGW0gvRzO3+b7Hs0ojhAFO+bwHuqnp8BLKheQNJukhZIWifpUUkfk9SS5rVKulTSM5IeAd5UZ92vSXpS0hpJn+5vl1zSf0p6StJGSXdIOqxq3lhJX0zl2Sjpp5LGpnmvlXSXpA2SHpd0Zpq+3XBB7Z5d6jW9X9JDwENp2j+n19gk6R5Jr6tavlXSRyQ9LOm5NH9fSVdI+mJNXW6Q9KEGVT0R+EnN8v9H0gPpde+XdESavkrShyUtA/4gqU3SW9MQy4ZUx0OrXufD6XN/TtIKScen6UdKWpLqtVbSlxpsg5sknVcz7T5Jp/T1+dSss93Qo6T9Jf0klesWoLYXW3fbSzobOB24QNnwzg+qPpc3pMftki6T9ET6u0xSe5o3V9JqSX8r6en0vfyLBtulYrqk/0llvVmpx12nTmdKeiQt9ztJp6dt8e/AUam8G9KyzX5TZ6b3+ydJ64FLJD2rbOet8vnsKekFSVPSpMXA8ZV6jhgR4b+C/oBVwBuAFcChQCuwGpgOBDAjLbeAbPhjAjADeBB4b5p3DvBbYF9gInB7Wrctzb8e+AowDtgT+CXwvjTvTOCnTcp3VnrPduAyYGnVvCvIfhRTU7lfk5abDjxH1isaBUwCDk/rLAb+suo1tnv/VO5bUj3Gpml/nl6jDfhb4ClgTJr3d8CvgYMBkQ0TTQKOBJ4AWtJyk4EXgL3q1HFcet8pVdPeCawBXple90BgetU2W5o+77HAHwN/AN6Y6nsBsBIYncr1OLBPWncG8LL0+GfAu9Pj8cCrG2yD9wD/U/V8JrABaO/H53Mx8K2q967+XvwM+FLaZq9P2+xb/dz2VwOfrvddTo8vAX5O9n2bAtwFfCrNmwt0pWVGASelbbNHg/ovBh5On/PY9PxztXVK23ETcHCatzdwWKPvOc1/U2emMv51eu2xwL8Cn69a/wPAD2pecxMwq+h2ZUDbqKILUOY/tgWIjwGfBU4gayDb0hd/BlnjuxWYWbXe+4DF6fFtwDlV8/6k6kezF7CF1Nim+fOB29PjF/1wmpR19/S6u5H1PDcDr6iz3EXA9Q1eYzF9B4jj+ijH7yvvSxZY5zVY7gHgjenxecCNDZabmt53TNW0RcAHmmyzs6qe/z1wbdXzFrLgMpcssDydtvGomte5A/gkMLmP+k4gC0DT0/PPAFf18/O5mDoBAtgvNYDjqtb7DlUBotG2T8+vpnmAeBg4qWrenwKr0uO56bvTVjX/aRoHyMXAx6qe/xXwozp1GkcWON9O1fe9wfesr9/UmcBjNa/xKuAxQOn5EuDUmmXWAK/vz+9puPx5iGlo+CbwZ2RfzAU18yaT7Wk9WjXtUbKGDWAfsr3U6nkV09O6T6bhjw1kvYk9+ypQGr75XBq+2UTWAFTKMxkYQ9YQ1Nq3wfT+qq4Lks5PQz0bU/l3Y9twSLP3+gbZ3jXp/zcbLLch/Z9QNa2vOlSXcR+qPvOI6Enzp0bESuCDZA3105IWStonLfpesr3i30q6W9KbAST9exoKeV7SRyLiOeCHwGlpvflk492k5Zt9Po3sA/w+Iv5QNa23Dn1s+/7Y7jNJj/eper4+Irqqnr9A1otq5Km+lk11eRdZj/pJST+UdEiD1+vrNwU138OI+EV677npdQ8Ebqh53Qls+z6NCA4QQ0BEPEqWrD4J+F7N7GeATrLGvmI/sr0VgCfJGrTqeRWPk/UgJkfE7ulv14g4jL79GTCPbO93N7K9NciGXJ4BOoCX1Vnv8QbTIdsTrk7A/1GdZXoTxWk8/QLgVLIhiN2BjakMfb3Xt4B5kl5BNnz3/XoLpYalMoTRnzpsV0ayoazebSNJZNtjTXr970TEa9k2bPj5NP2hiJhPFqw/D1wnaVxEnBPZkTnjI+If0steA8yXdBRZYL49vVdfn08jTwJ7SBpXNa36e9Ns29fWv57tPpP02k/0sc5Oi4hFEfFGsuGl3wJfrcyqWbSv31S9dWDbTse7gesioqMyQ9JUsmHFFTtTh6HGAWLoeC/Z8Er1Xh2RHcJ3LfAZSRMkTQf+hqwBJM37v5KmSdoDuLBq3SeBm4EvStpVUoukl0k6ph/lmUAWXNaTNeqVxqqyl3wV8CVJ+6Q9zqNSgu7bwBsknaosgTtJ0uFp1aXAKZJ2kXRgqnNfZegC1gFtkj4O7Fo1/z+AT0k6SJlZkialMq4G7ibrOXw3IjY3eZ8bgerP5D+A8yX97/S6B6bPvZ5rgTdJOl7SKLI8wBbgLkkHSzoufS4dZEMrPQCS/lzSlPRZbkiv1dOkfNPJxu3/X1qnP59PXWmHZAnwSUmjJb0WqD5Es+G2T9YCBzR5i2uAj0makhLKH2fb9zUXkvaSNC8FvS3A82z7PNcC0ySNhn79phr5FnAyWZCo7ekfA9wWEVsGpEJDhAPEEBERD0fEkgaz/5ps7/sR4Kdk48VXpXlfJRszvw/4FS/ugbyHbM/mfrLx6evI9rD6soCs270mrfvzmvnnkyWI7waeJdsLbomIx8h6Qn+bpi8lSx4D/BPZ2O9asr2xb9PcIuBHZAnER8ka2equ/5fIfug3kyUIv0aWUKz4BvByGg8vVVwJnJ72/omI/yQb6/8OWfL2+2SJ8xeJiBVkDca/kO2ZvgV4S0RsJUvwfi5Nf4qst3BRWvUEYLmk54F/Bk5rFMRSo/M9sj3671TN6uvzaebPyMbVnwU+wfYNXl/b/mvAzDRs+f06r/1psgC0jOw78qs0LU8tZI38E2R1OgY4N827DVgOPCXpmTSt2W+qroh4nKwuAdxZM/t0sqOlRpRKwsVsxJH0erK9vunRxxdd0nfIks3fH4yy2fAk6SrgiYj4WNW0WcBXIuKo4kqWDwcIG5HScM9C4L6IuKTo8tjwp+zKBkuB2RHxu2JLMzg8xGQjTjo5agPZUNplhRbGRgRJnwJ+A3yhLMEB3IMwM7MG3IMwM7O6RszFxiZPnhwzZswouhhmZsPKPffc80xETKk3b8QEiBkzZrBkSaOjRM3MrB5Jjzaa5yEmMzOrywHCzMzqcoAwM7O6RkwOwsxsR3V2drJ69Wo6Ojr6XniYGzNmDNOmTWPUqFH9XscBwsxKa/Xq1UyYMIEZM2aQLsU1IkUE69evZ/Xq1ey///79Xi+3ISZJVym7peBvGsyXpMslrZS0TOmWjmneGZIeSn9n5FVGMyu3jo4OJk2aNKKDA4AkJk2atMM9pTxzEFeTXbGykROBg9Lf2cC/AUiaSHZ1yVeR3TryE+ky1mZmA26kB4eKl1LP3IaYIuKOdHGrRuYBC9JVNn8uaXdJe5PdkvCWiHgWQNkN1U8gu8b84Ft5KzxWe7VjMxsR9jgeNj3Z+7Q7go6t3X3eEWnIaR3F+In17r+1c4rMQUxl+2vXr07TGk1/EUlnk/U+2G+//eotsvMWfRTWPUDfN+kys2HnT+fA89vuaNoC7DKI0WH97zfwhnedA8BT69bT2tLClEnZgMkv/vubjB7dOKG85L77WXDdf3P5py5gi8ZQ/waNO2dYJ6kj4kqym70wZ86cfDZrTyccdgq88+u5vLyZFeiBB2CfQ3ufPvNcB09u7OCwfXajtSX/ncLJU2Hp8uwupRdffDHjx4/n/PPP753f1dVFW1v9ZvqVU2fzypNOB7L70OahyPMg1rD9vZSnpWmNphcjAuTTRczKoCftZg5CbGjozDPP5JxzzuFVr3oVF1xwAb/85S856qijmD17Nq95zWtYsSILKIsXL+bNb34zkAWXs846i7lz53LAAQdw+eWXD0hZiuxB3ACcJ2khWUJ6Y0Q8KWkR8A9Viek/YdttGgdf9EBJklhmZfbJHyxn6eMb6OzuYdzogWkaZ+6zK594y2E7vN7q1au56667aG1tZdOmTdx55520tbXx4x//mI985CN897vffdE6v/3tb7n99tt57rnnOPjggzn33HN36JyHenILEJKuIUs4T5a0muzIpFEAEfHvZDdiPwlYCbwA/EWa92y6Ocfd6aUuqSSsi+EehFlpxNDINr7zne+ktbUVgI0bN3LGGWfw0EMPIYnOzs6667zpTW+ivb2d9vZ29txzT9auXcu0adN2qhx5HsU0v4/5Aby/wbyr6OMG4oMmehgaXxkzy9Mn3nIYq3//Aps6upi5966FlmXcuHG9j//+7/+eY489luuvv55Vq1Yxd+7cuuu0t7f3Pm5tbaWrq2uny+Fd4744B2FWGj1RbP6hno0bNzJ1anYg59VXXz2o7+2Wry8RzkGYlURE0DLEfu8XXHABF110EbNnzx6QXsGOGDH3pJ4zZ07kcsOgLx4KBx4H864Y+Nc2s0I98MADHHrotsNcf/fMH+ju6eHAPScUWKr81NYXQNI9ETGn3vLuQfTJQ0xmZdETUZpLb/SHW76+OEltVhoRDLkhpiI5QPTFSWqz0uiJGHJJ6iK55euLT5QzKw0PMW3PAaJP7kGYlUWEG8Vq/iz64hyEWWn0RNDiMaZeDhB9iR73IMxKomeQT3s69thjWbRo0XbTLrvsMs4999y6y8+dO5dcDudvwC1fXwIHCLMSiIhBP1Fu/vz5LFy4cLtpCxcuZP78plcqGjRu+friJLVZKVQu9T2YP/d3vOMd/PCHP2Tr1q0ArFq1iieeeIJrrrmGOXPmcNhhh/GJT3xi8ApUY1jfMGhwOEltVgb60YUc8NhS2ttaoHWAfvN/9HI48XMNZ0+cOJEjjzySm266iXnz5rFw4UJOPfVUPvKRjzBx4kS6u7s5/vjjWbZsGbNmzRqYMu0At3x9iZ6iS2Bmg6D3okODPGBQPcxUGV669tprOeKII5g9ezbLly/n/vvvH9xCJe5B9MUnypmVQucb/4FH1j7HfhN3YfddRg/a+86bN48PfehD/OpXv+KFF15g4sSJXHrppdx9993ssccenHnmmXR0dAxaeaq55euLcxBmpVC5cOlgnyg3fvx4jj32WM466yzmz5/Ppk2bGDduHLvtthtr167lpptuGtTyVHMPoi8+zNWsFIq8H/X8+fM5+eSTWbhwIYcccgizZ8/mkEMOYd999+Xoo48e/AIlDhB9CnyinNnIV1QPAuBtb3sb1bdeaHRjoMWLFw9OgRLvGvfFPQizUiiyBzFUueXri5PUZqXQk/bgfbnvbdzy9cm3HDUbySpDO0WcKDeYXsrdQx0gmql8oO5BmI1IY8aMYf369b2X2YCR2YOICNavX8+YMWN2aD0nqZvpPUlu5H1hzAymTZvG6tWrWbduHc91dLFxcyetm8aMyCAxZswYpk2btkPrOEA04x6E2Yg2atQo9t9/fwC+fNtDXHrzYzz46RMZ3ebfPHiIqblKD2Lk7UyYWY3Nnd20tohRrf7BVzhANNMbIPwxmY10HZ09jGlr8S1Hq3iIqSkPMZkV5ennOvjanb9ja/fgXDDzZw+vZ8yo1kF5r+HCAaIZJ6nNCnPL/Wv5yh2PML69bdAOPX3tgZMH542GCQeIZpykNivM5q3dANx10XHsOmZUwaUpJ7d8zfTmINyDMBtslQAx1sM+hXGAaMo9CLOidHRVjiry768ouX7ykk6QtELSSkkX1pk/XdKtkpZJWixpWtW8z0v6Tfp7V57lbMg5CLPCdHT2uPdQsNwChKRW4ArgRGAmMF/SzJrFLgUWRMQs4BLgs2ndNwFHAIcDrwLOl7RrXmVtyDkIs8Js7uxmzCj/9oqU56d/JLAyIh6JiK3AQmBezTIzgdvS49ur5s8E7oiIroj4A7AMOCHHstbnAGFWmI7Obtrb3IMoUp4t31Tg8arnq9O0avcBp6THJwMTJE1K00+QtIukycCxwL61byDpbElLJC1Zt27dgFfASWqz4nR0djN2tANEkYreNT4fOEbSvcAxwBqgOyJuBm4E7gKuAX4GdNeuHBFXRsSciJgzZcqUHIo3wq//azaEdXT2eIipYHl++mvYfq9/WprWKyKeiIhTImI28NE0bUP6/5mIODwi3kiWJX4wx7LW5yS1WWE6OrsZ4yGmQuUZIO4GDpK0v6TRwGnADdULSJos9Q7wXwRclaa3pqEmJM0CZgE351jW+pyDMCvMZg8xFS63M6kjokvSecAioBW4KiKWS7oEWBIRNwBzgc9KCuAO4P1p9VHAnemiWZuAP4+IrrzK2pBzEGaF6ejsYdI4B4gi5XqpjYi4kSyXUD3t41WPrwOuq7NeB9mRTMXy1VzNCrPFPYjCueVrqnIPV/cgzAbb5s5uxvjGPYXyp9+MexBmheno7Pbltwvmlq8ZJ6nNCuMkdfHc8jXjJLVZISKi9w5vVhx/+v3hHoTZoNrSle2ctXuIqVBu+ZrxiXJmhejo9L0ghgIHiGbCl9owK0JHZ7Zz5iR1sRwgmnEOwqwQvT2I0W6iiuRPvxkf5mpWiM0pQPhaTMVyy9eUD3M1K0KlB+EhpmK55WvGSWqzQmx2gBgSHCCa8YlyZoXY0puk9m+vSP70m3GS2qwQHmIaGhwgmnIPwqwIm30exJDglq8Z5yDMCuHzIIYGB4hmnIMwK4TPpB4a3PI14zOpzQpRGWJqd5K6UP70m3GS2qwQWzq7kaDdV3MtlD/9pjzEZFaE7G5yrcg7Z4XK9Z7Uw9UftnTxhUUr2HvjQ7wPGMgk9YYXtvKlWx5k89buAXtNs5Hm3sc3+ByIIcABoo57H9vA1Xet4kit5X3tDGgP4uePPMuCnz3K5PHtjG713pFZI8cevGfRRSg9B4g6KgmyFg18krpydMa173s1B0wZP2Cva2Y20NyHq6PSiCuHHITPEDWz4cIBoo7NtQFiAHMQPkPUzIYLB4g6tlSGmHLpQfgMUTMbHhwg6qg04nkMMfWeAOTju81siHMrVUelEd+lcpjdACapt3R2097WQkuLj2Ays6HNAaKOjs5u2lpEe2UUaICT1B5eMrPhwAGijo7OHsaOamXbKNDAJqmdoDaz4cABoo7Nnd20j2ql9zy2AT0PosdniJrZsJBrSyXpBEkrJK2UdGGd+dMl3SppmaTFkqZVzftHScslPSDpcg3iRVm2dHYzZlQLve34AL71Zg8xmdkwkVuAkNQKXAGcCMwE5kuaWbPYpcCCiJgFXAJ8Nq37GuBoYBbwv4BXAsfkVdZalWGg3iEm5yDMrITy7EEcCayMiEciYiuwEJhXs8xM4Lb0+Paq+QGMAUYD7cAoYG2OZd1OpRFv6x1iGriPaYuHmMxsmMizpZoKPF71fHWaVu0+4JT0+GRggqRJEfEzsoDxZPpbFBEP1L6BpLMlLZG0ZN26dQNW8EqeoK0lnzOpnaQ2s+Gg6F3Z84FjJN1LNoS0BuiWdCBwKDCNLKgcJ+l1tStHxJURMSci5kyZMmXAClXJE7RWzlXwEJOZlVCeAWINsG/V82lpWq+IeCIiTomI2cBH07QNZL2Jn0fE8xHxPHATcFSOZd1OpREflcPVXN2DMLPhIs8AcTdwkKT9JY0GTgNuqF5A0mSpd/f8IuCq9Pgxsp5Fm6RRZL2LFw0x5WVLV3YeRGsuSeoe2h0gzGwYyC1AREQXcB6wiKxxvzYilku6RNJb02JzgRWSHgT2Aj6Tpl8HPAz8mixPcV9E/CCvstbavDU7zLU3ST2AOYjKIbRmZkNdrjcMiogbgRtrpn286vF1ZMGgdr1uSHf7LEBHV+Uopnwu1uchJjMbDrwrW8fmrd01Q0wD04Po7O6hqyecpDazYcEBokZEsKUryxO0DfClNjp8syAzG0YcIGps6arc0KdlwJPU224W5I/dzIY+t1Q1Nm/dtpffm4MYoCR1pQfho5jMbDhwgKjR0ZU14mO2u5rrQPUgPMRkZsOHA0SNyjDQ2Bwu9+37UZvZcNKvACFpXOWENkl/LOmt6QS2EacyxJRHDmKzexBmNoz0t+W7AxgjaSpwM/Bu4Oq8ClWkyhBTe445CCepzWw46G9LpYh4gezKq/8aEe8EDsuvWMXpqJekHuAchIeYzGw46HeAkHQUcDrwwzRtRLZy1UnqlgFOUm92gDCzYaS/Ld8HyS6md326ntIBZPdrGHGqz1Wo9CCi2Qo7YIvPgzCzYaRf12KKiJ8APwFIyepnIuL/5lmwolSfB1HpQXSHBuSiVU5Sm9lw0t+jmL4jaVdJ44DfAPdL+rt8i1aM7c+DyPoOXQPUhXAOwsyGk/7uGM+MiE2STie7ec+FwD3AF3Ir2SDZ1NHJh69b1vt81foXgBQgUvjsiu2PYrp00QoeXvf8Dr/Xyqef731tM7Ohrr8BYlQ67+FtwJcjolPSQA3NF6qnJ17U2B9/yJ5MaG/rzcJ39Wyr6tauHr58+0omjx/NxHGjd+i9JHjTrL233crUzGwI62+A+AqwiuzmPXdImg5syqtQg2n3XUZz84eOqTuvkqTurupBVIagzjnmZfzl6w7Iv4BmZgXpb5L6cuDyqkmPSjo2nyINHZUd/RQTgG3nSXiYyMxGuv4mqXeT9CVJS9LfF4FxOZetcJUkdWfVEJOvp2RmZdHfA/KvAp4DTk1/m4Cv51WooaK1zhCTD1U1s7Lobw7iZRHx9qrnn5S0NIfyDCmVIabOqO5B+HpKZlYO/W3lNkt6beWJpKOBzfkUaeioXO67s7sqSe1zGcysJPrbgzgHWCBpt/T898AZ+RRp6GihMsS0bZqvp2RmZdHfo5juA14hadf0fJOkDwLLmq44zG1LUm+b5vtKm1lZ7FArFxGbIqJy/sPf5FCeIaWlcqmNqgCxpcs9CDMrh53ZDR7xpwNXQkD1Ya7VF/MzMxvJdiZAjIhLbTTToqA7RHdPvaOYHCDMbGRrmoOQ9Bz1A4GAsbmUaAhpIQhEV1WWuiONN7kHYWYjXdMAERETBqsgQ1FrC/QgOru3JSEqQ0ztbU5Sm9nI5lauCaUexHZDTF3djG5rocVXZDWzEc4BoolWZQFiu2sxbe328JKZlYIDRBPbchDbhpg6Ont8DoSZlUKuLZ2kEyStkLRS0oV15k+XdKukZZIWS5qWph8raWnVX4ekt+VZ1npaCHrQdjcM6ujq9hFMZlYKuQUISa3AFcCJwExgvqSZNYtdCiyIiFnAJcBnASLi9og4PCIOB44DXgBuzqusjbQIemjZ7iimzR5iMrOSyLMHcSSwMiIeiYitwEJgXs0yM4Hb0uPb68wHeAdwU0S8kFtJG8iGmKCrp2qIqauHdgcIMyuBPAPEVODxquer07Rq9wGnpMcnAxMkTapZ5jTgmnpvIOnsyk2M1q1bNwBF3l5LJUndvf2JcmOdgzCzEii6pTsfOEbSvcAxwBqg9wafkvYGXg4sqrdyRFwZEXMiYs6UKVMGvHDbDnOtTlI7B2Fm5dDfy32/FGuAfaueT0vTekXEE6QehKTxwNsjYkPVIqcC10dEZ47lbKiFyoly2/cgxrQ5QJjZyJdnD+Ju4CBJ+0saTTZUdEP1ApImS6qU4SKyW5tWm0+D4aXBUBli2i5J3dnN2NEOEGY28uUWICKiCziPbHjoAeDaiFgu6RJJb02LzQVWSHoQ2Av4TGV9STPIeiA/yauMfVH00POiISafB2Fm5ZDnEBMRcSNwY820j1c9vg64rsG6q3hxUntQiYDaM6k7u2n3EJOZlYB3hZuJHoKWmjOpPcRkZuXgANFMpBxE6kF09wSd3eEktZmVggNEMxGEtiWpKzcLGjvaH5uZjXxu6Zqq9CCyIabNvpucmZWIA0Qz0QNV50H03m7UQ0xmVgIOEM1EEGrpvWFQb4BwktrMSiDXw1yHvdSDuPOhZ3j3137BH7Z0ATDGtxs1sxJwgGgmetilfRT77jqW51NwOPrAScyatnux5TIzGwQOEE0Fu49r5/q/OrrogpiZDTqPlTSThpjMzMrIAaKZCJA/IjMrJ7d+zUQPyD0IMysnB4im3IMws/Jy69dMZFdzNTMrIweIZqLHPQgzKy23fs1EuANhZqXlANGMexBmVmJu/ZpyktrMysutXzM+Uc7MSswBohmfKGdmJebWrxmfKGdmJeYA0ZR7EGZWXm79mnEOwsxKzAGiGecgzKzE3Po14wBhZiXm1q8ZJ6nNrMQcIJoKBwgzKy0HiGacpDazEnOAaMY5CDMrMbd+zTgHYWYllmuAkHSCpBWSVkq6sM786ZJulbRM0mJJ06rm7SfpZkkPSLpf0ow8y1qXr+ZqZiWWW+snqRW4AjgRmAnMlzSzZrFLgQURMQu4BPhs1bwFwBci4lDgSODpvMramO8oZ2bllefu8ZHAyoh4JCK2AguBeTXLzARuS49vr8xPgaQtIm4BiIjnI+KFHMtan3sQZlZiebZ+U4HHq56vTtOq3Qeckh6fDEyQNAn4Y2CDpO9JulfSF1KPZDuSzpa0RNKSdevWDXwNnKQ2sxIruvU7HzhG0r3AMcAaoBtoA16X5r8SOAA4s3bliLgyIuZExJwpU6YMfOnC50GYWXnlGSDWAPtWPZ+WpvWKiCci4pSImA18NE3bQNbbWJqGp7qA7wNH5FjWBtyDMLPyyrP1uxs4SNL+kkYDpwE3VC8gabLU2wJfBFxVte7ukirdguOA+3Msa33RM+hvaWY2VOQWINKe/3nAIuAB4NqIWC7pEklvTYvNBVZIehDYC/hMWrebbHjpVkm/JjuU6Kt5lbUh5yDMrMTa8nzxiLgRuLFm2serHl8HXNdg3VuAWXmWr08+Uc7MSsy7x834MFczKzG3fk15iMnMysutXzO+mquZlZgDRDNOUptZibn1a8ZJajMrMQeIptyDMLPycuvXTPhqrmZWXg4QzfgwVzMrMbd+zfhifWZWYg4QzThJbWYl5gDRlJPUZlZebv2a8YlyZlZiDhDN+EQ5Mysxt37NOAdhZiXmANGMD3M1sxJz69eUT5Qzs/JygGjGOQgzKzG3fs04QJhZibn1a8ZJajMrMQeIpnypDTMrLweIZnyinJmVmANEM85BmFmJufVrxjkIMysxB4hmfKKcmZWYW7+mPMRkZuXl1q8ZJ6nNrMQcIBqJyP67B2FmJeXWr5HeAOEehJmVkwNEQ+5BmFm5ufVrJHrSA/cgzKycHCAaqQQIDzGZWUnlGiAknSBphaSVki6sM3+6pFslLZO0WNK0qnndkpamvxvyLGddzkGYWcm15fXCklqBK4A3AquBuyXdEBH3Vy12KbAgIr4h6Tjgs8C707zNEXF4XuXrU28Pwp0sMyun3AIEcCSwMiIeAZC0EJgHVAeImcDfpMe3A9/PsTz1vfAsfP3EF093DsLMSi7PADEVeLzq+WrgVTXL3AecAvwzcDIwQdKkiFgPjJG0BOgCPhcR3699A0lnA2cD7Lfffi+tlC2tMOXg+vP+6OVwcJ3gYWZWAnkGiP44H/iypDOBO4A1QHeaNz0i1kg6ALhN0q8j4uHqlSPiSuBKgDlz5sRLKsGY3eDUBS+x+GZmI1eeAWINsG/V82lpWq+IeIKsB4Gk8cDbI2JDmrcm/X9E0mJgNrBdgDAzs/zkmYG9GzhI0v6SRgOnAdsdjSRpstSbBb4IuCpN30NSe2UZ4Gi2z12YmVnOcgsQEdEFnAcsAh4Aro2I5ZIukfTWtNhcYIWkB4G9gM+k6YcCSyTdR5a8/lzN0U9mZpYzRby0ofuhZs6cObFkyZKii2FmNqxIuici5tSb54P8zcysLgcIMzOrywHCzMzqcoAwM7O6RkySWtI64NGdeInJwDMDVJzhwPUd+cpW57LVFwamztMjYkq9GSMmQOwsSUsaZfJHItd35CtbnctWX8i/zh5iMjOzuhwgzMysLgeIba4sugCDzPUd+cpW57LVF3Kus3MQZmZWl3sQZmZWlwOEmZnVVfoAIekESSskrZR0YdHlyYukVZJ+LWlpulMfkiZKukXSQ+n/HkWX86WSdJWkpyX9pmpa3fopc3na5sskHVFcyV+aBvW9WNKatI2XSjqpat5Fqb4rJP1pMaXeOZL2lXS7pPslLZf0gTR9RG7nJvUdvO0cEaX9A1rJbkJ0ADCa7BaoM4suV051XQVMrpn2j8CF6fGFwOeLLudO1O/1wBHAb/qqH3AScBPZDcdfDfyi6PIPUH0vBs6vs+zM9N1uB/ZP3/nWouvwEuq8N3BEejwBeDDVbURu5yb1HbTtXPYexJHAyoh4JCK2AguBeQWXaTDNA76RHn8DeFtxRdk5EXEH8GzN5Eb1mwcsiMzPgd0l7T0oBR0gDerbyDxgYURsiYjfASvJvvvDSkQ8GRG/So+fI7vPzFRG6HZuUt9GBnw7lz1ATAUer3q+muYbYDgL4GZJ90g6O03bKyKeTI+fIrtp00jSqH4jebufl4ZTrqoaMhxx9ZU0g+w2xL+gBNu5pr4wSNu57AGiTF4bEUcAJwLvl/T66pmR9VFH7DHPI71+yb8BLwMOB54EvlhoaXKS7l//XeCDEbGpet5I3M516jto27nsAWINsG/V82lp2ogTEWvS/6eB68m6nmsrXe70/+niSpiLRvUbkds9ItZGRHdE9ABfZdvwwoipr6RRZI3ltyPie2nyiN3O9eo7mNu57AHibuAgSftLGg2cBtxQcJkGnKRxkiZUHgN/AvyGrK5npMXOAP6rmBLmplH9bgDek45yeTWwsWqIYtiqGV8/mWwbQ1bf0yS1S9ofOAj45WCXb2dJEvA14IGI+FLVrBG5nRvVd1C3c9GZ+qL/yI50eJAs4//RosuTUx0PIDu64T5geaWewCTgVuAh4MfAxKLLuhN1vIasu91JNvb63kb1Izuq5Yq0zX8NzCm6/ANU32+m+ixLjcXeVct/NNV3BXBi0eV/iXV+Ldnw0TJgafo7aaRu5yb1HbTt7EttmJlZXWUfYjIzswYcIMzMrC4HCDMzq8sBwszM6nKAMDOzuhwgzHaApO6qq2guHcgrAEuaUX11VrOitRVdALNhZnNEHF50IcwGg3sQZgMg3W/jH9M9N34p6cA0fYak29KF1W6VtF+avpek6yXdl/5ek16qVdJX0/X/b5Y0trBKWek5QJjtmLE1Q0zvqpq3MSJeDnwZuCxN+xfgGxExC/g2cHmafjnwk4h4Bdl9HZan6QcBV0TEYcAG4O251sasCZ9JbbYDJD0fEePrTF8FHBcRj6QLrD0VEZMkPUN2KYTONP3JiJgsaR0wLSK2VL3GDOCWiDgoPf8wMCoiPj0IVTN7EfcgzAZONHi8I7ZUPe7GeUIrkAOE2cB5V9X/n6XHd5FdJRjgdODO9PhW4FwASa2SdhusQpr1l/dOzHbMWElLq57/KCIqh7ruIWkZWS9gfpr218DXJf0dsA74izT9A8CVkt5L1lM4l+zqrGZDhnMQZgMg5SDmRMQzRZfFbKB4iMnMzOpyD8LMzOpyD8LMzOpygDAzs7ocIMzMrC4HCDMzq8sBwszM6vr/uVR+ESMZwpcAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY4AAAEWCAYAAABxMXBSAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAAsTAAALEwEAmpwYAAAmBUlEQVR4nO3dfZRddX3v8fdnzjxmSCaPUsiASeWhxkqjnYZWXAhmqVCs8dYISRGDpeWWe6kiq1WktgXkXosLBWm5rkZBHkQCoqybWhCv4mNVzIDhITzGEMiEpzCZJCSTME/f+8feZ+bMmTOT2cnszEzyea111tn7t397n9/OgvOZ3++3z96KCMzMzEararwbYGZmk4uDw8zMMnFwmJlZJg4OMzPLxMFhZmaZODjMzCwTB4dZTiTNkxSSqkdR91xJP9/f45gdCA4OM0DSRkldkmaXlf8m/dKeN05NM5twHBxmA54FlhdXJL0VmDJ+zTGbmBwcZgNuBT5asr4CuKW0gqQmSbdI2iLpOUmflVSVbitIulrSq5I2AGdU2PcGSS9K2izpSkmFrI2UdKSk1ZK2Slov6a9Lti2S1Cpph6SXJX0pLa+X9A1J7ZK2SVoj6fCsn20GDg6zUr8Cpkl6c/qFvgz4RlmdfwWagN8F3kUSNB9Lt/018H7gbUALsLRs35uAHuCYtM57gb/ah3auAtqAI9PP+N+S3p1u+zLw5YiYBrwJuDMtX5G2+yhgFvA3wO59+GwzB4dZmWKv4z3AE8Dm4oaSMPlMRLwWERuBLwLnpFXOBK6NiE0RsRX4fMm+hwN/ClwUEbsi4hXgmvR4oybpKOAk4NMRsSci1gJfY6Cn1A0cI2l2ROyMiF+VlM8CjomI3oh4MCJ2ZPlssyIHh9lgtwJ/AZxL2TAVMBuoAZ4rKXsOmJsuHwlsKttW9MZ03xfToaJtwL8Db8jYviOBrRHx2jBtOA84DngyHY56f8l53QeskvSCpC9Iqsn42WaAg8NskIh4jmSS/E+B75RtfpXkL/c3lpQdzUCv5EWSoaDSbUWbgNeB2RExPX1Ni4i3ZGziC8BMSVMrtSEinomI5SSBdBVwl6TGiOiOiMsjYgHwDpIhtY9itg8cHGZDnQe8OyJ2lRZGRC/JnMH/kjRV0huBixmYB7kT+LikZkkzgEtK9n0R+D7wRUnTJFVJepOkd2VpWERsAn4BfD6d8D4hbe83ACR9RNKciOgDtqW79Uk6VdJb0+G2HSQB2Jfls82KHBxmZSLitxHROszmvwV2ARuAnwPfBG5Mt32VZDjoYeAhhvZYPgrUAo8DHcBdwBH70MTlwDyS3sfdwD9HxA/SbacB6yTtJJkoXxYRu4HfST9vB8nczU9Ihq/MMpMf5GRmZlm4x2FmZpk4OMzMLBMHh5mZZeLgMDOzTA6J2zTPnj075s2bN97NMDObVB588MFXI2JOefkhERzz5s2jtXW4qyvNzKwSSc9VKvdQlZmZZeLgMDOzTBwcZmaWySExx2FmllV3dzdtbW3s2bNnvJuSu/r6epqbm6mpGd0Nkx0cZmYVtLW1MXXqVObNm4ek8W5ObiKC9vZ22tramD9//qj28VCVmVkFe/bsYdasWQd1aABIYtasWZl6Vg4OM7NhHOyhUZT1PD1UNYKb/utZdnX10tRQQ1NDDdOn1PQvNzXUMLW+hkLVofEflplZkYNjBN/89fM8/fLOYbdLMLWumqayQGlqqC1bHxw80xpqmFpXTZVDx8wqaG9vZ/HixQC89NJLFAoF5sxJfsD961//mtra2mH3bW1t5ZZbbuG6667LrX0OjhF8/5PvYk93L9t3dw+8OrvZVrK+o2R5W2cXL23fw/bdPezY3U1X7/APWKsSTK0f3IuZVhoyZaEzrSR4DqurPmS60GaHolmzZrF27VoALrvsMg477DD+7u/+rn97T08P1dWVv75bWlpoaWnJtX0Ojr2orylQX1Pg8Gn1mfaLCPZ097Ftd1d/4AwKoAqvzR27+5d7+oZ/wFahSkyrrx4IlinFHk41M9Ll6VNqmTGlGDbJclNDDdUFT2uZTUbnnnsu9fX1/OY3v+Gkk05i2bJlfOITn2DPnj00NDTw9a9/neOPP54f//jHXH311Xz3u9/lsssu4/nnn2fDhg08//zzXHTRRXz84x/f77Y4OHIiiYbaAg21DRzR1JBp34igs6s37cUM07vZ3cX23T3965u2drKtMwmpETKHqXXVTG+sYXpDLdOnJAEzvaEmCZbicmMSNtOn1DBjSi3T6qsdOHZIu/w/1vH4CzvG9JgLjpzGP//ZWzLt09bWxi9+8QsKhQI7duzgZz/7GdXV1fzgBz/g0ksv5dvf/vaQfZ588kl+9KMf8dprr3H88cdzwQUXjPr3GsNxcExAkmisq6axrpojp2cLnb6+4LXXe9jW2cW2dFitf7mzm440XLZ1dtHR2U1bx+7RBU590pspDpcVl6envZtiyDSlZTOm1DKtwRcPmI2lD3/4wxQKBQC2b9/OihUreOaZZ5BEd3d3xX3OOOMM6urqqKur4w1veAMvv/wyzc3N+9UOB8dBpqpK/UNYb5w1+v36+oLX9vTQ0dlVFjbF9YHljs60h5P2dkZ6bP20+mpmNCY9mabi8FnJ8owptcxoHLzcWFvwHI5NKFl7BnlpbGzsX/7Hf/xHTj31VO6++242btzIKaecUnGfurq6/uVCoUBPT89+t8PBYUAaOFNqaJqSrQvb2xe8ticJk21DQmdo8DzXvqt/+G04NQUlIZL2ZGY21vbP2ZQuJ4GTLE+rr/FVanZI2b59O3PnzgXgpptuOqCf7eCw/VKoUjpUVQs07rV+UW9fsH13MnTWsSsZNitd3tbZxdZdSQCtf2Vnsq2zm95hxtOqRP+Q2cwpew+aYi/Iczc2WX3qU59ixYoVXHnllZxxxhkH9LMVI40z7O/BpdOALwMF4GsR8S9l2+uAW4A/BNqBsyJio6Qa4GvA20nC7ZaI+PxojllJS0tL+EFOk19EMn+zt6DpKFne2tlFV8/wl0VPra8e3KOZMnzQJPVqqKsuHMCztvHyxBNP8OY3v3m8m3HAVDpfSQ9GxJBre3PrcUgqANcD7wHagDWSVkfE4yXVzgM6IuIYScuAq4CzgA8DdRHxVklTgMcl3Q5sGsUx7SAliWn1ybDUaOdvIoLd3b1J0Ozq6u+5FJe3dXazNV1u39nFMy/vZFtnF7u6eoc95mF1SdjMaKxlZjFU0vmZmWnYzGysZWZjDTMb62jyRQJ2kMlzqGoRsD4iNgBIWgUsAUq/5JcAl6XLdwH/pmRWNIBGSdVAA9AF7BjlMc36SWJKbTVTaquZm+EKtdd7evt7Lx27BnoxHbu62NpZfO/m1Z1dPP1yMpTWOUzYSKSXOZcETH/QJBcFzDpsIHBmNNYy1T/ytAksz+CYS9JDKGoDThyuTkT0SNoOzCIJkSXAi8AU4JMRsVXSaI4JgKTzgfMBjj766P0+GTu01FUXOHxath9+7unuZeuurv4ezEDQdA8KnE1bO3l40zY6Orvo7q08VFxdpZKAqenvycxqHNqzKdZrqPUQmh0YE3VyfBHQCxwJzAB+JukHWQ4QESuBlZDMcYx5C83K1NcUOHJ6w6h/exMR7Hy9h45d3QO9mJLQKQ2hp156rX9eZ7hpyfqaqkFDZsVXMWxmNdYys7Guv3x6g69Es32TZ3BsBo4qWW9OyyrVaUuHpZpIJsn/AvheRHQDr0j6L6CFpLext2OaTQqSmFqf3GX56FlTRrVPb1+wY/fQoGkv9m52dbN11+ts7ezmufZOtu7qYufrla/brxL9v50ZGjDl4VPHjEZfGGCJPINjDXCspPkkX+7LSAKh1GpgBfBLYClwf0SEpOeBdwO3SmoE/hi4lmQuY2/HNDtoFdIhrBmNtTBndPvs6e4d0ospvoqB076ri2de2dkfRMP1akovDKgcMIO3+YacB6fcgiOds7gQuI/k0tkbI2KdpCuA1ohYDdxAEg7rga0kQQDJlVNfl7QOEPD1iHgEoNIx8zoHs4NBfU2BI5pGf8+04m9stu56vb8HUxowxdB5eccennhxB+27hr/kubZQlc7R1PVfZVYMldKAKb5Pn1LrK9BSp556Kpdccgnve9/7+suuvfZannrqKb7yla8MqX/KKadw9dVX535nXMh5jiMi7gHuKSv7p5LlPSSX3pbvt7NS+XDHNLOxU6hSfw9iNIo35SzvwZQGTnHb5o5ttO/q4rU9lYfPlA6fzSwLlP73w9LgOSytM6X2oP0R5/Lly1m1atWg4Fi1ahVf+MIXxrFViYk6OW5mk0TpTTmPmjm6uZqunj62dQ70YNp3dbF15+v9y+07k/KnX34t+THnCPdEa2qoGTRsNuuwgXmZ4nJxfWZjLbXVkyNoli5dymc/+1m6urqora1l48aNvPDCC9x+++1cfPHF7N69m6VLl3L55Zcf8LY5OMzsgKutruIN0+p5wygvd+7p7WPb7uTHmsVQKfZoiuvtu15nY/suHnq+g627uoa92/PUuur+HsuQnkxJyNAX9PVFcuXZvZfAS4+O4b8A8DtvhdOHv/HFzJkzWbRoEffeey9Llixh1apVnHnmmVx66aXMnDmT3t5eFi9ezCOPPMIJJ5wwtm3bCweHmU141YUqZh9Wx+zD6uDwvdfvS+dpBuZkykMmKWvr2M0jbdvZuqtryMPTvvqBI4gXtlMlceSuLhq6ewAhJUNqKi6T9LqS96R8rBSHq4rBccMNN3DnnXeycuVKenp6ePHFF3n88ccdHGZm+6uq9OqzUYgIduzpGQiZnV3M6N7C70yrp6cv2PnuK9nW20dvX9CTvoa7z1+VRHWVqC6IQlVV/3J1VYX1vhjxYoAlS5bwyU9+koceeojOzk5mzpzJ1VdfzZo1a5gxYwbnnnsue/bs2ad/o/3h4DCzQ5408Byb+bOTuzw/8UTHsENpEUFfpCHSG2mg9JWtBz29fezpHl3QFAqiekjQ1PLOk9/FuR/7GGeedRYd27bT2NhIU1MTL7/8Mvfee++wz+HIk4PDzCwjSRQkClVQN4pv0SRoSMKlNFjK1ysEzcmnfZC7v/0RPvflr1I9Zx7zjn8Lv3vscRxxZDML/+hEtu58nRe376a7t6//EdOlPZw8Lm/O9bbqE4Vvq25mWY3nbdVLg6a3d2B4rFLQ9PQl633DfJe/5cimUYXHhLitupmZ7ZukRwOFqsKovqVHCpo8fk/p4DAzm+SyBs3+mhy/hDEzGweHwlA+ZD9PB4eZWQX19fW0t7cf9OEREbS3t1NfP/pnz3ioysysgubmZtra2tiyZct4NyV39fX1NDc3j7q+g8PMrIKamhrmz58/3s2YkDxUZWZmmTg4zMwsEweHmZll4uAwM7NMcg0OSadJekrSekmXVNheJ+mOdPsDkual5WdLWlvy6pO0MN22XNKjkh6R9D1Js/M8BzMzGyy34JBUIHl2+OnAAmC5pAVl1c4DOiLiGOAa4CqAiLgtIhZGxELgHODZiFgrqRr4MnBqRJwAPAJcmNc5mJnZUHn2OBYB6yNiQ0R0AauAJWV1lgA3p8t3AYslld9ZZXm6L6TPTAEa03rTgBfyaLyZmVWWZ3DMBTaVrLelZRXrREQPsB2YVVbnLOD2tE43cAHwKElgLABuqPThks6X1Cqp9VD4AY+Z2YEyoSfHJZ0IdEbEY+l6DUlwvA04kmSo6jOV9o2IlRHREhEtc+bMOVBNNjM76OUZHJuBo0rWm9OyinXS+YsmoL1k+zLS3kZqIUBE/DaSG8jcCbxjTFttZmYjyjM41gDHSpovqZYkBFaX1VkNrEiXlwL3p4GApCrgTAbmNyAJmgWSil2I9wBP5NR+MzOrILd7VUVEj6QLgfuAAnBjRKyTdAXQGhGrSeYnbpW0HthKEi5FJwObImJDyTFfkHQ58FNJ3cBzwLl5nYOZmQ3lR8eamVlFwz06dkJPjpuZ2cTj4DAzs0wcHGZmlomDw8zMMnFwmJlZJg4OMzPLxMFhZmaZODjMzCwTB4eZmWXi4DAzs0wcHGZmlomDw8zMMnFwmJlZJg4OMzPLxMFhZmaZODjMzCwTB4eZmWXi4DAzs0xyDQ5Jp0l6StJ6SZdU2F4n6Y50+wOS5qXlZ0taW/Lqk7Qw3VYraaWkpyU9KelDeZ6DmZkNlltwSCoA1wOnAwuA5ZIWlFU7D+iIiGOAa4CrACLitohYGBELgXOAZyNibbrPPwCvRMRx6XF/ktc5mJnZUHn2OBYB6yNiQ0R0AauAJWV1lgA3p8t3AYslqazO8nTfor8EPg8QEX0R8eqYt9zMzIaVZ3DMBTaVrLelZRXrREQPsB2YVVbnLOB2AEnT07LPSXpI0rckHV7pwyWdL6lVUuuWLVv260TMzGzAhJ4cl3Qi0BkRj6VF1UAz8IuIeDvwS+DqSvtGxMqIaImIljlz5hyYBpuZHQLyDI7NwFEl681pWcU6kqqBJqC9ZPsy0t5Gqh3oBL6Trn8LePvYNdnMzPYmz+BYAxwrab6kWpIQWF1WZzWwIl1eCtwfEQEgqQo4k5L5jXTbfwCnpEWLgcfzOgEzMxuqOq8DR0SPpAuB+4ACcGNErJN0BdAaEauBG4BbJa0HtpKES9HJwKaI2FB26E+n+1wLbAE+ltc5mJnZUEr/wD+otbS0RGtr63g3w8xsUpH0YES0lJdP6MlxMzObeBwcZmaWiYPDzMwycXCYmVkmDg4zM8vEwWFmZpk4OMzMLBMHh5mZZeLgMDOzTBwcZmaWiYPDzMwycXCYmVkmDg4zM8vEwWFmZpk4OMzMLBMHh5mZZeLgMDOzTHINDkmnSXpK0npJl1TYXifpjnT7A5LmpeVnS1pb8uqTtLBs39WSHsuz/WZmNlRuwSGpAFwPnA4sAJZLWlBW7TygIyKOAa4BrgKIiNsiYmFELATOAZ6NiLUlx/5zYGdebTczs+Hl2eNYBKyPiA0R0QWsApaU1VkC3Jwu3wUslqSyOsvTfQGQdBhwMXBlLq02M7MR5Rkcc4FNJettaVnFOhHRA2wHZpXVOQu4vWT9c8AXgc6RPlzS+ZJaJbVu2bIle+vNzKyiUQWHpEZJVenycZI+IKkm36aBpBOBzoh4LF1fCLwpIu7e274RsTIiWiKiZc6cOTm31Mzs0DHaHsdPgXpJc4Hvk8w73LSXfTYDR5WsN6dlFetIqgaagPaS7csY3Nv4E6BF0kbg58Bxkn48ynMwM7MxMNrgUER0An8O/J+I+DDwlr3sswY4VtJ8SbUkIbC6rM5qYEW6vBS4PyICIO3hnEnJ/EZEfCUijoyIecA7gacj4pRRnoOZmY2B6lHWk6Q/Ac4muRIKoDDSDhHRI+lC4L607o0RsU7SFUBrRKwGbgBulbQe2EoSLkUnA5siYsPoT8fMzPI22uC4CPgMcHf65f+7wI/2tlNE3APcU1b2TyXLe4APD7Pvj4E/HuHYG4Hf33vTzcxsLI0qOCLiJ8BPoH8I6dWI+HieDTMzs4lptFdVfVPSNEmNwGPA45L+Pt+mmZnZRDTayfEFEbED+CBwLzCf5MoqMzM7xIw2OGrS3218EFgdEd1A5NYqMzObsEYbHP8ObAQagZ9KeiOwI69GmZnZxDXayfHrgOtKip6TdGo+TTIzs4lstJPjTZK+VLz3k6QvkvQ+zMzsEDPaoaobgddIfsl9Jskw1dfzapSZmU1co/0B4Jsi4kMl65dLWptDe8zMbIIbbY9jt6R3FlcknQTszqdJZmY2kY22x/E3wC2SmtL1DgZuTmhmZoeQ0V5V9TDwB5Kmpes7JF0EPJJj28zMbALK9ATAiNiR/oIckse3mpnZIWZ/Hh1b/mxwMzM7BOxPcPiWI2Zmh6AR5zgkvUblgBDQkEuLzMxsQhsxOCJi6oFqiJmZTQ77M1S1V5JOk/SUpPWSLqmwvU7SHen2ByTNS8vPlrS25NUnaaGkKZL+U9KTktZJ+pc8229mZkPlFhySCsD1wOnAAmC5pAVl1c4DOiLiGOAa4CqAiLgtIhZGxEKS5348GxFr032ujojfA94GnCTp9LzOwczMhsqzx7EIWB8RGyKiC1gFLCmrswS4OV2+C1gsqfxqreXpvkREZ0T8KF3uAh4CmnNqv5mZVZBncMwFNpWst6VlFetERA+wHZhVVucs4Pbyg0uaDvwZ8MNKHy7p/OLdfLds2bIv7TczswpynePYX5JOBDoj4rGy8mqSMLkuIjZU2jciVkZES0S0zJkz5wC01szs0JBncGwGjipZb07LKtZJw6AJaC/ZvowKvQ1gJfBMRFw7Vo01M7PRyTM41gDHSpovqZYkBFaX1VnNwM0SlwL3R0QASKoiefbHqtIdJF1JEjAX5dd0MzMbTm7Bkc5ZXAjcBzwB3BkR6yRdIekDabUbgFmS1pPc+6r0kt2TgU2lQ1GSmoF/ILlK66H0Ut2/yusczMxsKKV/4B/UWlpaorW1dbybYWY2qUh6MCJayssn9OS4mZlNPA4OMzPLxMFhZmaZODjMzCwTB4eZmWXi4DAzs0wcHGZmlomDw8zMMnFwmJlZJg4OMzPLxMFhZmaZODjMzCwTB4eZmWXi4DAzs0wcHGZmlomDw8zMMnFwmJlZJrkGh6TTJD0lab2kSypsr5N0R7r9AUnz0vKz08fCFl99kham2/5Q0qPpPtdJUp7nYGZmg+UWHJIKwPXA6STPCF8uaUFZtfOAjog4BrgGuAogIm6LiIURsRA4B3g2Itam+3wF+Gvg2PR1Wl7nYGZmQ+XZ41gErI+IDRHRBawClpTVWQLcnC7fBSyu0INYnu6LpCOAaRHxq0geln4L8MGc2m9mZhXkGRxzgU0l621pWcU6EdEDbAdmldU5C7i9pH7bXo5pZmY5mtCT45JOBDoj4rF92Pd8Sa2SWrds2ZJD68zMDk15Bsdm4KiS9ea0rGIdSdVAE9Besn0ZA72NYv3mvRwTgIhYGREtEdEyZ86cfToBMzMbKs/gWAMcK2m+pFqSEFhdVmc1sCJdXgrcn85dIKkKOJN0fgMgIl4Edkj643Qu5KPA/83xHMzMrEx1XgeOiB5JFwL3AQXgxohYJ+kKoDUiVgM3ALdKWg9sJQmXopOBTRGxoezQ/wO4CWgA7k1fZmZ2gCj9A/+g1tLSEq2trePdDDOzSUXSgxHRUl4+oSfHzcxs4nFwmJlZJg4OMzPLxMFhZmaZODjMzCwTB4eZmWXi4DAzs0wcHGZmlomDw8zMMnFwmJlZJg4OMzPLxMFhZmaZODjMzCwTB4eZmWXi4DAzs0wcHGZmlomDw8zMMnFwmJlZJrkGh6TTJD0lab2kSypsr5N0R7r9AUnzSradIOmXktZJelRSfVq+PF1/RNL3JM3O8xzMzGyw3IJDUgG4HjgdWAAsl7SgrNp5QEdEHANcA1yV7lsNfAP4m4h4C3AK0J2Wfxk4NSJOAB4BLszrHMzMbKg8exyLgPURsSEiuoBVwJKyOkuAm9Plu4DFkgS8F3gkIh4GiIj2iOgFlL4a03rTgBdyPAczMyuTZ3DMBTaVrLelZRXrREQPsB2YBRwHhKT7JD0k6VNpnW7gAuBRksBYANxQ6cMlnS+pVVLrli1bxu6szMwOcRN1crwaeCdwdvr+3yQtllRDEhxvA44kGar6TKUDRMTKiGiJiJY5c+YcoGabmR388gyOzcBRJevNaVnFOun8RRPQTtI7+WlEvBoRncA9wNuBhQAR8duICOBO4B05noOZmZXJMzjWAMdKmi+pFlgGrC6rsxpYkS4vBe5PA+E+4K2SpqSB8i7gcZKgWSCp2IV4D/BEjudgZmZlqvM6cET0SLqQJAQKwI0RsU7SFUBrRKwmmZ+4VdJ6YCtJuBARHZK+RBI+AdwTEf8JIOly4KeSuoHngHPzOgczMxtKyR/4B7eWlpZobW0d72aYmU0qkh6MiJby8ok6OW5mZhOUg8PMzDJxcJiZWSYODjMzy8TBYWZmmTg4zMwsEweHmZll4uAwM7NMHBxmZpaJg8PMzDJxcJiZWSYODjMzy8TBYWZmmTg4zMwsEweHmZll4uAwM7NMHBxmZpZJrsEh6TRJT0laL+mSCtvrJN2Rbn9A0rySbSdI+qWkdZIelVSfltdKWinpaUlPSvpQnudgZmaD5fbMcUkF4HrgPUAbsEbS6oh4vKTaeUBHRBwjaRlwFXCWpGrgG8A5EfGwpFlAd7rPPwCvRMRxkqqAmXmdg5mZDZVbcACLgPURsQFA0ipgCVAaHEuAy9Llu4B/kyTgvcAjEfEwQES0l+zzl8DvpeV9wKs5noOZ2YERAX090NsNfd3Q25O+dw+8D7utdL1n8D4tfwlVhTFtap7BMRfYVLLeBpw4XJ2I6JG0HZgFHAeEpPuAOcCqiPiCpOnpfp+TdArwW+DCiHi5/MMlnQ+cD3D00UeP0SmZ2biJgOgb+HLs64G+3uQLsnR9xO096ZfsCK+Rtg/5Yh7hC7tiva7h9+nryeff7W0fgaqGMT1knsGxP6qBdwJ/BHQCP5T0IPAw0Az8IiIulnQxcDVwTvkBImIlsBKgpaUl9qkV9/w97HghSeuq6uSlwuD1/uVCyfYK5cVlle9bul4Nqhq8Xl5npM9XIdlfApS8q2qYZe3TP4lVEDHwpVb+orR8mDqDXmNUp68Pojf94uxJl4tl6RdqcXv0DS0btH24sp7BnzPo2H1lnz1SWemXc+/gL+jiep5frKNR/P9SBSjUJK+q4nt1yXr14PKahqH1CrUj7FPhGEM+q3Yvn1u2Xl0/5v8ceQbHZuCokvXmtKxSnbZ0XqMJaCfpnfw0Il4FkHQP8HbgfpIg+U66/7dI5knyseMF2Ppsyf8QPQP/A5WuD9o+jv9xZ6aSkBlN4FCh7kj7DVNe3A9IvlhjYBnS9b0tl9evcKzRLGf5jOG+pIt1DkaqGvzHkApQNUxZ6R82w5VV10HVlAr1Sr4Y+/8YKls/YNsrvXwBaqk8g2MNcKyk+SQBsQz4i7I6q4EVwC+BpcD9EVEcovqUpClAF/Au4Jp0238Ap5CEyGIGz5mMrWW37dt+fWV/RUWFsCl9j97K5VnqFLcXv+D6vyCLX3iULMfA9tK6Q/YrP8b+7le2TNrrKYZJ/zIMhEyG5f634Y67n5+nqlG8VPY+Up3RHGcftqP0S7mKwV/uhcHLpb1XVZX1iEt7r2aD5RYc6ZzFhcB9QAG4MSLWSboCaI2I1cANwK2S1gNbScKFiOiQ9CWS8Angnoj4z/TQn073uRbYAnwsr3PYZ1VVUFUL1I53S8zMxpyiv9t+8GppaYnW1tbxboaZ2aQi6cGIaCkv98CdmZll4uAwM7NMHBxmZpaJg8PMzDJxcJiZWSYODjMzy8TBYWZmmRwSv+OQtAV4bh93n83kuQPvZGorTK72Tqa2wuRq72RqK0yu9u5vW98YEXPKCw+J4Ngfklor/QBmIppMbYXJ1d7J1FaYXO2dTG2FydXevNrqoSozM8vEwWFmZpk4OPZu5Xg3IIPJ1FaYXO2dTG2FydXeydRWmFztzaWtnuMwM7NM3OMwM7NMHBxmZpaJg2MYkk6T9JSk9ZIuGe/2jETSjZJekfTYeLdlbyQdJelHkh6XtE7SJ8a7TSORVC/p15IeTtt7+Xi3aW8kFST9RtJ3x7steyNpo6RHJa2VNKEfmiNpuqS7JD0p6QlJfzLebRqOpOPTf9Pia4eki8bs+J7jGEpSAXgaeA/J88/XAMsjIr/H1O4HSScDO4FbIuL3x7s9I5F0BHBERDwkaSrwIPDBCfxvK6AxInZKqgF+DnwiIn41zk0blqSLgRZgWkS8f7zbMxJJG4GWiJjwP6iTdDPws4j4mqRaYEpEbBvnZu1V+n22GTgxIvb1h9CDuMdR2SJgfURsiIguYBWwZJzbNKyI+CnJo3cnvIh4MSIeSpdfA54A5o5vq4YXiZ3pak36mrB/bUlqBs4AvjbebTmYSGoCTiZ53DUR0TUZQiO1GPjtWIUGODiGMxfYVLLexgT+cpusJM0D3gY8MM5NGVE69LMWeAX4fxExkdt7LfApoG+c2zFaAXxf0oOSzh/vxoxgPrAF+Ho6DPg1SY3j3ahRWgbcPpYHdHDYuJB0GPBt4KKI2DHe7RlJRPRGxEKgGVgkaUIOB0p6P/BKRDw43m3J4J0R8XbgdOB/psOuE1E18HbgKxHxNmAXMKHnPgHSIbUPAN8ay+M6OCrbDBxVst6cltkYSOcKvg3cFhHfGe/2jFY6NPEj4LRxbspwTgI+kM4brALeLekb49ukkUXE5vT9FeBukmHiiagNaCvpbd5FEiQT3enAQxHx8lge1MFR2RrgWEnz08ReBqwe5zYdFNLJ5huAJyLiS+Pdnr2RNEfS9HS5geSCiSfHtVHDiIjPRERzRMwj+W/2/oj4yDg3a1iSGtMLJEiHfd4LTMgrAyPiJWCTpOPTosXAhLygo8xyxniYCpLul5WJiB5JFwL3AQXgxohYN87NGpak24FTgNmS2oB/jogbxrdVwzoJOAd4NJ03ALg0Iu4ZvyaN6Ajg5vTKlCrgzoiY8Je5ThKHA3cnf0tQDXwzIr43vk0a0d8Ct6V/TG4APjbO7RlRGsbvAf77mB/bl+OamVkWHqoyM7NMHBxmZpaJg8PMzDJxcJiZWSYODjMzy8TBYTYGJPWW3Y10zH5VLGneZLjzsR06/DsOs7GxO70tidlBzz0Osxylz5v4QvrMiV9LOiYtnyfpfkmPSPqhpKPT8sMl3Z0+/+NhSe9ID1WQ9NX0mSDfT3/FbjYuHBxmY6OhbKjqrJJt2yPircC/kdy9FuBfgZsj4gTgNuC6tPw64CcR8Qck90Iq3rHgWOD6iHgLsA34UK5nYzYC/3LcbAxI2hkRh1Uo3wi8OyI2pDd3fCkiZkl6leSBVt1p+YsRMVvSFqA5Il4vOcY8ktu5H5uufxqoiYgrD8CpmQ3hHodZ/mKY5SxeL1nuxfOTNo4cHGb5O6vk/Zfp8i9I7mALcDbws3T5h8AF0P8AqaYD1Uiz0fJfLWZjo6Hkbr8A34uI4iW5MyQ9QtJrWJ6W/S3J0+T+nuTJcsU7rX4CWCnpPJKexQXAi3k33iwLz3GY5Sid42iJiFfHuy1mY8VDVWZmlol7HGZmlol7HGZmlomDw8zMMnFwmJlZJg4OMzPLxMFhZmaZ/H8RE87CpIiXagAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Defining random seeds to enable reproducibility\n",
    "from numpy.random import seed\n",
    "seed(1)\n",
    "\n",
    "import tensorflow as tf\n",
    "tf.random.set_seed(1)\n",
    " \n",
    "import random\n",
    "random.seed(1)\n",
    " \n",
    "import pickle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.python.client import device_lib\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "\n",
    "print(device_lib.list_local_devices())\n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n",
    "\n",
    "\n",
    "def load_patras_dataset():\n",
    "    \"\"\"\n",
    "    Loads the datasets encoded in .pkl files and returns its decoded form.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    list\n",
    "        A list of n-dimensional arrays representing the subjects samples that will be used to \\\\\n",
    "        train the drunkenness classification model.\n",
    "    list\n",
    "        A list of n-dimensional arrays representing the subjects samples that will be used to \\\\\n",
    "        test the drunkenness classification model.\n",
    "    ndarray\n",
    "        A n-dimensional array representing the training set labels.\n",
    "    ndarray\n",
    "        A n-dimensional array representing the test set labels.\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"Loading Sober-Drunk Face Dataset, from Patras University\")\n",
    "    \n",
    "    # Defining the sample and label sets filenames\n",
    "    sets = [\n",
    "        \"Insert the unbalanced x_training-set.pkl file path here\",\n",
    "        \"Insert the unbalanced x_test-set.pkl file path here\",\n",
    "        \"Insert the unbalanced y_training-set.pkl file path here\",\n",
    "        \"Insert the unbalanced y_test-set.pkl file path here\"\n",
    "    ]\n",
    " \n",
    "    # Defining an empty list for storing the decoded datasets\n",
    "    loaded_datasets = []\n",
    " \n",
    "    # Iterating over the dataset files\n",
    "    for set_ in sets:\n",
    "        # Opening the .pkl file in read mode\n",
    "        with open(set_, 'rb') as file:\n",
    "            # Appending the decoded dataset to the datasets list\n",
    "            loaded_datasets.append(pickle.load(file))\n",
    "    \n",
    "    # Unpacking the datasets list into individual subsets\n",
    "    x_train, x_test, y_train, y_test = loaded_datasets\n",
    "    \n",
    "    # Converting the label list to the n-dimensional array format\n",
    "    y_train= np.array(y_train)\n",
    "    y_test = np.array(y_test)\n",
    " \n",
    "    # Printing the dataset length\n",
    "    print(\"\\nSamples total: {0}\".format((len(x_train)) + (len(x_test))))\n",
    "    \n",
    "    print(\"\\nDataset splitting: \")\n",
    "    \n",
    "    # Printing the training and test sets length\n",
    "    print(\"\\nTraining set: {0}\".format(len(x_train)))\n",
    "    print(\"Test set: {0}\".format(len(x_test)))\n",
    "    \n",
    "    # Returning the training and test sets, and its respective labels\n",
    "    return x_train, x_test, y_train, y_test\n",
    "\n",
    "\n",
    "def min_max_norm(dataset):\n",
    "    \"\"\"\n",
    "    Normalizes the keyframes according to the minimum-maximum norm, \\\\\n",
    "    such that pixel values ranges from 0 to 1.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    dataset : list\n",
    "        A list of n-dimensional arrays representing the subjects keyframes.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    ndarray\n",
    "        A n-dimensional array representing keyframes with pixel values ranging from 0 to 1.\n",
    "    \"\"\"\n",
    "\n",
    "    # Converting the dataset type from list to n-dimensional array\n",
    "    dataset = np.asarray(dataset, dtype=\"int16\")\n",
    "\n",
    "    # Finding the keyframes minimum and maximum values\n",
    "    x_min = dataset.min(axis=(1, 2), keepdims=True)\n",
    "    x_max = dataset.max(axis=(1, 2), keepdims=True)\n",
    "\n",
    "    # Applying the minimum-maximum norm to each keyframe\n",
    "    norm_dataset = (dataset - x_min) / (x_max - x_min)\n",
    "\n",
    "    # Printing the minimum and maximum values from a given sample for sanity check\n",
    "    print(\"\\nMinMax normalization\")\n",
    "    print(\"dataset shape: \", norm_dataset.shape)\n",
    "    print(\"min: \", norm_dataset[0].min())\n",
    "    print(\"max: \", norm_dataset[0].max())\n",
    "\n",
    "    # Returning the normalized dataset\n",
    "    return norm_dataset\n",
    "\n",
    "\n",
    "def visualize_model_history(hist):\n",
    "    \"\"\"\n",
    "    Displays the training process loss and accuracy history from a given fold of the \\\\\n",
    "    stratified cross-validation procedure.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    hist : dictionary\n",
    "        A dictionary conataining loss and accuracy values lists from the training and \\\\\n",
    "        validation sets.\n",
    "    \"\"\"\n",
    "\n",
    "    # Displaying the training and validation loss history\n",
    "    plt.figure()\n",
    "    plt.plot(hist.history['loss'])\n",
    "    plt.plot(hist.history['val_loss'])\n",
    "    plt.title('Model loss')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train', 'Val'], loc='upper right')\n",
    "    \n",
    "    # Displaying the training and validation accuracy history\n",
    "    plt.figure()\n",
    "    plt.plot(hist.history['accuracy'])\n",
    "    plt.plot(hist.history['val_accuracy'])\n",
    "    plt.title('Model accuracy')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train', 'Val'], loc='lower right')\n",
    "    \n",
    "    # Showing the training process loss and accuracy history\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def visualize_model_history_cv(training_loss, training_accuracy, validation_loss, validation_accuracy):\n",
    "    \"\"\"\n",
    "    Displays the training process loss and accuracy history throughout the \\\\\n",
    "    stratified k-fold cross-validation procedure.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    training_loss : list\n",
    "        A list conataining the loss values from the training set throught the \\\\\n",
    "        stratified k-fold cross-validation procedure.\n",
    "    training_accuracy : list\n",
    "        A list conataining the accuracy values from the training set throught the \\\\\n",
    "        stratified k-fold cross-validation procedure.\n",
    "    validation_loss : list\n",
    "        A list conataining the loss values from the validation set throught the \\\\\n",
    "        stratified k-fold cross-validation procedure.\n",
    "    validation_accuracy : list\n",
    "        A list conataining the accuracy values from the validation set throught the \\\\\n",
    "        stratified k-fold cross-validation procedure.\n",
    "    \"\"\"\n",
    "\n",
    "    # Displaying and saving the training and validation loss history\n",
    "    plt.figure()\n",
    "    plt.plot(training_loss)\n",
    "    plt.plot(validation_loss)\n",
    "    plt.title('Model loss (cross-validation history)')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train', 'Val'], loc='upper right')\n",
    "    plt.savefig(\"ft_learning-curve_final-model.pdf\", dpi=600, bbox_inches='tight', pad_inches=0)\n",
    "    \n",
    "    # Displaying the training and validation accuracy history\n",
    "    plt.figure()\n",
    "    plt.plot(training_accuracy)\n",
    "    plt.plot(validation_accuracy)\n",
    "    plt.title('Model accuracy (cross-validation history)')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train', 'Val'], loc='upper right')\n",
    "    \n",
    "    # Showing the training process loss and accuracy history\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "def fine_tunning():\n",
    "    \"\"\"\n",
    "    Fine-tunes the final drunkenness classification model deepest convolutional \\\\ \n",
    "    layers.\n",
    "\n",
    "    This function loads the previously trained drunkenness classification model, \\\\\n",
    "    unfreezes the deepestes convolutional layers weights and retrains the model \\\\ \n",
    "    in order to induce such layers to extract high-level drunkenness-related \\\\ \n",
    "    features.\n",
    "    \"\"\"\n",
    "\n",
    "    # Loading the training and test datasets\n",
    "    x_train, x_test, y_train, y_test = load_patras_dataset()\n",
    "\n",
    "    # Applying the min-max normalization\n",
    "    x_train = min_max_norm(x_train)\n",
    "    x_test = min_max_norm(x_test)\n",
    "    \n",
    "    # Reshaping datsets to the tensor format (channel last)\n",
    "    x_train = x_train.reshape(x_train.shape[0], x_train.shape[1], x_train.shape[2], 3)\n",
    "    x_test = x_test.reshape(x_test.shape[0], x_test.shape[1], x_test.shape[2], 3)\n",
    "\n",
    "\n",
    "    print(\"\\n Loading pre-trained model\")\n",
    "\n",
    "    # Loading the final drunkenness classification model\n",
    "    model = models.load_model('sober-drunk_final-model-VGG16_fold-6.h5')\n",
    "\n",
    "    # Printing the final model summary\n",
    "    model.summary()\n",
    "    \n",
    "    # Iterating over the layers from convolutional blocks 4 and 5\n",
    "    for layer in model.layers[10:]:\n",
    "        # Unfreezing the layers weights\n",
    "        layer.trainable = True\n",
    "    \n",
    "    # Iterating over the final model layers\n",
    "    for layer in model.layers:\n",
    "        # Printing the layers 'trainable' parameter for sanity check  \n",
    "        print(\"{}: {}\".format(layer.name, layer.trainable))\n",
    " \n",
    "    # Defining the optmization function\n",
    "    adam = optimizers.Adam(learning_rate=1e-7, amsgrad=True)\n",
    "    \n",
    "    # Defining the early stopping callback\n",
    "    callback = keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=0, patience=5, restore_best_weights=True, verbose=1)\n",
    "    \n",
    "    print(\"\\nRe-compiling model...\")\n",
    "\n",
    "    # Compiling the model\n",
    "    model.compile(loss=keras.losses.BinaryCrossentropy(from_logits=False),\n",
    "                optimizer=adam,\n",
    "                metrics=['accuracy'])\n",
    "    \n",
    "    # Printing the model summary\n",
    "    model.summary()\n",
    "    \n",
    "    # Shuffling the training set organization\n",
    "    x_train, y_train = shuffle(x_train, y_train, random_state=1)\n",
    "    \n",
    "    # Defining the stratified cross-validation folds\n",
    "    folds = list(StratifiedKFold(n_splits=7, shuffle=False, random_state=None).split(x_train, y_train))\n",
    "    \n",
    "    # Instantiating empty lists for storing the model training and validation loss history\n",
    "    cv_training_acc = []\n",
    "    cv_training_loss = []\n",
    "    \n",
    "    # Instantiating empty lists for storing the model training and validation accuracy history\n",
    "    cv_val_acc = []\n",
    "    cv_val_loss = []\n",
    "    \n",
    "    # Instantiating an empty list for storing the model classification accuracies on the test set samples\n",
    "    fold_acc = []\n",
    "    \n",
    "    # Defining weights for sober and drunk classes in order to prevent the class  \n",
    "    # imbalance from influencing the loss function\n",
    "    weight_for_0 = (1 / 35)*(140)/2.0 \n",
    "    weight_for_1 = (1 / 105)*(140)/2.0\n",
    "    \n",
    "    class_weights = {0: weight_for_0, 1: weight_for_1}\n",
    "    \n",
    "    print(\"\\nFitting model...\")\n",
    "    \n",
    "    # Iterating over the stratified cross-validation folds\n",
    "    for j, (train_idx, val_idx) in enumerate(folds):\n",
    "        print('\\nFold ',j)\n",
    "        # Defining the training and validation sets\n",
    "        X_train_cv, y_train_cv = x_train[train_idx], y_train[train_idx]\n",
    "        X_valid_cv, y_valid_cv = x_train[val_idx], y_train[val_idx]\n",
    "        \n",
    "        print(\"\\nTraining with {0} samples and validating with {1} samples\\n\".format(len(X_train_cv), len(X_valid_cv)))\n",
    "        \n",
    "        # Fitting the model\n",
    "        history = model.fit(x=X_train_cv, y=y_train_cv, \n",
    "                            validation_data=(X_valid_cv, y_valid_cv),\n",
    "                            shuffle=False,\n",
    "                            batch_size=60,\n",
    "                            callbacks=[callback],\n",
    "                            epochs=205,\n",
    "                            class_weight=class_weights,\n",
    "                            verbose=1)\n",
    "    \n",
    "        # Updating the training loss and accuracy history lists\n",
    "        cv_training_acc += history.history['accuracy']\n",
    "        cv_training_loss += history.history['loss']\n",
    "\n",
    "        # Updating the validation loss and accuracy history lists\n",
    "        cv_val_acc += history.history['val_accuracy']\n",
    "        cv_val_loss += history.history['val_loss']\n",
    "\n",
    "        # Evaluating the model on unseen data\n",
    "        test_loss, test_acc = model.evaluate(x_test, y_test, verbose=1)\n",
    "\n",
    "        # Appending the model classification accuracies to the test set accuracies list\n",
    "        fold_acc.append(test_acc)\n",
    "\n",
    "        # Printing the model classification accuracy on unseen data\n",
    "        print('\\nFold ',j)\n",
    "        print(\"\\nTest accuracy: \", test_acc)\n",
    "        print(\"Test loss: \", test_loss)\n",
    "\n",
    "        # Saving the model obtained in the stratified cross-validation j-th fold\n",
    "        model.save('sober-drunk_final-model_ft_fold-{0}.h5'.format(j))\n",
    "        \n",
    "        # Uncomment to break the loop\n",
    "        #if j == 3:\n",
    "        #    break\n",
    " \n",
    "    # Printing the model classification accuracy in each fold of the stratified \n",
    "    # cross-validation\n",
    "    print(\"\\nK-Fold accuracy: \", fold_acc)\n",
    "\n",
    "    # Printing the model average accuracy along the stratified k-fold cross-validation \n",
    "    # procedure\n",
    "    print(\"\\nAverage accuracy: \", np.mean(fold_acc))\n",
    "\n",
    "    # Printing the standard deviation of accuracies obtained throughout the \n",
    "    # stratified k-fold cross-validation procedure\n",
    "    print(\"K-Fold Standard deviation: \", np.std(fold_acc))\n",
    " \n",
    "    \n",
    "    print(\"\\nClassification report: \")\n",
    "\n",
    "    # Obtaining the test samples class probabilities\n",
    "    y_prob = model.predict(x_test)\n",
    "\n",
    "    # Obtaining the binary label from the model output probabilities\n",
    "    y_hat = (y_prob > 0.5).astype(int)\n",
    "    \n",
    "    # Printing the classification performance report\n",
    "    report = classification_report(y_test, y_hat, target_names=['sober', 'drunk'])\n",
    "    print(report)\n",
    " \n",
    "    print(\"\\nConfusion Matrix: \")\n",
    "\n",
    "    # Printing the confusion matrix\n",
    "    matrix = confusion_matrix(y_test, y_hat)\n",
    "    print(matrix)\n",
    " \n",
    "    tn, fp, fn, tp = matrix.ravel()\n",
    "    print(\"\\nTrue Negatives: \", tn)\n",
    "    print(\"False Positives: \", fp)\n",
    "    print(\"False Negatives: \", fn)\n",
    "    print(\"True Positives: \", tp)\n",
    "\n",
    "    # Displaying the training process history\n",
    "    visualize_model_history_cv(cv_training_loss, cv_training_acc, cv_val_loss, cv_val_acc)\n",
    "    visualize_model_history(history)\n",
    "    \n",
    "# Running the final model fine-tuning\n",
    "fine_tunning()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.3 ('virtual-env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 142.740099,
   "end_time": "2022-06-30T17:29:23.638330",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-06-30T17:27:00.898231",
   "version": "2.3.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "91dd42dc31c8286e87f4f857c1cf087015eed96189f5f719a42d322017809b0b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
