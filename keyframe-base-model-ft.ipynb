{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8879045b",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2022-05-30T20:08:47.979307Z",
     "iopub.status.busy": "2022-05-30T20:08:47.978788Z",
     "iopub.status.idle": "2022-05-30T20:09:52.510784Z",
     "shell.execute_reply": "2022-05-30T20:09:52.510077Z"
    },
    "papermill": {
     "duration": 64.539305,
     "end_time": "2022-05-30T20:09:52.512661",
     "exception": false,
     "start_time": "2022-05-30T20:08:47.973356",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-30 20:08:54.672005: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-05-30 20:08:54.733784: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-30 20:08:54.857075: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-30 20:08:54.857876: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-30 20:08:57.095258: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-30 20:08:57.096183: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-30 20:08:57.096843: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-30 20:08:57.098263: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /device:GPU:0 with 15403 MB memory:  -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n",
      "2022-05-30 20:08:57.103789: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-30 20:08:57.104617: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-30 20:08:57.105301: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 4204125763408840409\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 16152002560\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 9060463695780192534\n",
      "physical_device_desc: \"device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\"\n",
      "]\n",
      "Num GPUs Available:  1\n",
      "Loading Sober-Drunk Face Dataset, from Patras University\n",
      "\n",
      "Samples total: 80\n",
      "\n",
      "Dataset splitting: \n",
      "\n",
      "Training set: 70\n",
      "Test set: 10\n",
      "\n",
      "MinMax normalization\n",
      "dataset shape:  (70, 128, 160, 3)\n",
      "min:  0.0\n",
      "max:  1.0\n",
      "\n",
      "MinMax normalization\n",
      "dataset shape:  (10, 128, 160, 3)\n",
      "min:  0.0\n",
      "max:  1.0\n",
      "\n",
      " Loading pre-trained model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-30 20:08:57.372874: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-30 20:08:57.373766: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-30 20:08:57.374458: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-30 20:08:57.375163: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-30 20:08:57.375784: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-30 20:08:57.376349: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 15403 MB memory:  -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 128, 160, 3)]     0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 128, 160, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 128, 160, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 64, 80, 64)        0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 64, 80, 128)       73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 64, 80, 128)       147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 32, 40, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 32, 40, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 32, 40, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 32, 40, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 16, 20, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 16, 20, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 16, 20, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 16, 20, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 8, 10, 512)        0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 8, 10, 512)        2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 8, 10, 512)        2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 8, 10, 512)        2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 4, 5, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 10240)             0         \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 1)                 10241     \n",
      "=================================================================\n",
      "Total params: 14,724,929\n",
      "Trainable params: 10,241\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n",
      "input_1: True\n",
      "block1_conv1: False\n",
      "block1_conv2: False\n",
      "block1_pool: False\n",
      "block2_conv1: False\n",
      "block2_conv2: False\n",
      "block2_pool: False\n",
      "block3_conv1: False\n",
      "block3_conv2: False\n",
      "block3_conv3: False\n",
      "block3_pool: False\n",
      "block4_conv1: True\n",
      "block4_conv2: True\n",
      "block4_conv3: True\n",
      "block4_pool: True\n",
      "block5_conv1: True\n",
      "block5_conv2: True\n",
      "block5_conv3: True\n",
      "block5_pool: True\n",
      "flatten: True\n",
      "output: True\n",
      "\n",
      "Re-compiling model...\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 128, 160, 3)]     0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 128, 160, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 128, 160, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 64, 80, 64)        0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 64, 80, 128)       73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 64, 80, 128)       147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 32, 40, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 32, 40, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 32, 40, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 32, 40, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 16, 20, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 16, 20, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 16, 20, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 16, 20, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 8, 10, 512)        0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 8, 10, 512)        2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 8, 10, 512)        2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 8, 10, 512)        2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 4, 5, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 10240)             0         \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 1)                 10241     \n",
      "=================================================================\n",
      "Total params: 14,724,929\n",
      "Trainable params: 12,989,441\n",
      "Non-trainable params: 1,735,488\n",
      "_________________________________________________________________\n",
      "\n",
      "Fitting model...\n",
      "\n",
      "Fold  0\n",
      "\n",
      "Training with 56 samples and validating with 14 samples\n",
      "\n",
      "Epoch 1/205\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-30 20:08:58.710987: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n",
      "2022-05-30 20:09:00.418834: I tensorflow/stream_executor/cuda/cuda_dnn.cc:369] Loaded cuDNN version 8005\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 11s 2s/step - loss: 0.5165 - accuracy: 0.9286 - val_loss: 0.6064 - val_accuracy: 0.8571\n",
      "Epoch 2/205\n",
      "2/2 [==============================] - 0s 75ms/step - loss: 0.5157 - accuracy: 0.9286 - val_loss: 0.6064 - val_accuracy: 0.8571\n",
      "Epoch 3/205\n",
      "2/2 [==============================] - 0s 75ms/step - loss: 0.5149 - accuracy: 0.9286 - val_loss: 0.6064 - val_accuracy: 0.8571\n",
      "Epoch 4/205\n",
      "2/2 [==============================] - 0s 73ms/step - loss: 0.5141 - accuracy: 0.9286 - val_loss: 0.6064 - val_accuracy: 0.8571\n",
      "Epoch 5/205\n",
      "2/2 [==============================] - 0s 77ms/step - loss: 0.5133 - accuracy: 0.9286 - val_loss: 0.6065 - val_accuracy: 0.8571\n",
      "Epoch 6/205\n",
      "2/2 [==============================] - 0s 76ms/step - loss: 0.5126 - accuracy: 0.9286 - val_loss: 0.6065 - val_accuracy: 0.7857\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00006: early stopping\n",
      "1/1 [==============================] - 1s 558ms/step - loss: 0.5573 - accuracy: 0.9000\n",
      "\n",
      "Fold  0\n",
      "\n",
      "Test accuracy:  0.8999999761581421\n",
      "Test loss:  0.557348370552063\n",
      "\n",
      "Fold  1\n",
      "\n",
      "Training with 56 samples and validating with 14 samples\n",
      "\n",
      "Epoch 1/205\n",
      "2/2 [==============================] - 0s 98ms/step - loss: 0.5513 - accuracy: 0.8929 - val_loss: 0.4632 - val_accuracy: 1.0000\n",
      "Epoch 2/205\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 0.5507 - accuracy: 0.8929 - val_loss: 0.4626 - val_accuracy: 1.0000\n",
      "Epoch 3/205\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 0.5501 - accuracy: 0.8929 - val_loss: 0.4620 - val_accuracy: 1.0000\n",
      "Epoch 4/205\n",
      "2/2 [==============================] - 0s 74ms/step - loss: 0.5495 - accuracy: 0.8929 - val_loss: 0.4615 - val_accuracy: 1.0000\n",
      "Epoch 5/205\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 0.5489 - accuracy: 0.8929 - val_loss: 0.4611 - val_accuracy: 1.0000\n",
      "Epoch 6/205\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 0.5483 - accuracy: 0.8929 - val_loss: 0.4607 - val_accuracy: 1.0000\n",
      "Epoch 7/205\n",
      "2/2 [==============================] - 0s 70ms/step - loss: 0.5477 - accuracy: 0.8929 - val_loss: 0.4603 - val_accuracy: 1.0000\n",
      "Epoch 8/205\n",
      "2/2 [==============================] - 0s 73ms/step - loss: 0.5470 - accuracy: 0.8929 - val_loss: 0.4599 - val_accuracy: 1.0000\n",
      "Epoch 9/205\n",
      "2/2 [==============================] - 0s 73ms/step - loss: 0.5464 - accuracy: 0.8929 - val_loss: 0.4596 - val_accuracy: 1.0000\n",
      "Epoch 10/205\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 0.5458 - accuracy: 0.8929 - val_loss: 0.4593 - val_accuracy: 1.0000\n",
      "Epoch 11/205\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 0.5452 - accuracy: 0.8929 - val_loss: 0.4589 - val_accuracy: 1.0000\n",
      "Epoch 12/205\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 0.5446 - accuracy: 0.8929 - val_loss: 0.4586 - val_accuracy: 1.0000\n",
      "Epoch 13/205\n",
      "2/2 [==============================] - 0s 73ms/step - loss: 0.5439 - accuracy: 0.8929 - val_loss: 0.4583 - val_accuracy: 1.0000\n",
      "Epoch 14/205\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 0.5433 - accuracy: 0.8929 - val_loss: 0.4581 - val_accuracy: 1.0000\n",
      "Epoch 15/205\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 0.5427 - accuracy: 0.8929 - val_loss: 0.4578 - val_accuracy: 1.0000\n",
      "Epoch 16/205\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 0.5421 - accuracy: 0.8929 - val_loss: 0.4575 - val_accuracy: 1.0000\n",
      "Epoch 17/205\n",
      "2/2 [==============================] - 0s 74ms/step - loss: 0.5415 - accuracy: 0.8929 - val_loss: 0.4572 - val_accuracy: 1.0000\n",
      "Epoch 18/205\n",
      "2/2 [==============================] - 0s 73ms/step - loss: 0.5408 - accuracy: 0.8929 - val_loss: 0.4569 - val_accuracy: 1.0000\n",
      "Epoch 19/205\n",
      "2/2 [==============================] - 0s 77ms/step - loss: 0.5402 - accuracy: 0.8929 - val_loss: 0.4567 - val_accuracy: 1.0000\n",
      "Epoch 20/205\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 0.5396 - accuracy: 0.8929 - val_loss: 0.4564 - val_accuracy: 1.0000\n",
      "Epoch 21/205\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 0.5390 - accuracy: 0.8929 - val_loss: 0.4561 - val_accuracy: 1.0000\n",
      "Epoch 22/205\n",
      "2/2 [==============================] - 0s 74ms/step - loss: 0.5384 - accuracy: 0.8929 - val_loss: 0.4558 - val_accuracy: 1.0000\n",
      "Epoch 23/205\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 0.5377 - accuracy: 0.9107 - val_loss: 0.4555 - val_accuracy: 1.0000\n",
      "Epoch 24/205\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 0.5371 - accuracy: 0.9107 - val_loss: 0.4553 - val_accuracy: 1.0000\n",
      "Epoch 25/205\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 0.5365 - accuracy: 0.9107 - val_loss: 0.4550 - val_accuracy: 1.0000\n",
      "Epoch 26/205\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 0.5359 - accuracy: 0.9107 - val_loss: 0.4547 - val_accuracy: 1.0000\n",
      "Epoch 27/205\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 0.5353 - accuracy: 0.9107 - val_loss: 0.4544 - val_accuracy: 1.0000\n",
      "Epoch 28/205\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 0.5347 - accuracy: 0.9107 - val_loss: 0.4541 - val_accuracy: 1.0000\n",
      "Epoch 29/205\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 0.5341 - accuracy: 0.9107 - val_loss: 0.4538 - val_accuracy: 1.0000\n",
      "Epoch 30/205\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 0.5335 - accuracy: 0.9107 - val_loss: 0.4536 - val_accuracy: 1.0000\n",
      "Epoch 31/205\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 0.5329 - accuracy: 0.9107 - val_loss: 0.4533 - val_accuracy: 1.0000\n",
      "Epoch 32/205\n",
      "2/2 [==============================] - 0s 77ms/step - loss: 0.5322 - accuracy: 0.9107 - val_loss: 0.4530 - val_accuracy: 1.0000\n",
      "Epoch 33/205\n",
      "2/2 [==============================] - 0s 78ms/step - loss: 0.5316 - accuracy: 0.9107 - val_loss: 0.4527 - val_accuracy: 1.0000\n",
      "Epoch 34/205\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 0.5310 - accuracy: 0.9107 - val_loss: 0.4525 - val_accuracy: 1.0000\n",
      "Epoch 35/205\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 0.5304 - accuracy: 0.9286 - val_loss: 0.4522 - val_accuracy: 1.0000\n",
      "Epoch 36/205\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 0.5298 - accuracy: 0.9286 - val_loss: 0.4519 - val_accuracy: 1.0000\n",
      "Epoch 37/205\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 0.5292 - accuracy: 0.9286 - val_loss: 0.4516 - val_accuracy: 1.0000\n",
      "Epoch 38/205\n",
      "2/2 [==============================] - 0s 70ms/step - loss: 0.5286 - accuracy: 0.9286 - val_loss: 0.4513 - val_accuracy: 1.0000\n",
      "Epoch 39/205\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 0.5280 - accuracy: 0.9286 - val_loss: 0.4511 - val_accuracy: 1.0000\n",
      "Epoch 40/205\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 0.5274 - accuracy: 0.9286 - val_loss: 0.4508 - val_accuracy: 1.0000\n",
      "Epoch 41/205\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 0.5268 - accuracy: 0.9286 - val_loss: 0.4506 - val_accuracy: 1.0000\n",
      "Epoch 42/205\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 0.5262 - accuracy: 0.9286 - val_loss: 0.4503 - val_accuracy: 1.0000\n",
      "Epoch 43/205\n",
      "2/2 [==============================] - 0s 73ms/step - loss: 0.5257 - accuracy: 0.9286 - val_loss: 0.4500 - val_accuracy: 1.0000\n",
      "Epoch 44/205\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 0.5251 - accuracy: 0.9286 - val_loss: 0.4498 - val_accuracy: 1.0000\n",
      "Epoch 45/205\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 0.5245 - accuracy: 0.9286 - val_loss: 0.4495 - val_accuracy: 1.0000\n",
      "Epoch 46/205\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 0.5239 - accuracy: 0.9286 - val_loss: 0.4493 - val_accuracy: 1.0000\n",
      "Epoch 47/205\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 0.5233 - accuracy: 0.9286 - val_loss: 0.4490 - val_accuracy: 1.0000\n",
      "Epoch 48/205\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 0.5227 - accuracy: 0.9286 - val_loss: 0.4487 - val_accuracy: 1.0000\n",
      "Epoch 49/205\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 0.5222 - accuracy: 0.9286 - val_loss: 0.4485 - val_accuracy: 1.0000\n",
      "Epoch 50/205\n",
      "2/2 [==============================] - 0s 74ms/step - loss: 0.5216 - accuracy: 0.9286 - val_loss: 0.4482 - val_accuracy: 1.0000\n",
      "Epoch 51/205\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 0.5210 - accuracy: 0.9286 - val_loss: 0.4480 - val_accuracy: 1.0000\n",
      "Epoch 52/205\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 0.5204 - accuracy: 0.9286 - val_loss: 0.4477 - val_accuracy: 1.0000\n",
      "Epoch 53/205\n",
      "2/2 [==============================] - 0s 73ms/step - loss: 0.5199 - accuracy: 0.9286 - val_loss: 0.4475 - val_accuracy: 1.0000\n",
      "Epoch 54/205\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 0.5193 - accuracy: 0.9286 - val_loss: 0.4472 - val_accuracy: 1.0000\n",
      "Epoch 55/205\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 0.5187 - accuracy: 0.9286 - val_loss: 0.4470 - val_accuracy: 1.0000\n",
      "Epoch 56/205\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 0.5182 - accuracy: 0.9286 - val_loss: 0.4467 - val_accuracy: 1.0000\n",
      "Epoch 57/205\n",
      "2/2 [==============================] - 0s 73ms/step - loss: 0.5176 - accuracy: 0.9286 - val_loss: 0.4465 - val_accuracy: 1.0000\n",
      "Epoch 58/205\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 0.5170 - accuracy: 0.9286 - val_loss: 0.4462 - val_accuracy: 1.0000\n",
      "Epoch 59/205\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 0.5165 - accuracy: 0.9286 - val_loss: 0.4460 - val_accuracy: 1.0000\n",
      "Epoch 60/205\n",
      "2/2 [==============================] - 0s 73ms/step - loss: 0.5159 - accuracy: 0.9286 - val_loss: 0.4457 - val_accuracy: 1.0000\n",
      "Epoch 61/205\n",
      "2/2 [==============================] - 0s 74ms/step - loss: 0.5154 - accuracy: 0.9286 - val_loss: 0.4455 - val_accuracy: 1.0000\n",
      "Epoch 62/205\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 0.5148 - accuracy: 0.9286 - val_loss: 0.4452 - val_accuracy: 1.0000\n",
      "Epoch 63/205\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 0.5142 - accuracy: 0.9286 - val_loss: 0.4450 - val_accuracy: 1.0000\n",
      "Epoch 64/205\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 0.5137 - accuracy: 0.9286 - val_loss: 0.4448 - val_accuracy: 1.0000\n",
      "Epoch 65/205\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 0.5131 - accuracy: 0.9286 - val_loss: 0.4445 - val_accuracy: 1.0000\n",
      "Epoch 66/205\n",
      "2/2 [==============================] - 0s 78ms/step - loss: 0.5126 - accuracy: 0.9286 - val_loss: 0.4443 - val_accuracy: 1.0000\n",
      "Epoch 67/205\n",
      "2/2 [==============================] - 0s 89ms/step - loss: 0.5120 - accuracy: 0.9286 - val_loss: 0.4441 - val_accuracy: 1.0000\n",
      "Epoch 68/205\n",
      "2/2 [==============================] - 0s 84ms/step - loss: 0.5115 - accuracy: 0.9286 - val_loss: 0.4438 - val_accuracy: 1.0000\n",
      "Epoch 69/205\n",
      "2/2 [==============================] - 0s 81ms/step - loss: 0.5109 - accuracy: 0.9286 - val_loss: 0.4436 - val_accuracy: 1.0000\n",
      "Epoch 70/205\n",
      "2/2 [==============================] - 0s 125ms/step - loss: 0.5104 - accuracy: 0.9286 - val_loss: 0.4434 - val_accuracy: 0.9286\n",
      "Epoch 71/205\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 0.5098 - accuracy: 0.9286 - val_loss: 0.4431 - val_accuracy: 0.9286\n",
      "Epoch 72/205\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 0.5093 - accuracy: 0.9464 - val_loss: 0.4429 - val_accuracy: 0.9286\n",
      "Epoch 73/205\n",
      "2/2 [==============================] - 0s 77ms/step - loss: 0.5088 - accuracy: 0.9464 - val_loss: 0.4427 - val_accuracy: 0.9286\n",
      "Epoch 74/205\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 0.5082 - accuracy: 0.9464 - val_loss: 0.4425 - val_accuracy: 0.9286\n",
      "Epoch 75/205\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 0.5077 - accuracy: 0.9464 - val_loss: 0.4422 - val_accuracy: 0.9286\n",
      "Epoch 76/205\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 0.5071 - accuracy: 0.9464 - val_loss: 0.4420 - val_accuracy: 0.9286\n",
      "Epoch 77/205\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 0.5066 - accuracy: 0.9643 - val_loss: 0.4418 - val_accuracy: 0.9286\n",
      "Epoch 78/205\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 0.5061 - accuracy: 0.9643 - val_loss: 0.4416 - val_accuracy: 0.9286\n",
      "Epoch 79/205\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 0.5055 - accuracy: 0.9643 - val_loss: 0.4414 - val_accuracy: 0.9286\n",
      "Epoch 80/205\n",
      "2/2 [==============================] - 0s 77ms/step - loss: 0.5050 - accuracy: 0.9643 - val_loss: 0.4411 - val_accuracy: 0.9286\n",
      "Epoch 81/205\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 0.5045 - accuracy: 0.9643 - val_loss: 0.4409 - val_accuracy: 0.9286\n",
      "Epoch 82/205\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 0.5039 - accuracy: 0.9643 - val_loss: 0.4407 - val_accuracy: 0.9286\n",
      "Epoch 83/205\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 0.5034 - accuracy: 0.9643 - val_loss: 0.4405 - val_accuracy: 0.9286\n",
      "Epoch 84/205\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 0.5028 - accuracy: 0.9643 - val_loss: 0.4402 - val_accuracy: 0.9286\n",
      "Epoch 85/205\n",
      "2/2 [==============================] - 0s 74ms/step - loss: 0.5023 - accuracy: 0.9643 - val_loss: 0.4400 - val_accuracy: 0.9286\n",
      "Epoch 86/205\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 0.5018 - accuracy: 0.9643 - val_loss: 0.4398 - val_accuracy: 0.9286\n",
      "Epoch 87/205\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 0.5012 - accuracy: 0.9643 - val_loss: 0.4396 - val_accuracy: 0.9286\n",
      "Epoch 88/205\n",
      "2/2 [==============================] - 0s 74ms/step - loss: 0.5007 - accuracy: 0.9643 - val_loss: 0.4394 - val_accuracy: 0.9286\n",
      "Epoch 89/205\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 0.5002 - accuracy: 0.9643 - val_loss: 0.4391 - val_accuracy: 0.9286\n",
      "Epoch 90/205\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 0.4996 - accuracy: 0.9643 - val_loss: 0.4389 - val_accuracy: 0.9286\n",
      "Epoch 91/205\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 0.4991 - accuracy: 0.9643 - val_loss: 0.4387 - val_accuracy: 0.9286\n",
      "Epoch 92/205\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 0.4986 - accuracy: 0.9643 - val_loss: 0.4385 - val_accuracy: 0.9286\n",
      "Epoch 93/205\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 0.4980 - accuracy: 0.9643 - val_loss: 0.4382 - val_accuracy: 0.9286\n",
      "Epoch 94/205\n",
      "2/2 [==============================] - 0s 73ms/step - loss: 0.4975 - accuracy: 0.9643 - val_loss: 0.4380 - val_accuracy: 0.9286\n",
      "Epoch 95/205\n",
      "2/2 [==============================] - 0s 73ms/step - loss: 0.4970 - accuracy: 0.9643 - val_loss: 0.4378 - val_accuracy: 0.9286\n",
      "Epoch 96/205\n",
      "2/2 [==============================] - 0s 73ms/step - loss: 0.4965 - accuracy: 0.9643 - val_loss: 0.4376 - val_accuracy: 0.9286\n",
      "Epoch 97/205\n",
      "2/2 [==============================] - 0s 73ms/step - loss: 0.4959 - accuracy: 0.9643 - val_loss: 0.4374 - val_accuracy: 0.9286\n",
      "Epoch 98/205\n",
      "2/2 [==============================] - 0s 81ms/step - loss: 0.4954 - accuracy: 0.9643 - val_loss: 0.4371 - val_accuracy: 0.9286\n",
      "Epoch 99/205\n",
      "2/2 [==============================] - 0s 77ms/step - loss: 0.4949 - accuracy: 0.9643 - val_loss: 0.4369 - val_accuracy: 0.9286\n",
      "Epoch 100/205\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 0.4943 - accuracy: 0.9643 - val_loss: 0.4367 - val_accuracy: 0.9286\n",
      "Epoch 101/205\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 0.4938 - accuracy: 0.9643 - val_loss: 0.4365 - val_accuracy: 0.9286\n",
      "Epoch 102/205\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 0.4933 - accuracy: 0.9643 - val_loss: 0.4363 - val_accuracy: 0.9286\n",
      "Epoch 103/205\n",
      "2/2 [==============================] - 0s 73ms/step - loss: 0.4928 - accuracy: 0.9643 - val_loss: 0.4360 - val_accuracy: 0.9286\n",
      "Epoch 104/205\n",
      "2/2 [==============================] - 0s 77ms/step - loss: 0.4923 - accuracy: 0.9643 - val_loss: 0.4358 - val_accuracy: 0.9286\n",
      "Epoch 105/205\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 0.4917 - accuracy: 0.9643 - val_loss: 0.4356 - val_accuracy: 0.9286\n",
      "Epoch 106/205\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 0.4912 - accuracy: 0.9643 - val_loss: 0.4354 - val_accuracy: 0.9286\n",
      "Epoch 107/205\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 0.4907 - accuracy: 0.9643 - val_loss: 0.4352 - val_accuracy: 0.9286\n",
      "Epoch 108/205\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 0.4902 - accuracy: 0.9643 - val_loss: 0.4349 - val_accuracy: 0.9286\n",
      "Epoch 109/205\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 0.4896 - accuracy: 0.9643 - val_loss: 0.4347 - val_accuracy: 0.9286\n",
      "Epoch 110/205\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 0.4891 - accuracy: 0.9643 - val_loss: 0.4345 - val_accuracy: 0.9286\n",
      "Epoch 111/205\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 0.4886 - accuracy: 0.9643 - val_loss: 0.4343 - val_accuracy: 0.9286\n",
      "Epoch 112/205\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 0.4881 - accuracy: 0.9643 - val_loss: 0.4340 - val_accuracy: 0.9286\n",
      "Epoch 113/205\n",
      "2/2 [==============================] - 0s 74ms/step - loss: 0.4875 - accuracy: 0.9643 - val_loss: 0.4338 - val_accuracy: 0.9286\n",
      "Epoch 114/205\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 0.4870 - accuracy: 0.9643 - val_loss: 0.4336 - val_accuracy: 0.9286\n",
      "Epoch 115/205\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 0.4865 - accuracy: 0.9643 - val_loss: 0.4334 - val_accuracy: 0.9286\n",
      "Epoch 116/205\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 0.4860 - accuracy: 0.9643 - val_loss: 0.4332 - val_accuracy: 0.9286\n",
      "Epoch 117/205\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 0.4855 - accuracy: 0.9643 - val_loss: 0.4330 - val_accuracy: 0.9286\n",
      "Epoch 118/205\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 0.4849 - accuracy: 0.9643 - val_loss: 0.4327 - val_accuracy: 0.9286\n",
      "Epoch 119/205\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 0.4844 - accuracy: 0.9643 - val_loss: 0.4325 - val_accuracy: 0.9286\n",
      "Epoch 120/205\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 0.4839 - accuracy: 0.9643 - val_loss: 0.4323 - val_accuracy: 0.9286\n",
      "Epoch 121/205\n",
      "2/2 [==============================] - 0s 73ms/step - loss: 0.4834 - accuracy: 0.9643 - val_loss: 0.4321 - val_accuracy: 0.9286\n",
      "Epoch 122/205\n",
      "2/2 [==============================] - 0s 73ms/step - loss: 0.4829 - accuracy: 0.9643 - val_loss: 0.4319 - val_accuracy: 0.9286\n",
      "Epoch 123/205\n",
      "2/2 [==============================] - 0s 74ms/step - loss: 0.4823 - accuracy: 0.9643 - val_loss: 0.4317 - val_accuracy: 0.9286\n",
      "Epoch 124/205\n",
      "2/2 [==============================] - 0s 73ms/step - loss: 0.4818 - accuracy: 0.9643 - val_loss: 0.4314 - val_accuracy: 0.9286\n",
      "Epoch 125/205\n",
      "2/2 [==============================] - 0s 75ms/step - loss: 0.4813 - accuracy: 0.9643 - val_loss: 0.4312 - val_accuracy: 0.9286\n",
      "Epoch 126/205\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 0.4808 - accuracy: 0.9643 - val_loss: 0.4310 - val_accuracy: 0.9286\n",
      "Epoch 127/205\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 0.4803 - accuracy: 0.9643 - val_loss: 0.4308 - val_accuracy: 0.9286\n",
      "Epoch 128/205\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 0.4798 - accuracy: 0.9643 - val_loss: 0.4306 - val_accuracy: 0.9286\n",
      "Epoch 129/205\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 0.4792 - accuracy: 0.9643 - val_loss: 0.4304 - val_accuracy: 0.9286\n",
      "Epoch 130/205\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 0.4787 - accuracy: 0.9643 - val_loss: 0.4301 - val_accuracy: 0.9286\n",
      "Epoch 131/205\n",
      "2/2 [==============================] - 0s 73ms/step - loss: 0.4782 - accuracy: 0.9643 - val_loss: 0.4299 - val_accuracy: 0.9286\n",
      "Epoch 132/205\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 0.4777 - accuracy: 0.9643 - val_loss: 0.4297 - val_accuracy: 0.9286\n",
      "Epoch 133/205\n",
      "2/2 [==============================] - 0s 73ms/step - loss: 0.4772 - accuracy: 0.9643 - val_loss: 0.4295 - val_accuracy: 0.9286\n",
      "Epoch 134/205\n",
      "2/2 [==============================] - 0s 73ms/step - loss: 0.4767 - accuracy: 0.9643 - val_loss: 0.4293 - val_accuracy: 0.9286\n",
      "Epoch 135/205\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 0.4761 - accuracy: 0.9643 - val_loss: 0.4291 - val_accuracy: 0.9286\n",
      "Epoch 136/205\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 0.4756 - accuracy: 0.9643 - val_loss: 0.4289 - val_accuracy: 0.9286\n",
      "Epoch 137/205\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 0.4751 - accuracy: 0.9643 - val_loss: 0.4286 - val_accuracy: 0.9286\n",
      "Epoch 138/205\n",
      "2/2 [==============================] - 0s 93ms/step - loss: 0.4746 - accuracy: 0.9643 - val_loss: 0.4284 - val_accuracy: 0.9286\n",
      "Epoch 139/205\n",
      "2/2 [==============================] - 0s 82ms/step - loss: 0.4741 - accuracy: 0.9643 - val_loss: 0.4282 - val_accuracy: 0.9286\n",
      "Epoch 140/205\n",
      "2/2 [==============================] - 0s 86ms/step - loss: 0.4736 - accuracy: 0.9643 - val_loss: 0.4280 - val_accuracy: 0.9286\n",
      "Epoch 141/205\n",
      "2/2 [==============================] - 0s 89ms/step - loss: 0.4731 - accuracy: 0.9643 - val_loss: 0.4278 - val_accuracy: 0.9286\n",
      "Epoch 142/205\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 0.4725 - accuracy: 0.9643 - val_loss: 0.4276 - val_accuracy: 0.9286\n",
      "Epoch 143/205\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 0.4720 - accuracy: 0.9643 - val_loss: 0.4273 - val_accuracy: 0.9286\n",
      "Epoch 144/205\n",
      "2/2 [==============================] - 0s 76ms/step - loss: 0.4715 - accuracy: 0.9643 - val_loss: 0.4271 - val_accuracy: 0.9286\n",
      "Epoch 145/205\n",
      "2/2 [==============================] - 0s 73ms/step - loss: 0.4710 - accuracy: 0.9643 - val_loss: 0.4269 - val_accuracy: 0.9286\n",
      "Epoch 146/205\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 0.4705 - accuracy: 0.9643 - val_loss: 0.4267 - val_accuracy: 0.9286\n",
      "Epoch 147/205\n",
      "2/2 [==============================] - 0s 70ms/step - loss: 0.4700 - accuracy: 0.9643 - val_loss: 0.4265 - val_accuracy: 0.9286\n",
      "Epoch 148/205\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 0.4695 - accuracy: 0.9643 - val_loss: 0.4263 - val_accuracy: 0.9286\n",
      "Epoch 149/205\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 0.4690 - accuracy: 0.9643 - val_loss: 0.4261 - val_accuracy: 0.9286\n",
      "Epoch 150/205\n",
      "2/2 [==============================] - 0s 73ms/step - loss: 0.4685 - accuracy: 0.9643 - val_loss: 0.4259 - val_accuracy: 0.9286\n",
      "Epoch 151/205\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 0.4679 - accuracy: 0.9643 - val_loss: 0.4257 - val_accuracy: 0.9286\n",
      "Epoch 152/205\n",
      "2/2 [==============================] - 0s 73ms/step - loss: 0.4674 - accuracy: 0.9643 - val_loss: 0.4255 - val_accuracy: 0.9286\n",
      "Epoch 153/205\n",
      "2/2 [==============================] - 0s 73ms/step - loss: 0.4669 - accuracy: 0.9643 - val_loss: 0.4253 - val_accuracy: 0.9286\n",
      "Epoch 154/205\n",
      "2/2 [==============================] - 0s 74ms/step - loss: 0.4664 - accuracy: 0.9643 - val_loss: 0.4251 - val_accuracy: 0.9286\n",
      "Epoch 155/205\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 0.4659 - accuracy: 0.9643 - val_loss: 0.4249 - val_accuracy: 0.9286\n",
      "Epoch 156/205\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 0.4654 - accuracy: 0.9643 - val_loss: 0.4247 - val_accuracy: 0.9286\n",
      "Epoch 157/205\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 0.4649 - accuracy: 0.9643 - val_loss: 0.4245 - val_accuracy: 0.9286\n",
      "Epoch 158/205\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 0.4644 - accuracy: 0.9643 - val_loss: 0.4243 - val_accuracy: 0.9286\n",
      "Epoch 159/205\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 0.4639 - accuracy: 0.9643 - val_loss: 0.4241 - val_accuracy: 0.9286\n",
      "Epoch 160/205\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 0.4634 - accuracy: 0.9643 - val_loss: 0.4239 - val_accuracy: 0.9286\n",
      "Epoch 161/205\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 0.4629 - accuracy: 0.9643 - val_loss: 0.4237 - val_accuracy: 0.9286\n",
      "Epoch 162/205\n",
      "2/2 [==============================] - 0s 119ms/step - loss: 0.4624 - accuracy: 0.9643 - val_loss: 0.4235 - val_accuracy: 0.9286\n",
      "Epoch 163/205\n",
      "2/2 [==============================] - 0s 86ms/step - loss: 0.4618 - accuracy: 0.9643 - val_loss: 0.4233 - val_accuracy: 0.9286\n",
      "Epoch 164/205\n",
      "2/2 [==============================] - 0s 73ms/step - loss: 0.4613 - accuracy: 0.9643 - val_loss: 0.4231 - val_accuracy: 0.9286\n",
      "Epoch 165/205\n",
      "2/2 [==============================] - 0s 76ms/step - loss: 0.4608 - accuracy: 0.9643 - val_loss: 0.4229 - val_accuracy: 0.9286\n",
      "Epoch 166/205\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 0.4603 - accuracy: 0.9643 - val_loss: 0.4227 - val_accuracy: 0.9286\n",
      "Epoch 167/205\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 0.4598 - accuracy: 0.9643 - val_loss: 0.4225 - val_accuracy: 0.9286\n",
      "Epoch 168/205\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 0.4593 - accuracy: 0.9643 - val_loss: 0.4223 - val_accuracy: 0.9286\n",
      "Epoch 169/205\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 0.4588 - accuracy: 0.9643 - val_loss: 0.4221 - val_accuracy: 0.9286\n",
      "Epoch 170/205\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 0.4583 - accuracy: 0.9643 - val_loss: 0.4219 - val_accuracy: 0.9286\n",
      "Epoch 171/205\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 0.4578 - accuracy: 0.9643 - val_loss: 0.4217 - val_accuracy: 0.9286\n",
      "Epoch 172/205\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 0.4573 - accuracy: 0.9643 - val_loss: 0.4215 - val_accuracy: 0.9286\n",
      "Epoch 173/205\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 0.4568 - accuracy: 0.9643 - val_loss: 0.4213 - val_accuracy: 0.9286\n",
      "Epoch 174/205\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 0.4563 - accuracy: 0.9643 - val_loss: 0.4212 - val_accuracy: 0.9286\n",
      "Epoch 175/205\n",
      "2/2 [==============================] - 0s 104ms/step - loss: 0.4558 - accuracy: 0.9643 - val_loss: 0.4210 - val_accuracy: 0.9286\n",
      "Epoch 176/205\n",
      "2/2 [==============================] - 0s 99ms/step - loss: 0.4553 - accuracy: 0.9643 - val_loss: 0.4208 - val_accuracy: 0.9286\n",
      "Epoch 177/205\n",
      "2/2 [==============================] - 0s 93ms/step - loss: 0.4548 - accuracy: 0.9643 - val_loss: 0.4206 - val_accuracy: 0.9286\n",
      "Epoch 178/205\n",
      "2/2 [==============================] - 0s 79ms/step - loss: 0.4543 - accuracy: 0.9643 - val_loss: 0.4204 - val_accuracy: 0.9286\n",
      "Epoch 179/205\n",
      "2/2 [==============================] - 0s 80ms/step - loss: 0.4538 - accuracy: 0.9643 - val_loss: 0.4202 - val_accuracy: 0.9286\n",
      "Epoch 180/205\n",
      "2/2 [==============================] - 0s 79ms/step - loss: 0.4533 - accuracy: 0.9643 - val_loss: 0.4200 - val_accuracy: 0.9286\n",
      "Epoch 181/205\n",
      "2/2 [==============================] - 0s 79ms/step - loss: 0.4528 - accuracy: 0.9643 - val_loss: 0.4198 - val_accuracy: 0.9286\n",
      "Epoch 182/205\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 0.4523 - accuracy: 0.9643 - val_loss: 0.4196 - val_accuracy: 0.9286\n",
      "Epoch 183/205\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 0.4518 - accuracy: 0.9643 - val_loss: 0.4194 - val_accuracy: 0.9286\n",
      "Epoch 184/205\n",
      "2/2 [==============================] - 0s 73ms/step - loss: 0.4513 - accuracy: 0.9643 - val_loss: 0.4192 - val_accuracy: 0.9286\n",
      "Epoch 185/205\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 0.4508 - accuracy: 0.9643 - val_loss: 0.4191 - val_accuracy: 0.9286\n",
      "Epoch 186/205\n",
      "2/2 [==============================] - 0s 70ms/step - loss: 0.4503 - accuracy: 0.9643 - val_loss: 0.4189 - val_accuracy: 0.9286\n",
      "Epoch 187/205\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 0.4498 - accuracy: 0.9643 - val_loss: 0.4187 - val_accuracy: 0.9286\n",
      "Epoch 188/205\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 0.4493 - accuracy: 0.9821 - val_loss: 0.4185 - val_accuracy: 0.9286\n",
      "Epoch 189/205\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 0.4488 - accuracy: 0.9821 - val_loss: 0.4183 - val_accuracy: 0.8571\n",
      "Epoch 190/205\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 0.4483 - accuracy: 0.9821 - val_loss: 0.4181 - val_accuracy: 0.8571\n",
      "Epoch 191/205\n",
      "2/2 [==============================] - 0s 74ms/step - loss: 0.4479 - accuracy: 0.9821 - val_loss: 0.4179 - val_accuracy: 0.8571\n",
      "Epoch 192/205\n",
      "2/2 [==============================] - 0s 73ms/step - loss: 0.4474 - accuracy: 0.9821 - val_loss: 0.4177 - val_accuracy: 0.8571\n",
      "Epoch 193/205\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 0.4469 - accuracy: 0.9821 - val_loss: 0.4175 - val_accuracy: 0.8571\n",
      "Epoch 194/205\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 0.4464 - accuracy: 0.9821 - val_loss: 0.4174 - val_accuracy: 0.8571\n",
      "Epoch 195/205\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 0.4459 - accuracy: 0.9821 - val_loss: 0.4172 - val_accuracy: 0.8571\n",
      "Epoch 196/205\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 0.4454 - accuracy: 0.9821 - val_loss: 0.4170 - val_accuracy: 0.8571\n",
      "Epoch 197/205\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 0.4449 - accuracy: 0.9821 - val_loss: 0.4168 - val_accuracy: 0.8571\n",
      "Epoch 198/205\n",
      "2/2 [==============================] - 0s 76ms/step - loss: 0.4444 - accuracy: 0.9821 - val_loss: 0.4166 - val_accuracy: 0.8571\n",
      "Epoch 199/205\n",
      "2/2 [==============================] - 0s 73ms/step - loss: 0.4439 - accuracy: 0.9821 - val_loss: 0.4164 - val_accuracy: 0.8571\n",
      "Epoch 200/205\n",
      "2/2 [==============================] - 0s 73ms/step - loss: 0.4434 - accuracy: 0.9821 - val_loss: 0.4162 - val_accuracy: 0.8571\n",
      "Epoch 201/205\n",
      "2/2 [==============================] - 0s 73ms/step - loss: 0.4429 - accuracy: 0.9821 - val_loss: 0.4161 - val_accuracy: 0.8571\n",
      "Epoch 202/205\n",
      "2/2 [==============================] - 0s 75ms/step - loss: 0.4424 - accuracy: 0.9821 - val_loss: 0.4159 - val_accuracy: 0.8571\n",
      "Epoch 203/205\n",
      "2/2 [==============================] - 0s 75ms/step - loss: 0.4419 - accuracy: 0.9821 - val_loss: 0.4157 - val_accuracy: 0.8571\n",
      "Epoch 204/205\n",
      "2/2 [==============================] - 0s 74ms/step - loss: 0.4414 - accuracy: 0.9821 - val_loss: 0.4155 - val_accuracy: 0.8571\n",
      "Epoch 205/205\n",
      "2/2 [==============================] - 0s 74ms/step - loss: 0.4410 - accuracy: 0.9821 - val_loss: 0.4153 - val_accuracy: 0.8571\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.5325 - accuracy: 0.9000\n",
      "\n",
      "Fold  1\n",
      "\n",
      "Test accuracy:  0.8999999761581421\n",
      "Test loss:  0.5325409770011902\n",
      "\n",
      "Fold  2\n",
      "\n",
      "Training with 56 samples and validating with 14 samples\n",
      "\n",
      "Epoch 1/205\n",
      "2/2 [==============================] - 0s 142ms/step - loss: 0.4396 - accuracy: 0.9643 - val_loss: 0.4184 - val_accuracy: 0.9286\n",
      "Epoch 2/205\n",
      "2/2 [==============================] - 0s 86ms/step - loss: 0.4391 - accuracy: 0.9643 - val_loss: 0.4181 - val_accuracy: 0.9286\n",
      "Epoch 3/205\n",
      "2/2 [==============================] - 0s 83ms/step - loss: 0.4386 - accuracy: 0.9643 - val_loss: 0.4180 - val_accuracy: 0.9286\n",
      "Epoch 4/205\n",
      "2/2 [==============================] - 0s 73ms/step - loss: 0.4380 - accuracy: 0.9643 - val_loss: 0.4179 - val_accuracy: 0.9286\n",
      "Epoch 5/205\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 0.4374 - accuracy: 0.9643 - val_loss: 0.4178 - val_accuracy: 0.9286\n",
      "Epoch 6/205\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 0.4368 - accuracy: 0.9643 - val_loss: 0.4178 - val_accuracy: 0.9286\n",
      "Epoch 7/205\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 0.4361 - accuracy: 0.9643 - val_loss: 0.4178 - val_accuracy: 0.9286\n",
      "Epoch 8/205\n",
      "2/2 [==============================] - 0s 70ms/step - loss: 0.4355 - accuracy: 0.9643 - val_loss: 0.4178 - val_accuracy: 0.9286\n",
      "Epoch 9/205\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 0.4349 - accuracy: 0.9643 - val_loss: 0.4178 - val_accuracy: 0.9286\n",
      "Epoch 10/205\n",
      "2/2 [==============================] - 0s 73ms/step - loss: 0.4342 - accuracy: 0.9643 - val_loss: 0.4179 - val_accuracy: 0.9286\n",
      "Epoch 11/205\n",
      "2/2 [==============================] - 0s 74ms/step - loss: 0.4336 - accuracy: 0.9643 - val_loss: 0.4180 - val_accuracy: 0.9286\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00011: early stopping\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.5314 - accuracy: 0.9000\n",
      "\n",
      "Fold  2\n",
      "\n",
      "Test accuracy:  0.8999999761581421\n",
      "Test loss:  0.5313879251480103\n",
      "\n",
      "Fold  3\n",
      "\n",
      "Training with 56 samples and validating with 14 samples\n",
      "\n",
      "Epoch 1/205\n",
      "2/2 [==============================] - 0s 94ms/step - loss: 0.4392 - accuracy: 0.9464 - val_loss: 0.4054 - val_accuracy: 1.0000\n",
      "Epoch 2/205\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 0.4387 - accuracy: 0.9464 - val_loss: 0.4049 - val_accuracy: 1.0000\n",
      "Epoch 3/205\n",
      "2/2 [==============================] - 0s 74ms/step - loss: 0.4382 - accuracy: 0.9464 - val_loss: 0.4045 - val_accuracy: 1.0000\n",
      "Epoch 4/205\n",
      "2/2 [==============================] - 0s 74ms/step - loss: 0.4376 - accuracy: 0.9464 - val_loss: 0.4042 - val_accuracy: 1.0000\n",
      "Epoch 5/205\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 0.4371 - accuracy: 0.9464 - val_loss: 0.4040 - val_accuracy: 1.0000\n",
      "Epoch 6/205\n",
      "2/2 [==============================] - 0s 73ms/step - loss: 0.4365 - accuracy: 0.9464 - val_loss: 0.4039 - val_accuracy: 1.0000\n",
      "Epoch 7/205\n",
      "2/2 [==============================] - 0s 74ms/step - loss: 0.4360 - accuracy: 0.9464 - val_loss: 0.4038 - val_accuracy: 1.0000\n",
      "Epoch 8/205\n",
      "2/2 [==============================] - 0s 73ms/step - loss: 0.4354 - accuracy: 0.9464 - val_loss: 0.4037 - val_accuracy: 1.0000\n",
      "Epoch 9/205\n",
      "2/2 [==============================] - 0s 77ms/step - loss: 0.4348 - accuracy: 0.9464 - val_loss: 0.4037 - val_accuracy: 1.0000\n",
      "Epoch 10/205\n",
      "2/2 [==============================] - 0s 74ms/step - loss: 0.4343 - accuracy: 0.9464 - val_loss: 0.4037 - val_accuracy: 1.0000\n",
      "Epoch 11/205\n",
      "2/2 [==============================] - 0s 73ms/step - loss: 0.4337 - accuracy: 0.9464 - val_loss: 0.4038 - val_accuracy: 1.0000\n",
      "Epoch 12/205\n",
      "2/2 [==============================] - 0s 70ms/step - loss: 0.4331 - accuracy: 0.9464 - val_loss: 0.4038 - val_accuracy: 1.0000\n",
      "Epoch 13/205\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 0.4326 - accuracy: 0.9464 - val_loss: 0.4039 - val_accuracy: 1.0000\n",
      "Epoch 14/205\n",
      "2/2 [==============================] - 0s 70ms/step - loss: 0.4320 - accuracy: 0.9464 - val_loss: 0.4039 - val_accuracy: 1.0000\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00014: early stopping\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.5300 - accuracy: 0.9000\n",
      "\n",
      "Fold  3\n",
      "\n",
      "Test accuracy:  0.8999999761581421\n",
      "Test loss:  0.5300045013427734\n",
      "\n",
      "Fold  4\n",
      "\n",
      "Training with 56 samples and validating with 14 samples\n",
      "\n",
      "Epoch 1/205\n",
      "2/2 [==============================] - 0s 97ms/step - loss: 0.4325 - accuracy: 0.9464 - val_loss: 0.4105 - val_accuracy: 1.0000\n",
      "Epoch 2/205\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 0.4320 - accuracy: 0.9464 - val_loss: 0.4101 - val_accuracy: 1.0000\n",
      "Epoch 3/205\n",
      "2/2 [==============================] - 0s 73ms/step - loss: 0.4315 - accuracy: 0.9464 - val_loss: 0.4099 - val_accuracy: 1.0000\n",
      "Epoch 4/205\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 0.4310 - accuracy: 0.9464 - val_loss: 0.4096 - val_accuracy: 1.0000\n",
      "Epoch 5/205\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 0.4305 - accuracy: 0.9464 - val_loss: 0.4095 - val_accuracy: 1.0000\n",
      "Epoch 6/205\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 0.4299 - accuracy: 0.9464 - val_loss: 0.4094 - val_accuracy: 1.0000\n",
      "Epoch 7/205\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 0.4293 - accuracy: 0.9464 - val_loss: 0.4094 - val_accuracy: 1.0000\n",
      "Epoch 8/205\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 0.4287 - accuracy: 0.9464 - val_loss: 0.4094 - val_accuracy: 1.0000\n",
      "Epoch 9/205\n",
      "2/2 [==============================] - 0s 75ms/step - loss: 0.4281 - accuracy: 0.9464 - val_loss: 0.4094 - val_accuracy: 1.0000\n",
      "Epoch 10/205\n",
      "2/2 [==============================] - 0s 74ms/step - loss: 0.4275 - accuracy: 0.9464 - val_loss: 0.4094 - val_accuracy: 1.0000\n",
      "Epoch 11/205\n",
      "2/2 [==============================] - 0s 73ms/step - loss: 0.4269 - accuracy: 0.9464 - val_loss: 0.4095 - val_accuracy: 1.0000\n",
      "Epoch 12/205\n",
      "2/2 [==============================] - 0s 78ms/step - loss: 0.4263 - accuracy: 0.9464 - val_loss: 0.4096 - val_accuracy: 1.0000\n",
      "Epoch 13/205\n",
      "2/2 [==============================] - 0s 73ms/step - loss: 0.4256 - accuracy: 0.9464 - val_loss: 0.4097 - val_accuracy: 1.0000\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00013: early stopping\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.5289 - accuracy: 0.9000\n",
      "\n",
      "Fold  4\n",
      "\n",
      "Test accuracy:  0.8999999761581421\n",
      "Test loss:  0.5289499163627625\n",
      "\n",
      "K-Fold accuracy:  [0.8999999761581421, 0.8999999761581421, 0.8999999761581421, 0.8999999761581421, 0.8999999761581421]\n",
      "\n",
      "Average accuracy:  0.8999999761581421\n",
      "K-Fold Standard deviation:  0.0\n",
      "\n",
      "Classification report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       sober       0.83      1.00      0.91         5\n",
      "       drunk       1.00      0.80      0.89         5\n",
      "\n",
      "    accuracy                           0.90        10\n",
      "   macro avg       0.92      0.90      0.90        10\n",
      "weighted avg       0.92      0.90      0.90        10\n",
      "\n",
      "\n",
      "AUC ROC: \n",
      "0.9600000000000001\n",
      "\n",
      "Confusion Matrix: \n",
      "[[5 0]\n",
      " [1 4]]\n",
      "\n",
      "True Negatives:  5\n",
      "False Positives:  0\n",
      "False Negatives:  1\n",
      "True Positives:  4\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY4AAAEWCAYAAABxMXBSAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAAsTAAALEwEAmpwYAAAni0lEQVR4nO3deXxc5X3v8c9Po9XSSLJkydaGZcAL3ghBoSQkKUtJSaGYFpLipgk0vUmbXhKyl+QmN2S5bZJLaULLzS1ZILsvl5QbJ4RCkuKsJSA27xhjbCzJljesxbb23/3jnBmNZEnWsTQeLd/363VeM+c5yzwH5PnOc57znGPujoiIyHhlZboCIiIyvSg4REQkEgWHiIhEouAQEZFIFBwiIhKJgkNERCJRcIikiZnVm5mbWfY41r3ZzH490f2InAkKDhHAzHabWY+ZzRtW/kz4pV2foaqJTDkKDpFBLwFrEzNmtgqYk7nqiExNCg6RQd8G3pEyfxPwrdQVzKzEzL5lZgfNbI+ZfcLMssJlMTO7w8wOmdku4OoRtv26me0zs2Yz+5yZxaJW0syqzWy9mR0xs51m9q6UZReZWaOZtZtZq5ndGZbnm9l3zOywmR01syfNbH7UzxYBBYdIqseBYjM7L/xCvxH4zrB1/hkoAc4Gfp8gaP4yXPYu4BrgAqABuGHYtvcBfcC54TpvAv7LadRzHdAEVIef8fdmdnm47MvAl929GDgHuD8svymsdx1QDvwNcOI0PltEwSEyTKLVcSWwDWhOLEgJk4+5e4e77wb+EXh7uMpbgS+5+153PwL8Q8q284E/At7v7sfc/QDwT+H+xs3M6oBLgL9z9y53fxb4GoMtpV7gXDOb5+6d7v54Snk5cK6797v7U+7eHuWzRRIUHCJDfRv4c+Bmhp2mAuYBOcCelLI9QE34vhrYO2xZwsJw233hqaKjwL8ClRHrVw0ccfeOUerwV8ASYHt4OuqalON6BFhnZi1m9kUzy4n42SKAgkNkCHffQ9BJ/kfAvw1bfIjgl/vClLKzGGyV7CM4FZS6LGEv0A3Mc/fScCp29xURq9gClJlZfKQ6uPsL7r6WIJC+ADxgZoXu3uvun3b35cDrCE6pvQOR06DgEDnZXwGXu/ux1EJ37yfoM/gfZhY3s4XABxnsB7kfeJ+Z1ZrZXOC2lG33AY8C/2hmxWaWZWbnmNnvR6mYu+8Ffgv8Q9jhvTqs73cAzOwvzKzC3QeAo+FmA2Z2mZmtCk+3tRME4ECUzxZJUHCIDOPuL7p74yiL3wscA3YBvwa+B3wjXPZVgtNBzwFPc3KL5R1ALrAVeAV4AKg6jSquBeoJWh8PAp9y95+Fy64CtphZJ0FH+Y3ufgJYEH5eO0HfzS8ITl+JRGZ6kJOIiEShFoeIiESi4BARkUgUHCIiEomCQ0REIpkVt2meN2+e19fXZ7oaIiLTylNPPXXI3SuGl8+K4Kivr6excbSrK0VEZCRmtmekcp2qEhGRSBQcIiISiYJDREQimRV9HCIiUfX29tLU1ERXV1emq5J2+fn51NbWkpMzvhsmKzhEREbQ1NREPB6nvr4eM8t0ddLG3Tl8+DBNTU0sWrRoXNvoVJWIyAi6urooLy+f0aEBYGaUl5dHalkpOERERjHTQyMh6nHqVNUY7vvNSzhwTkUR51QWUVWcT1bW7PhDEhEZjYJjDN974mV2tHYm5wtyYpxdURgESUVR8v3ZFYXk58QyWFMRmUkOHz7MFVdcAcD+/fuJxWJUVAQDuJ944glyc3NH3baxsZFvfetb3HXXXWmrn4JjDI+8/40c7OzmxQPH2HWokxcPHOPFg508/fIr/GhjC4lHmZhBTWnBSYFyTmUhFUV5s6a5KyKTo7y8nGeffRaA22+/naKiIj784Q8nl/f19ZGdPfLXd0NDAw0NDWmtn4JjDGZGZTyfyng+rz2nfMiyEz39vHRoaKC8eLCTJ146wone/uR68fzskwLl3MpCziorJDdbXUwiMj4333wz+fn5PPPMM1xyySXceOON3HrrrXR1dVFQUMC9997L0qVL2bBhA3fccQc//vGPuf3223n55ZfZtWsXL7/8Mu9///t53/veN+G6KDhOU0FujOXVxSyvLh5SPjDg7G/vCoLkQCcvHgxC5dc7D/KDp5uS68WyjIVlc4IwqSxiSWWcJfPjnFtZREGuTnuJTCWf/tEWtra0T+o+l1cX86k/XhFpm6amJn77298Si8Vob2/nV7/6FdnZ2fzsZz/j4x//OD/4wQ9O2mb79u089thjdHR0sHTpUt7znveMe7zGaBQckywry6guLaC6tIA3LB56U8mOrl5eOhS2TsJWyq6Dx/jljkP09A8AwWmvs8rmsLgyztIFRSyZH2dxZZxzKgvJy1agiMxmb3nLW4jFgu+BtrY2brrpJl544QXMjN7e3hG3ufrqq8nLyyMvL4/KykpaW1upra2dUD0UHGdQPD+H1bWlrK4tHVLe1z/A7sPHeaG1g+dbO3ihtZPnWzt47PkD9A8EHSmxLGNh+ZygZbIgzpL5RSydH6d+XiE5MZ3yEkmnqC2DdCksLEy+/+QnP8lll13Ggw8+yO7du7n00ktH3CYvLy/5PhaL0dfXN+F6KDimgOxYFudWFnFuZRFvXlWVLO/pG+ClQ8fCMOlgRxgsj27dT5gn5MSMRfMKWTI/Hk5BK2VheSExXTosMmO1tbVRU1MDwH333XdGP1vBMYXlZmexdEGcpQviQ8q7evvZeaCTFw50sKO1kx37O3iu6Sg/3rhvyLbnVBSxdH4Ri8NQWbYgTu3cAl3lJTIDfPSjH+Wmm27ic5/7HFdfffUZ/WzzxDWlM1hDQ4PPhgc5HevuY+eBTnaErZMdrZ280NpBS9vgrQTiedksXRBnWVWc86qKWbagmKUL4hTl6TeESKpt27Zx3nnnZboaZ8xIx2tmT7n7Sdf26ttiBinMy+b8ulLOrysdUt7e1csLrR1s39/B9n0dbN/fzg+faeE7j7+cXOessjksWxBnWVUx54WvC8vmaKS8iJxEwTELFOfncOHCMi5cWJYsc3eaj55IBsm2/R1s39fOz7a1JvtPCnJiLFkQZ3lVnGULioNgWVBMyZyJXconItObgmOWMjNq586hdu4c/mD5/GR5V28/O1qDlsm2/e1s39fBw5v38/0n9ibXqS7JZ1lVcbKFsrwqTn15Idm6uktkVlBwyBD5ObGTLhl2dw50dLNtX3t4uit4/eWOg/SFzZPc7CyWzC/ivAXBoMjlVcWcV11Mcb5aJyIzjYJDTsnMmF+cz/zifC5dWpks7+kb4MWDnWwPWyZb97Xz2PMH+L9PDY6QrysrYHlVMSuqS1heFYRKVUm+ruwSmcYUHHLacrOzOK+qmPOqiuGCwfIDHV1sbWln6752trS0s62lnUe3tiZvClk6JycIkapiVtQUs7yqhLMrNJBRZLpQcMikq4znU7l0aOvkWHcf2/cHrZKtLW1sbWnn24/vobsvuNVKbnYWS+fHk62SFdXFLKsq1mXCMmtddtll3HbbbfzhH/5hsuxLX/oSzz//PF/5yldOWv/SSy/ljjvuSPudcUHBIWdIYV42Fy6cy4UL5ybL+vqDkfGJlsnWlnYe3bqf/9M42BFfXz4n2WcSBEoJlXHdql5mvrVr17Ju3bohwbFu3Tq++MUvZrBWAQWHZEx2LIvF8+Msnh9nzauCWye4O63t3WzdF7RKtoTTTzbtT25XXpjL8upiVtaUsLK6hJU1xZxVNkdhIjPKDTfcwCc+8Ql6enrIzc1l9+7dtLS08P3vf58PfvCDnDhxghtuuIFPf/rTZ7xuCg6ZUsyMBSX5LCjJ5/Jlg5cJd3T1Bqe6WtrZ3NzGlpZ2vvrLXcmruuL52SyvCsOkppiV1SWcXVGk+3XJ5Hj4Nti/aXL3uWAVvPnzoy4uKyvjoosu4uGHH2bNmjWsW7eOt771rXz84x+nrKyM/v5+rrjiCjZu3Mjq1asnt26nkNbgMLOrgC8DMeBr7j7ifyUzux54AHiNuzea2UXAPYnFwO3u/mCUfcrMEs/P4TX1ZbymfnAQY3dfPzv2d7KlpY3NLW1sbm7nOyn9Jvk5Qed9olWyorqEJfPjeoCWTBuJ01WJ4Pj617/O/fffzz333ENfXx/79u1j69atMyc4zCwG3A1cCTQBT5rZenffOmy9OHAr8LuU4s1Ag7v3mVkV8JyZ/Qjw8exTZoe87BiraktYVVuSLOvrH+DFg8eCMGluZ3NLGw8+08y3H98DBHcTXjI/PhgmNSWct6BYD8+SsY3RMkinNWvW8IEPfICnn36a48ePU1ZWxh133MGTTz7J3Llzufnmm+nq6jr1jiZZOlscFwE73X0XgJmtA9YAw7/kPwt8AfhIosDdj6cszycIjCj7lFkqOzZ4R+E/fXVQNjDg7DlyPBkmW1rahnTCZxmcU1HEypoSVoR9J8s1eFGmgKKiIi677DLe+c53snbtWtrb2yksLKSkpITW1lYefvjhUZ/DkU7pDI4aYG/KfBPwe6krmNmrgTp3f8jMPjJs2e8B3wAWAm8PWx+n3GfK9u8G3g1w1llnTfBQZDrLygqeWbJoXiHXrK4Ggk74lrYutjS3sbmlnS3Nbfz2xUM8+ExzcruF5XNYWVPCqnBaWV2i+3TJGbd27Vr+5E/+hHXr1rFs2TIuuOACli1bRl1dHZdccklG6pSxznEzywLuBG4eabm7/w5YYWbnAd80s4ej7N/d7yHsJ2loaJj5946XSMyMmtICakoLeNOKBcnygx3dYcskaJ08+/JRHkp5zslZZXOCEEmESU0xpXNyM3EIMktcd911pD7+YrSHNm3YsOHMVIj0BkczUJcyXxuWJcSBlcCG8DLKBcB6M7vW3ZMPz3D3bWbWGa57qn2KTEhFPI9Ll1YOGbx45FgPm5vb2NQcBMpzTUd5aNNgmNSVFQwNk+oS5hYqTGTmSmdwPAksNrNFBF/uNwJ/nljo7m3AvMS8mW0APhxeVbUI2BuenloILAN2A0fH2qdIOpQV5vLGJRW8cUlFsuyVYz1sbhkMk03NbUPGmtTOHQyTRKCUKUxkhkhbcIRf+rcAjxBcOvsNd99iZp8BGt19/Ribvx64zcx6gQHgb939EMBI+0zXMYiMZm5hLm9YXMEbFg+GydHjPWxubh8SJg9vHgyTmtICVtYUD2mdlBflZaL6Mk7uPisGlkZ9EqweHSuSRm3He9kStkwSgbL78OBFg9Ul+ayqLWF1balaJlPMSy+9RDwep7y8fEaHh7tz+PBhOjo6WLRo0ZBloz06VsEhcoa1nehNdsBvam5nU9PRIWGSOM21qraE1TWlrKrR1VyZ0NvbS1NTU0bGSZxp+fn51NbWkpMz9O9MwaHgkCms7UQvW8JWycbmNjY1tfHykcEwOatsTjDYsaaE1TUlrKgpoaRAYSLpNVpw6F5VIlNASUEOrzt3Hq87N3m9yJA+k03NR3lu79BLg+vL57CqtpTVyU74YuIatChngIJDZIoqnZPL6xfP4/WLB8PklWM9yf6STU1tPL3nFX70XEty+dnzCpMtk1Vhy0TPNJHJpr8okWlk7giXBh/u7E4GyabmNp546Qg/fDYIEwtvp7I60WdSW8LyqhLdm0smRH0cIjPQwY5uNje3sbEpOM21qbmN1vZuILg315L58aC/pLaEVbWlLFsQJz9HYSJDqXNcwSGzXGt7F5ua2tjYdDTZAX/4WA8Q3DV46YI4q2pKgzCpKWHpgrieAz/LKTgUHCJDJG70uKnpaNgyCVoobSd6geA58OdVFQ85zXVuRRHZCpNZQ8Gh4BA5JXdn75ETbGwOwmRj01E2N7fT2d0HBA/HWlFdkjzNtbq2lLPnFZKlJy3OSAoOBYfIaRkYcF46fCw8zRX0mWxubudEbz8AhbkxVqb0l6yuKWFhuZ4BPxMoOBQcIpOmf8B58WBnECRNR3muqY2t+9rpCR/bW5yfzeraUlbVlnB+GCjVJfkKk2lGwaHgEEmr3v4BdrR2hKe4gpbJ9n0d9A0E3zHzinLDW6kErZLVdSVUxvMzXGsZi0aOi0ha5cSC/o8V1SWsvSgo6+rtZ/v+jmQH/MamNn6x4wXCLGFBcf6QVsnqGj3LZDpQcIhI2uTnxHhVXSmvqitNlh3v6WNrSzvPhae5Nja38dOtrcnldWUFwc0dwyu5VtaU6PnvU4yCQ0TOqDm52TTUl9FQX5Ysa+/qDe4WHLZKNjYPfcpi4lYqq2uDcSYrqouZk6uvr0zRf3kRybji/Bxed848XnfO0PtyBQMVg9NcqbdSyTJYXBkPLgmuC05xLauKk5et0e9ngjrHRWTaONDeFbZIwhHwTW0cSRn9vmxBcTi+JGidLK7UgMWJ0FVVCg6RGcfdaT56ItnxvrHpKJua2ugYYcDi+XUlrKrRgMUoFBwKDpFZYWDA2X34GJua23hu78kDFuN52ckBi4k+k9q5BRpjMgJdjisis0JWlnF2RRFnVxSx5lU1APT1D7AzHLCYaJXc+5vd9PQHAxbnzslhVW1pcFlwTQnn15Uyv1hjTEajFoeIzErdff3s2N/Jc2GQPNd0lBcOdNIfDjKpjOclWySJ1knZLBtjohaHiEiKvOxY8LTE2pJk2YmefrbuaxvSZ/Lz7a0kfl/Xzi0YPMVVU8LK2tk5xkTBISISKsiNceHCMi5cODjGpKOrN3z2+9Fw0GIbP9m0P7l8No4xmdlHJyIyQfH8HF57TjmvPac8WZZ49vvGMcaYpN5K5bwZNsZEfRwiIpPgQHtXcCVX0+CgxeFPWEyc4lpVW8KS+VP/CYu6HFfBISJnUOoTFhOnuDY2HaW9KxhjkpedxfLq4AmLidNcZ1cUEZtCY0wUHAoOEckwd2fP4ePJK7k2NrexubmN4z2DD8VaUVOSbJWcX1ua0Ydi6aoqEZEMMzPq5xVSP68wOcakf8DZlTLGZGNzG99+fA/dKQ/FWpVyJdeq2hJqSjM7YFEtDhGRKaa3f4AXWjuTQbKpqY3t+9vp7Q++r8sLc4MwCR+MdX5tCZVpGLCoFoeIyDSREwv6P5ZXF3NjWNbV28/z+zuCGzzuPcqm5jZ+ueNg8qFY84vzWFUTjn5P84BFBYeIyDSQnxPj/LpSzq8rhYsXAoMDFoN7cp08YLGmtIAfv/f1k/5URQWHiMg0daoBizsPdFI6Z/JHtis4RERmkJEGLE62tI4+MbOrzOx5M9tpZreNsd71ZuZm1hDOX2lmT5nZpvD18pR1N4T7fDacKtN5DCIiMlTaWhxmFgPuBq4EmoAnzWy9u28dtl4cuBX4XUrxIeCP3b3FzFYCjwA1Kcvf5u66TEpEJAPS2eK4CNjp7rvcvQdYB6wZYb3PAl8AuhIF7v6Mu7eEs1uAAjPLS2NdRURknNIZHDXA3pT5Joa2GjCzVwN17v7QGPu5Hnja3btTyu4NT1N90kYZBWNm7zazRjNrPHjw4GkegoiIDJexO2yZWRZwJ/ChMdZZQdAa+euU4re5+yrgDeH09pG2dfd73L3B3RsqKiomr+IiIrNcOoOjGahLma8NyxLiwEpgg5ntBi4G1qd0kNcCDwLvcPcXExu5e3P42gF8j+CUmIiInCHpDI4ngcVmtsjMcoEbgfWJhe7e5u7z3L3e3euBx4Fr3b3RzEqBh4Db3P03iW3MLNvM5oXvc4BrgM1pPAYRERkmbcHh7n3ALQRXRG0D7nf3LWb2GTO79hSb3wKcC/z3YZfd5gGPmNlG4FmCFsxX03UMIiJyMt3kUERERjTaTQ6n9uOnRERkylFwiIhIJAoOERGJRMEhIiKRKDhERCQSBYeIiESi4BARkUgUHCIiEomCQ0REIlFwiIhIJAoOERGJRMEhIiKRKDhERCQSBYeIiESi4BARkUgUHCIiEomCQ0REIlFwiIhIJAoOERGJRMEhIiKRKDhERCSScQWHmRWaWVb4fomZXWtmOemtmoiITEXjbXH8Esg3sxrgUeDtwH3pqpSIiExd4w0Oc/fjwJ8C/8vd3wKsSF+1RERkqhp3cJjZa4G3AQ+FZbH0VElERKay8QbH+4GPAQ+6+xYzOxt4LG21EhGRKSt7PCu5+y+AXwCEneSH3P196ayYiIhMTeO9qup7ZlZsZoXAZmCrmX0kvVUTEZGpaLynqpa7eztwHfAwsIjgyioREZllxhscOeG4jeuA9e7eC3jaaiUiIlPWeIPjX4HdQCHwSzNbCLSnq1IiIjJ1jbdz/C7grpSiPWZ2WXqqJCIiU9l4O8dLzOxOM2sMp38kaH2IiMgsM95TVd8AOoC3hlM7cG+6KiUiIlPXeIPjHHf/lLvvCqdPA2efaiMzu8rMnjeznWZ22xjrXW9mbmYN4fyVZvaUmW0KXy9PWffCsHynmd1lZjbOYxARkUkw3uA4YWavT8yY2SXAibE2MLMYcDfwZmA5sNbMlo+wXhy4FfhdSvEh4I/dfRVwE/DtlGVfAd4FLA6nq8Z5DCIiMgnGGxx/A9xtZrvNbDfwL8Bfn2Kbi4CdYQulB1gHrBlhvc8CXwC6EgXu/oy7t4SzW4ACM8szsyqg2N0fd3cHvkVwibCIiJwh4woOd3/O3c8HVgOr3f0C4PJTbFYD7E2ZbwrLkszs1UCduz/E6K4Hnnb37nD7prH2mbLvdyc68w8ePHiKqoqIyHhFegKgu7eHI8gBPjiRDw7veXUn8KEx1llB0Bo5VevmJO5+j7s3uHtDRUXF6VdURESGmMijY0/VKd0M1KXM14ZlCXFgJbAhPP11MbA+pYO8FngQeIe7v5iyz9ox9ikiImk2keA41S1HngQWm9kiM8sFbgTWJzd2b3P3ee5e7+71wOPAte7eaGalBM/9uM3df5OyzT6g3cwuDq+megfwwwkcg4iIRDRmcJhZh5m1jzB1ANVjbevufcAtwCPANuD+8FkenzGza09Rr1uAc4H/bmbPhlNluOxvga8BO4EXCW66KCIiZ4gFFyfNbA0NDd7Y2JjpaoiITCtm9pS7Nwwvn8ipKhERmYUUHCIiEomCQ0REIlFwiIhIJAoOERGJRMEhIiKRKDhERCQSBYeIiESi4BARkUgUHCIiEomCQ0REIlFwiIhIJAoOERGJRMEhIiKRKDhERCQSBYeIiESi4BARkUgUHCIiEomCQ0REIlFwiIhIJAoOERGJRMEhIiKRKDhERCQSBYeIiESi4BARkUgUHCIiEomCQ0REIlFwiIhIJAoOERGJRMEhIiKRKDhERCQSBYeIiESi4BARkUgUHCIiEklag8PMrjKz581sp5ndNsZ615uZm1lDOF9uZo+ZWaeZ/cuwdTeE+3w2nCrTeQwiIjJUdrp2bGYx4G7gSqAJeNLM1rv71mHrxYFbgd+lFHcBnwRWhtNwb3P3xrRUXERExpTOFsdFwE533+XuPcA6YM0I630W+AJBWADg7sfc/depZSIiMjWkMzhqgL0p801hWZKZvRqoc/eHIu773vA01SfNzEZawczebWaNZtZ48ODBiLsXEZHRZKxz3MyygDuBD0Xc9G3uvgp4Qzi9faSV3P0ed29w94aKioqJVVZERJLSGRzNQF3KfG1YlhAn6L/YYGa7gYuB9YkO8tG4e3P42gF8j+CUmIiInCHpDI4ngcVmtsjMcoEbgfWJhe7e5u7z3L3e3euBx4Frx+r0NrNsM5sXvs8BrgE2p/EYRERkmLRdVeXufWZ2C/AIEAO+4e5bzOwzQKO7rx9r+7AVUgzkmtl1wJuAPcAjYWjEgJ8BX03XMYiIyMnM3TNdh7RraGjwxkZdvSsiEoWZPeXuJ3UfaOS4iIhEouAQEZFIFBwiIhKJgkNERCJRcIiISCQKDhERiUTBISIikSg4REQkEgWHiIhEouAQEZFIFBwiIhKJgkNERCJRcIiISCQKDhERiUTBISIikSg4REQkEgWHiIhEouAQEZFIFBwiIhKJgkNERCJRcIiISCQKDhERiUTBISIikSg4REQkEgWHiIhEouAQEZFIFBwiIhKJgkNERCJRcIiISCQKDhERiUTBISIikWRnugJT2v03QXc7zK0/ecovyWjVREQyRcExljllcPRlaPl/cOLI0GUFc4MAKV14cqiU1EIs50zXVkTkjEhrcJjZVcCXgRjwNXf//CjrXQ88ALzG3RvNrDwxD9zn7rekrHshcB9QAPwEuNXdPS0HcM0/Db7vaoNX9sAru4dO+zfB9odgoDflgGJBeIzUUplbH4SOWVqqLCKSbmkLDjOLAXcDVwJNwJNmtt7dtw5bLw7cCvwupbgL+CSwMpxSfQV4V7j+T4CrgIfTcQxD5JdA1epgGm6gH9pbhgbK0TBknv8JHDs4dP28Ypib0lIpXQhF8yFeBfH5wfvsvHQfkYjIaUlni+MiYKe77wIws3XAGmDrsPU+C3wB+EiiwN2PAb82s3NTVzSzKqDY3R8P578FXMeZCI6xZMWgtC6YFr3h5OXdnYNBkjodfB52PAr93SdvUzAXihaEQTLS64IgYPKK0ntsIiLDpDM4aoC9KfNNwO+lrmBmrwbq3P0hM/sIp1YT7id1nzUTrWja5RXB/BXBNNzAABw7AB37obN15NfDvwleU0+HJeQWha2VRJiMEjb5pTo9JiKTImOd42aWBdwJ3Jym/b8beDfAWWedlY6PmBxZWYNf+mNxhxOvhIGyHzpah73uh+ang7DpPX7y9rE8mFMetGQK5kJBacr7MabcQgWOiAyRzuBoBupS5mvDsoQ4Qf/FBgu+mBYA683sWndvHGOftWPsM8nd7wHuAWhoaEhP5/mZZBZc5TWnDOYvH309d+juGKH1sj8InhNHg9cju4LX40dGPlWWkJVzinApHTqfXxKETW4R5MwJglFEohsYgL6ucOoO/p32dQ/Oj/g6QtkVnwpOp0+idAbHk8BiM1tE8OV+I/DniYXu3gbMS8yb2Qbgw2OEBu6+z8zazexigs7xdwD/nJ7qT1NmkF8cTPMWj2+b3hNhqIxjam+G1i3B+56OU+87pzA4VZdbGE7xwfd5RUHAJIIm8T5vhLLcoqA8O18tIEkPdxjog/6e8It6+Gs39PUMe01ZftI649jHWCEw0qnpqGJ58Pu3Qe6cie8rRdqCw937zOwW4BGCy3G/4e5bzOwzQKO7rx9rezPbDRQDuWZ2HfCm8Iqsv2XwctyHyXTH+EyQUxBMxdXRtuvrCS5TTgbLkaC1090BPcfCqTOYujsH548fCi4W6DkWlneAD4zvMy0WBEksNwiR7PB11Pm8YIrlDb4/aX6k7fMglh18XlZ28IstKxbOh2XJ98Pns2duuLkH/69Sp4H+8H0/9PcFX77JqT/lfe+w+ZR1+ntH2SYxHy5PrNffE0694dST8tqTsk5KWf/w7XqC/aauM5kSf0fZuaO8hqePE3+DqX+vybJTveaP8DecMp+mFr+lawjEVNLQ0OCNjaM2ZCTT3INfWIlgSQ2Zns6UgOkcDKRksz38ddaf+PXWM/b8ZH85jMpSAicRKlkp77ODecsK1k1uNjxwxrnspOXDlg35su8fGgDJL/5RptTlTJHvi6zs4DRqLDcYbJt8HV6WG6ybeD/iuuF8cn/ZKV/EeaN/6SeXj7BeLGdG/Hgws6fcvWF4uUaOS+aZDbZ6Cuedev2JGBgIf12mBk/iFMKwoBnyi7c/+MJNzHv/YPlAX8qygaHrDfSFX759w/YxMLgsadiX8pAfdWMtG7Z8pGUWC0IqMWXFgv/uybKoy7OGzlsYismwzBk2nz04xbKHzg9ZnnPy+ol1YjlBPdL4S1rGR8Ehs0tWFmTlQ05+pmsiMm0ptkVEJBIFh4iIRKLgEBGRSBQcIiISiYJDREQiUXCIiEgkCg4REYlEwSEiIpHMiluOmNlBYM9pbj4PODSJ1cmkmXIsM+U4QMcyVc2UY5nocSx094rhhbMiOCbCzBpHulfLdDRTjmWmHAfoWKaqmXIs6ToOnaoSEZFIFBwiIhKJguPU7sl0BSbRTDmWmXIcoGOZqmbKsaTlONTHISIikajFISIikSg4REQkEgXHKMzsKjN73sx2mtltma7P6TKzOjN7zMy2mtkWM7s103WaKDOLmdkzZvbjTNdlIsys1MweMLPtZrbNzF6b6TqdDjP7QPi3tdnMvm9m0+YpWWb2DTM7YGabU8rKzOynZvZC+Do3k3Ucr1GO5X+Gf18bzexBMyudjM9ScIzAzGLA3cCbgeXAWjNbntlanbY+4EPuvhy4GPiv0/hYEm4FtmW6EpPgy8C/u/sy4Hym4TGZWQ3wPqDB3VcCMeDGzNYqkvuAq4aV3Qb83N0XAz8P56eD+zj5WH4KrHT31cAO4GOT8UEKjpFdBOx0913u3gOsA9ZkuE6nxd33ufvT4fsOgi+nmszW6vSZWS1wNfC1TNdlIsysBHgj8HUAd+9x96MZrdTpywYKzCwbmAO0ZLg+4+buvwSODCteA3wzfP9N4LozWafTNdKxuPuj7t4Xzj4O1E7GZyk4RlYD7E2Zb2Iaf9kmmFk9cAHwuwxXZSK+BHwUGMhwPSZqEXAQuDc87fY1MyvMdKWicvdm4A7gZWAf0Obuj2a2VhM23933he/3A/MzWZlJ9E7g4cnYkYJjljCzIuAHwPvdvT3T9TkdZnYNcMDdn8p0XSZBNvBq4CvufgFwjOlzSiQpPP+/hiAIq4FCM/uLzNZq8ngwXmHaj1kws/9GcNr6u5OxPwXHyJqBupT52rBsWjKzHILQ+K67/1um6zMBlwDXmtlugtOHl5vZdzJbpdPWBDS5e6L19wBBkEw3fwC85O4H3b0X+DfgdRmu00S1mlkVQPh6IMP1mRAzuxm4BnibT9LAPQXHyJ4EFpvZIjPLJejsW5/hOp0WMzOC8+jb3P3OTNdnItz9Y+5e6+71BP9P/sPdp+WvW3ffD+w1s6Vh0RXA1gxW6XS9DFxsZnPCv7UrmIad/MOsB24K398E/DCDdZkQM7uK4NTute5+fLL2q+AYQdiZdAvwCME/gvvdfUtma3XaLgHeTvDr/Nlw+qNMV0oAeC/wXTPbCLwK+PvMVie6sMX0APA0sIngO2Xa3K7DzL4P/Cew1MyazOyvgM8DV5rZCwQtqs9nso7jNcqx/AsQB34a/tv/35PyWbrliIiIRKEWh4iIRKLgEBGRSBQcIiISiYJDREQiUXCIiEgkCg6RSWBm/SmXOz87mXdUNrP61DueimRadqYrIDJDnHD3V2W6EiJnglocImlkZrvN7ItmtsnMnjCzc8PyejP7j/A5CT83s7PC8vnhcxOeC6fE7TtiZvbV8LkXj5pZQcYOSmY9BYfI5CgYdqrqz1KWtbn7KoJRvF8Ky/4Z+Gb4nITvAneF5XcBv3D38wnuXZW4Y8Fi4G53XwEcBa5P69GIjEEjx0UmgZl1unvRCOW7gcvdfVd4s8n97l5uZoeAKnfvDcv3ufs8MzsI1Lp7d8o+6oGfhg8Wwsz+Dshx98+dgUMTOYlaHCLp56O8j6I75X0/6p+UDFJwiKTfn6W8/mf4/rcMPmL1bcCvwvc/B94DyWerl5ypSoqMl361iEyOAjN7NmX+3909cUnu3PAOuN3A2rDsvQRP//sIwZMA/zIsvxW4J7yzaT9BiOxDZApRH4dIGoV9HA3ufijTdRGZLDpVJSIikajFISIikajFISIikSg4REQkEgWHiIhEouAQEZFIFBwiIhLJ/wdHCi3PdQLQQAAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Defining random seeds to enable reproducibility\n",
    "from numpy.random import seed\n",
    "seed(1)\n",
    "\n",
    "import tensorflow as tf\n",
    "tf.random.set_seed(1)\n",
    " \n",
    "import random\n",
    "random.seed(1)\n",
    "\n",
    "import pickle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.python.client import device_lib\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "\n",
    "print(device_lib.list_local_devices())\n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n",
    "\n",
    "\n",
    "def load_patras_dataset():\n",
    "    \"\"\"\n",
    "    Loads the datasets encoded in .pkl files and returns its decoded form.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    list\n",
    "        A list of n-dimensional arrays representing the subjects samples that will be used to \\\\\n",
    "        train the drunkenness classification model.\n",
    "    list\n",
    "        A list of n-dimensional arrays representing the subjects samples that will be used to \\\\\n",
    "        test the drunkenness classification model.\n",
    "    ndarray\n",
    "        A n-dimensional array representing the training set labels.\n",
    "    ndarray\n",
    "        A n-dimensional array representing the test set labels.\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"Loading Sober-Drunk Face Dataset, from Patras University\")\n",
    "    \n",
    "    # Defining the sample and label sets filenames\n",
    "    sets = [\n",
    "        \"Insert the balanced x_training-set.pkl file path here\",\n",
    "        \"Insert the balanced x_test-set.pkl file path here\",\n",
    "        \"Insert the balanced y_training-set.pkl file path here\",\n",
    "        \"Insert the balanced y_test-set.pkl file path here\"\n",
    "    ]\n",
    " \n",
    "    # Defining an empty list for storing the decoded datasets\n",
    "    loaded_datasets = []\n",
    " \n",
    "    # Iterating over the dataset files\n",
    "    for set_ in sets:\n",
    "        # Opening the .pkl file in read mode\n",
    "        with open(set_, 'rb') as file:\n",
    "            # Appending the decoded dataset to the datasets list\n",
    "            loaded_datasets.append(pickle.load(file))\n",
    "    \n",
    "    # Unpacking the datasets list into individual subsets\n",
    "    x_train, x_test, y_train, y_test = loaded_datasets\n",
    "    \n",
    "    # Converting the label list to the n-dimensional array format\n",
    "    y_train= np.array(y_train)\n",
    "    y_test = np.array(y_test)\n",
    " \n",
    "    # Printing the dataset length\n",
    "    print(\"\\nSamples total: {0}\".format((len(x_train)) + (len(x_test))))\n",
    "    \n",
    "    print(\"\\nDataset splitting: \")\n",
    "    \n",
    "    # Printing the training and test sets length\n",
    "    print(\"\\nTraining set: {0}\".format(len(x_train)))\n",
    "    print(\"Test set: {0}\".format(len(x_test)))\n",
    "    \n",
    "    # Returning the training and test sets, and its respective labels\n",
    "    return x_train, x_test, y_train, y_test\n",
    "\n",
    "\n",
    "def min_max_norm(dataset):\n",
    "    \"\"\"\n",
    "    Normalizes the keyframes according to the minimum-maximum norm, such that pixel \\\\\n",
    "    values ranges from 0 to 1.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    dataset : list\n",
    "        A list of n-dimensional arrays representing the subjects keyframes.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    ndarray\n",
    "        A n-dimensional array representing keyframes with pixel values ranging from \\\\\n",
    "        0 to 1.\n",
    "    \"\"\"\n",
    "\n",
    "    # Converting the dataset type from list to n-dimensional array\n",
    "    dataset = np.asarray(dataset, dtype=\"int16\")\n",
    "\n",
    "    # Finding the keyframes minimum and maximum values\n",
    "    x_min = dataset.min(axis=(1, 2), keepdims=True)\n",
    "    x_max = dataset.max(axis=(1, 2), keepdims=True)\n",
    "\n",
    "    # Applying the minimum-maximum norm to each keyframe\n",
    "    norm_dataset = (dataset - x_min) / (x_max - x_min)\n",
    "\n",
    "    # Printing the minimum and maximum values from a given sample for sanity check\n",
    "    print(\"\\nMinMax normalization\")\n",
    "    print(\"dataset shape: \", norm_dataset.shape)\n",
    "    print(\"min: \", norm_dataset[0].min())\n",
    "    print(\"max: \", norm_dataset[0].max())\n",
    "\n",
    "    # Returning the normalized dataset\n",
    "    return norm_dataset\n",
    "\n",
    "\n",
    "def visualize_model_history(hist):\n",
    "    \"\"\"\n",
    "    Displays the training process loss and accuracy history from a given fold of the \\\\\n",
    "    stratified cross-validation procedure.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    hist : dictionary\n",
    "        A dictionary conataining loss and accuracy values lists from the training and \\\\\n",
    "        validation sets.\n",
    "    \"\"\"\n",
    "\n",
    "    # Displaying the training and validation loss history\n",
    "    plt.figure()\n",
    "    plt.plot(hist.history['loss'])\n",
    "    plt.plot(hist.history['val_loss'])\n",
    "    plt.title('Model loss')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train', 'Val'], loc='upper right')\n",
    "    \n",
    "    # Displaying the training and validation accuracy history\n",
    "    plt.figure()\n",
    "    plt.plot(hist.history['accuracy'])\n",
    "    plt.plot(hist.history['val_accuracy'])\n",
    "    plt.title('Model accuracy')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train', 'Val'], loc='lower right')\n",
    "    \n",
    "    # Showing the training process loss and accuracy history\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def visualize_model_history_cv(training_loss, training_accuracy, validation_loss, validation_accuracy):\n",
    "    \"\"\"\n",
    "    Displays the training process loss and accuracy history throughout the \\\\\n",
    "    stratified k-fold cross-validation procedure.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    training_loss : list\n",
    "        A list conataining the loss values from the training set throught the \\\\\n",
    "        stratified k-fold cross-validation procedure.\n",
    "    training_accuracy : list\n",
    "        A list conataining the accuracy values from the training set throught the \\\\\n",
    "        stratified k-fold cross-validation procedure.\n",
    "    validation_loss : list\n",
    "        A list conataining the loss values from the validation set throught the \\\\\n",
    "        stratified k-fold cross-validation procedure.\n",
    "    validation_accuracy : list\n",
    "        A list conataining the accuracy values from the validation set throught the \\\\\n",
    "        stratified k-fold cross-validation procedure.\n",
    "    \"\"\"\n",
    "\n",
    "    # Displaying and saving the training and validation loss history\n",
    "    plt.figure()\n",
    "    plt.plot(training_loss)\n",
    "    plt.plot(validation_loss)\n",
    "    plt.title('Model loss (cross-validation history)')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train', 'Val'], loc='upper right')\n",
    "    plt.savefig(\"ft_adam_learning-curve_conv-block_4-5_bs30.pdf\", dpi=600, bbox_inches='tight', pad_inches=0)\n",
    "    \n",
    "    # Displaying the training and validation accuracy history\n",
    "    plt.figure()\n",
    "    plt.plot(training_accuracy)\n",
    "    plt.plot(validation_accuracy)\n",
    "    plt.title('Model accuracy (cross-validation history)')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train', 'Val'], loc='upper right')\n",
    "    \n",
    "    # Showing the training process loss and accuracy history\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "def fine_tunning():\n",
    "    \"\"\"\n",
    "    Fine-tunes the base drunkenness classification model deepest convolutional \\\\ \n",
    "    layers.\n",
    "\n",
    "    This function loads the previously trained drunkenness classification model, \\\\\n",
    "    unfreezes the deepestes convolutional layers weights and retrains the model \\\\ \n",
    "    in order to induce such layers to extract high-level drunkenness-related \\\\ \n",
    "    features.\n",
    "    \"\"\"\n",
    "\n",
    "    # Loading the training and test datasets\n",
    "    x_train, x_test, y_train, y_test = load_patras_dataset()\n",
    "\n",
    "    # Applying the min-max normalization\n",
    "    x_train = min_max_norm(x_train)\n",
    "    x_test = min_max_norm(x_test)\n",
    "    \n",
    "    # Reshaping datsets to the tensor format (channel last)\n",
    "    x_train = x_train.reshape(x_train.shape[0], x_train.shape[1], x_train.shape[2], 3)\n",
    "    x_test = x_test.reshape(x_test.shape[0], x_test.shape[1], x_test.shape[2], 3)\n",
    "\n",
    "\n",
    "    print(\"\\n Loading pre-trained model\")\n",
    "\n",
    "    # Loading the pre-trained base drunkenness classification model\n",
    "    model = models.load_model('sober-drunk_vgg16-tl-model_fold_3-205e.h5')\n",
    "\n",
    "    # Printing the base model summary\n",
    "    model.summary()\n",
    "    \n",
    "    # Iterating over the layers from convolutional blocks 4 and 5\n",
    "    for layer in model.layers[11:]:\n",
    "        # Unfreezing the layers weights \n",
    "        layer.trainable = True\n",
    "    \n",
    "    # Iterating over the base model layers\n",
    "    for layer in model.layers:\n",
    "        # Printing the layers 'trainable' parameter for sanity check  \n",
    "        print(\"{}: {}\".format(layer.name, layer.trainable))\n",
    " \n",
    "    # Defining the optmization function\n",
    "    adam = optimizers.Adam(learning_rate=1e-7, amsgrad=False)\n",
    "    \n",
    "    # Defining the early stopping callback\n",
    "    callback = keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=0, patience=5, restore_best_weights=True, verbose=1)\n",
    "    \n",
    "    print(\"\\nRe-compiling model...\")\n",
    "\n",
    "    # Compiling the model\n",
    "    model.compile(loss=keras.losses.BinaryCrossentropy(from_logits=False),\n",
    "                optimizer=adam,\n",
    "                metrics=['accuracy'])\n",
    "    \n",
    "    # Printing the model summary\n",
    "    model.summary()\n",
    "    \n",
    "\n",
    "    # Defining the stratified cross-validation folds\n",
    "    folds = list(StratifiedKFold(n_splits=5, shuffle=False, random_state=None).split(x_train, y_train))\n",
    " \n",
    "    # Instantiating empty lists for storing the model training and validation loss history\n",
    "    cv_training_acc = []\n",
    "    cv_training_loss = []\n",
    "    \n",
    "    # Instantiating empty lists for storing the model training and validation accuracy history\n",
    "    cv_val_acc = []\n",
    "    cv_val_loss = []\n",
    "    \n",
    "    # Instantiating an empty list for storing the model classification accuracies on the test set samples\n",
    "    fold_acc = []\n",
    "    \n",
    "    print(\"\\nFitting model...\")\n",
    "\n",
    "    # Iterating over the stratified cross-validation folds\n",
    "    for j, (train_idx, val_idx) in enumerate(folds):\n",
    "        print('\\nFold ',j)\n",
    "        # Defining the training and validation sets\n",
    "        X_train_cv, y_train_cv = x_train[train_idx], y_train[train_idx]\n",
    "        X_valid_cv, y_valid_cv = x_train[val_idx], y_train[val_idx]\n",
    "        \n",
    "        print(\"\\nTraining with {0} samples and validating with {1} samples\\n\".format(len(X_train_cv), len(X_valid_cv)))\n",
    "\n",
    "        # Fitting the model\n",
    "        history = model.fit(x=X_train_cv, y=y_train_cv, \n",
    "                            validation_data=(X_valid_cv, y_valid_cv),\n",
    "                            shuffle=False,\n",
    "                            batch_size=30,\n",
    "                            callbacks=[callback],\n",
    "                            epochs=205,\n",
    "                            verbose=1)\n",
    "\n",
    "        # Updating the training loss and accuracy history lists\n",
    "        cv_training_acc += history.history['accuracy']\n",
    "        cv_training_loss += history.history['loss']\n",
    "\n",
    "        # Updating the validation loss and accuracy history lists\n",
    "        cv_val_acc += history.history['val_accuracy']\n",
    "        cv_val_loss += history.history['val_loss']\n",
    "\n",
    "        # Evaluating the model on unseen data\n",
    "        test_loss, test_acc = model.evaluate(x_test, y_test, verbose=1)\n",
    "\n",
    "        # Appending the model classification accuracies to the test set accuracies list\n",
    "        fold_acc.append(test_acc)\n",
    "\n",
    "        # Printing the model classification accuracy on unseen data\n",
    "        print('\\nFold ',j)\n",
    "        print(\"\\nTest accuracy: \", test_acc)\n",
    "        print(\"Test loss: \", test_loss)\n",
    "\n",
    "        # Saving the model obtained in the stratified cross-validation j-th fold\n",
    "        model.save('vgg16_sober-drunk_ft-model_bs30_cb-4-5_fold-{0}.h5'.format(j))\n",
    "        \n",
    "        # Uncomment to break the loop\n",
    "        #if j == 2:\n",
    "        #    break\n",
    "    \n",
    "    # Printing the model classification accuracy in each fold of the stratified \n",
    "    # cross-validation\n",
    "    print(\"\\nK-Fold accuracy: \", fold_acc)\n",
    "\n",
    "    # Printing the model average accuracy along the stratified k-fold cross-validation \n",
    "    # procedure\n",
    "    print(\"\\nAverage accuracy: \", np.mean(fold_acc))\n",
    "\n",
    "    # Printing the standard deviation of accuracies obtained throughout the \n",
    "    # stratified k-fold cross-validation procedure\n",
    "    print(\"K-Fold Standard deviation: \", np.std(fold_acc))\n",
    "    \n",
    "\n",
    "    print(\"\\nClassification report: \")\n",
    "\n",
    "    # Obtaining the test samples class probabilities\n",
    "    y_prob = model.predict(x_test)\n",
    "\n",
    "    # Obtaining the binary label from the model output probabilities\n",
    "    y_hat = (y_prob > 0.5).astype(int)\n",
    "    \n",
    "    # Printing the classification performance report\n",
    "    report = classification_report(y_test, y_hat, target_names=['sober', 'drunk'])\n",
    "    print(report)\n",
    "    \n",
    "    print(\"\\nConfusion Matrix: \")\n",
    "\n",
    "    # Printing the confusion matrix\n",
    "    matrix = confusion_matrix(y_test, y_hat)\n",
    "    print(matrix)\n",
    " \n",
    "    tn, fp, fn, tp = matrix.ravel()\n",
    "    print(\"\\nTrue Negatives: \", tn)\n",
    "    print(\"False Positives: \", fp)\n",
    "    print(\"False Negatives: \", fn)\n",
    "    print(\"True Positives: \", tp)\n",
    "\n",
    "    # Displaying the training process history\n",
    "    visualize_model_history_cv(cv_training_loss, cv_training_acc, cv_val_loss, cv_val_acc)\n",
    "    visualize_model_history(history)\n",
    "\n",
    "\n",
    "# Running the base model fine-tuning\n",
    "fine_tunning()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.3 ('virtual-env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 76.356929,
   "end_time": "2022-05-30T20:09:56.063250",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-05-30T20:08:39.706321",
   "version": "2.3.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "91dd42dc31c8286e87f4f857c1cf087015eed96189f5f719a42d322017809b0b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
