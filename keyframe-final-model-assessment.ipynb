{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "644b0b95",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2022-08-08T15:10:32.321696Z",
     "iopub.status.busy": "2022-08-08T15:10:32.321173Z",
     "iopub.status.idle": "2022-08-08T15:10:56.502677Z",
     "shell.execute_reply": "2022-08-08T15:10:56.500584Z"
    },
    "papermill": {
     "duration": 24.188704,
     "end_time": "2022-08-08T15:10:56.505848",
     "exception": false,
     "start_time": "2022-08-08T15:10:32.317144",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-08 15:10:38.564445: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-08-08 15:10:38.628326: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-08 15:10:38.792924: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-08 15:10:38.793784: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-08 15:10:40.961845: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-08 15:10:40.962717: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-08 15:10:40.963431: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-08 15:10:40.964097: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /device:GPU:0 with 15403 MB memory:  -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n",
      "2022-08-08 15:10:40.969017: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-08 15:10:40.969781: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-08 15:10:40.970429: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-08 15:10:41.070776: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-08 15:10:41.071688: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-08 15:10:41.072370: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-08 15:10:41.073102: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-08 15:10:41.073772: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-08 15:10:41.074361: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 15403 MB memory:  -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 17185065197945081162\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 16152002560\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 2271303286835939952\n",
      "physical_device_desc: \"device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\"\n",
      "]\n",
      "Num GPUs Available:  1\n",
      "\n",
      "\n",
      "Classification performance assessment:\n",
      "\n",
      "Loading Sober-Drunk Face Dataset, from Patras University\n",
      "\n",
      "Test set samples: 20\n",
      "\n",
      "MinMax normalization\n",
      "dataset shape:  (20, 128, 160, 3)\n",
      "min:  0.0\n",
      "max:  1.0\n",
      "\n",
      "Loading the final drunkenness classification model\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "block1_conv1 (Conv2D)        (None, 128, 160, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 128, 160, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 64, 80, 64)        0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 64, 80, 128)       73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 64, 80, 128)       147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 32, 40, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 32, 40, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 32, 40, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 32, 40, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 16, 20, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 16, 20, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 16, 20, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 16, 20, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 8, 10, 512)        0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 8, 10, 512)        2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 8, 10, 512)        2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 8, 10, 512)        2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 4, 5, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 10240)             0         \n",
      "_________________________________________________________________\n",
      "dense_layer_1 (Dense)        (None, 10)                102410    \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 14,817,109\n",
      "Trainable params: 13,081,621\n",
      "Non-trainable params: 1,735,488\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-08 15:10:44.050406: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n",
      "2022-08-08 15:10:45.101403: I tensorflow/stream_executor/cuda/cuda_dnn.cc:369] Loaded cuDNN version 8005\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification performance on the keyframe dataset: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       sober       1.00      0.80      0.89         5\n",
      "       drunk       0.94      1.00      0.97        15\n",
      "\n",
      "    accuracy                           0.95        20\n",
      "   macro avg       0.97      0.90      0.93        20\n",
      "weighted avg       0.95      0.95      0.95        20\n",
      "\n",
      "\n",
      "AUC ROC: \n",
      "0.8800000000000001\n",
      "\n",
      "Confusion Matrix: \n",
      "[[ 4  1]\n",
      " [ 0 15]]\n",
      "\n",
      "True Negatives:  4\n",
      "False Positives:  1\n",
      "False Negatives:  0\n",
      "True Positives:  15\n",
      "\n",
      "subject 37 true classes: \t[0 1 1 1]\n",
      "subject 37 predicted classes: \t[0 1 1 1]\n",
      "\n",
      "subject 38 true classes: \t[0 1 1 1]\n",
      "subject 38 predicted classes: \t[0 1 1 1]\n",
      "\n",
      "subject 39 true classes: \t[0 1 1 1]\n",
      "subject 39 predicted classes: \t[0 1 1 1]\n",
      "\n",
      "subject 40 true classes: \t[0 1 1 1]\n",
      "subject 40 predicted classes: \t[0 1 1 1]\n",
      "\n",
      "subject 41 true classes: \t[0 1 1 1]\n",
      "subject 41 predicted classes: \t[1 1 1 1]\n",
      "\n",
      "==========================================================================================\n",
      "\n",
      "Generalization assessment:\n",
      "\n",
      "Loading Sober-Drunk Face Dataset, from Patras University\n",
      "\n",
      "Test set samples: 1000\n",
      "\n",
      "MinMax normalization\n",
      "dataset shape:  (1000, 128, 160, 3)\n",
      "min:  0.0\n",
      "max:  1.0\n",
      "\n",
      "Classification performance on the multiframe dataset: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       sober       0.95      0.49      0.65       250\n",
      "       drunk       0.85      0.99      0.92       750\n",
      "\n",
      "    accuracy                           0.87      1000\n",
      "   macro avg       0.90      0.74      0.78      1000\n",
      "weighted avg       0.88      0.87      0.85      1000\n",
      "\n",
      "\n",
      "AUC ROC: \n",
      "0.87952\n",
      "\n",
      "Confusion Matrix: \n",
      "[[123 127]\n",
      " [  7 743]]\n",
      "\n",
      "True Negatives:  123\n",
      "False Positives:  127\n",
      "False Negatives:  7\n",
      "True Positives:  743\n",
      "\n",
      "subject 37 true classes: \n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "\n",
      "subject 37 predicted classes: \n",
      "[0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 0 1 0 0 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "\n",
      "subject 38 true classes: \n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "\n",
      "subject 38 predicted classes: \n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 0 0 1\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "\n",
      "subject 39 true classes: \n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "\n",
      "subject 39 predicted classes: \n",
      "[0 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1\n",
      " 1 1 1 1 1 1 1 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "\n",
      "subject 40 true classes: \n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "\n",
      "subject 40 predicted classes: \n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "\n",
      "subject 41 true classes: \n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "\n",
      "subject 41 predicted classes: \n",
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "# Defining random seeds to enable reproducibility\n",
    "from numpy.random import seed\n",
    "seed(1)\n",
    "\n",
    "import tensorflow as tf\n",
    "tf.random.set_seed(1)\n",
    " \n",
    "import random\n",
    "random.seed(1)\n",
    "\n",
    "import pickle\n",
    "import numpy as np\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.python.client import device_lib\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    " \n",
    "print(device_lib.list_local_devices())\n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n",
    "\n",
    "\n",
    "def load_patras_dataset(variant='keyframe'):\n",
    "    \"\"\"\n",
    "    Loads the datasets encoded in .pkl files and returns its decoded form.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    variant : {'keyframe', 'multiframe'}\n",
    "        A string indicating the dataset version to load.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    list\n",
    "        A list of n-dimensional arrays representing the subjects samples that will be used to \\\\\n",
    "        test the drunkenness classification model.\n",
    "    ndarray\n",
    "        A n-dimensional array representing the test set labels.\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"Loading Sober-Drunk Face Dataset, from Patras University\")\n",
    "    \n",
    "    # Defining the sample and label sets filenames according to the variant parameter\n",
    "    if variant == 'keyframe':\n",
    "        sets = [\n",
    "            \"Insert the keyframe-based unbalanced x_test-set.pkl file path here\",\n",
    "            \"Insert the keyframe-based unbalanced y_test-set.pkl file path here\"\n",
    "        ]\n",
    "    else:\n",
    "        sets = [\n",
    "            \"Insert the multiframe-based unbalanced x_test-set.pkl file path here\",\n",
    "            \"Insert the multiframe-based unbalanced y_test-set.pkl file path here\"\n",
    "        ]\n",
    "    \n",
    "    # Defining an empty list for storing the decoded datasets\n",
    "    loaded_datasets = []\n",
    " \n",
    "    # Iterating over the dataset files\n",
    "    for set_ in sets:\n",
    "        # Opening the .pkl file in read mode\n",
    "        with open(set_, 'rb') as file:\n",
    "            # Appending the decoded dataset to the datasets list\n",
    "            loaded_datasets.append(pickle.load(file))\n",
    "    \n",
    "    # Unpacking the datasets list into individual subsets\n",
    "    x_test, y_test = loaded_datasets\n",
    "\n",
    "    # Converting the label list to the n-dimensional array format\n",
    "    y_test = np.array(y_test)\n",
    " \n",
    "    # Printing the dataset length\n",
    "    print(\"\\nTest set samples: {0}\".format(len(x_test)))\n",
    "    \n",
    "    # Returning the test set samples and its respective labels\n",
    "    return x_test, y_test\n",
    "        \n",
    "\n",
    "def min_max_norm(dataset):\n",
    "    \"\"\"\n",
    "    Normalizes the keyframes according to the minimum-maximum norm, \\\\\n",
    "    such that pixel values ranges from 0 to 1.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    dataset : list\n",
    "        A list of n-dimensional arrays representing the subjects keyframes.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    ndarray\n",
    "        A n-dimensional array representing keyframes with pixel values ranging from 0 to 1.\n",
    "    \"\"\"\n",
    "\n",
    "    # Converting the dataset type from list to n-dimensional array\n",
    "    dataset = np.asarray(dataset, dtype=\"int16\")\n",
    "\n",
    "    # Finding the keyframes minimum and maximum values\n",
    "    x_min = dataset.min(axis=(1, 2), keepdims=True)\n",
    "    x_max = dataset.max(axis=(1, 2), keepdims=True)\n",
    "\n",
    "    # Applying the minimum-maximum norm to each keyframe\n",
    "    norm_dataset = (dataset - x_min) / (x_max - x_min)\n",
    "\n",
    "    # Printing the minimum and maximum values from a given sample for sanity check\n",
    "    print(\"\\nMinMax normalization\")\n",
    "    print(\"dataset shape: \", norm_dataset.shape)\n",
    "    print(\"min: \", norm_dataset[0].min())\n",
    "    print(\"max: \", norm_dataset[0].max())\n",
    "\n",
    "    # Returning the normalized dataset\n",
    "    return norm_dataset\n",
    "\n",
    "\n",
    "def print_classification_report(y_test, y_hat, dataset_variant='keyframe'):\n",
    "    \"\"\"\n",
    "    Prints the final model classification performance assessment and the confusion \\\\\n",
    "    matrix comparing the predicted classes in relation to the real ones.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    y_test : ndarray\n",
    "        A n-dimensional array representing the test set true labels.\n",
    "    y_hat : ndarray\n",
    "        A n-dimensional array representing the test set labels predicted by the final \\\\\n",
    "        model.\n",
    "    dataset_variant : {'keyframe', 'multiframe'}\n",
    "        A string indicating the dataset version in which the classification model will \\\\ \n",
    "        be evaluated.\n",
    "    \"\"\"\n",
    "\n",
    "    # Printing the classification performance report\n",
    "    report = classification_report(y_test, y_hat, target_names=['sober', 'drunk'])\n",
    "    print(report)\n",
    " \n",
    "    print(\"\\nConfusion Matrix: \")\n",
    "\n",
    "    # Printing the confusion matrix\n",
    "    matrix = confusion_matrix(y_test, y_hat)\n",
    "    print(matrix)\n",
    " \n",
    "    tn, fp, fn, tp = matrix.ravel()\n",
    "    print(\"\\nTrue Negatives: \", tn)\n",
    "    print(\"False Positives: \", fp)\n",
    "    print(\"False Negatives: \", fn)\n",
    "    print(\"True Positives: \", tp)\n",
    "\n",
    "\n",
    "    # Flattening the n-dimensional label arrays\n",
    "    true_classes = y_test.ravel()\n",
    "    predicted_classes = y_hat.ravel()    \n",
    "    \n",
    "    # Printing the true and predicted labels of each subject\n",
    "    if dataset_variant == 'keyframe':\n",
    "        print(\"\\nsubject 37 true classes: \\t{0}\".format(true_classes[0:4]))\n",
    "        print(\"subject 37 predicted classes: \\t{0}\".format(predicted_classes[0:4]))\n",
    "\n",
    "        print(\"\\nsubject 38 true classes: \\t{0}\".format(true_classes[4:8]))\n",
    "        print(\"subject 38 predicted classes: \\t{0}\".format(predicted_classes[4:8]))\n",
    "\n",
    "        print(\"\\nsubject 39 true classes: \\t{0}\".format(true_classes[8:12]))\n",
    "        print(\"subject 39 predicted classes: \\t{0}\".format(predicted_classes[8:12]))\n",
    "\n",
    "        print(\"\\nsubject 40 true classes: \\t{0}\".format(true_classes[12:16]))\n",
    "        print(\"subject 40 predicted classes: \\t{0}\".format(predicted_classes[12:16]))\n",
    "\n",
    "        print(\"\\nsubject 41 true classes: \\t{0}\".format(true_classes[16:20]))\n",
    "        print(\"subject 41 predicted classes: \\t{0}\".format(predicted_classes[16:20]))\n",
    "    else:\n",
    "        print(\"\\nsubject 37 true classes: \\n{0}\".format(true_classes[0:200]))\n",
    "        print(\"\\nsubject 37 predicted classes: \\n{0}\".format(predicted_classes[0:200]))\n",
    "\n",
    "        print(\"\\nsubject 38 true classes: \\n{0}\".format(true_classes[200:400]))\n",
    "        print(\"\\nsubject 38 predicted classes: \\n{0}\".format(predicted_classes[200:400]))\n",
    "\n",
    "        print(\"\\nsubject 39 true classes: \\n{0}\".format(true_classes[400:600]))\n",
    "        print(\"\\nsubject 39 predicted classes: \\n{0}\".format(predicted_classes[400:600]))\n",
    "\n",
    "        print(\"\\nsubject 40 true classes: \\n{0}\".format(true_classes[600:800]))\n",
    "        print(\"\\nsubject 40 predicted classes: \\n{0}\".format(predicted_classes[600:800]))\n",
    "\n",
    "        print(\"\\nsubject 41 true classes: \\n{0}\".format(true_classes[800:1000]))\n",
    "        print(\"\\nsubject 41 predicted classes: \\n{0}\".format(predicted_classes[800:1000]))\n",
    "\n",
    "\n",
    "print(\"\\n\\nClassification performance assessment:\\n\")\n",
    "\n",
    "# Loading the test dataset\n",
    "x_test, y_test = load_patras_dataset()\n",
    "\n",
    "# Applying the min-max normalization\n",
    "x_test = min_max_norm(x_test)\n",
    "\n",
    "# Reshaping datsets to the tensor format (channel last)\n",
    "x_test = x_test.reshape(x_test.shape[0], x_test.shape[1], x_test.shape[2], 3)\n",
    "          \n",
    "print(\"\\nLoading the final drunkenness classification model\")\n",
    "\n",
    "# Loading the final drunkenness classification model\n",
    "model = models.load_model('sober-drunk_final-model_ft_fold-3.h5')\n",
    "\n",
    "# Printing the final model summary\n",
    "model.summary()\n",
    "\n",
    "# Obtaining the test samples class probabilities   \n",
    "y_prob = model.predict(x_test)\n",
    "\n",
    "# Obtaining the binary label from the model output probabilities\n",
    "y_hat = (y_prob > 0.5).astype(int)\n",
    "\n",
    "print(\"\\nClassification performance on the keyframe dataset: \")\n",
    "\n",
    "# Printing the final model classification performance assessment on the keyframe dataset\n",
    "print_classification_report(y_test, y_hat)\n",
    "\n",
    "print(\"\\n==========================================================================================\\n\")\n",
    "\n",
    "print(\"Generalization assessment:\\n\")\n",
    "\n",
    "# Loading the test dataset multiframe version\n",
    "x_test, y_test = load_patras_dataset('multiframe')\n",
    "\n",
    "# Applying the min-max normalization\n",
    "x_test = min_max_norm(x_test)\n",
    "\n",
    "# Reshaping datsets to the tensor format (channel last)\n",
    "x_test = x_test.reshape(x_test.shape[0], x_test.shape[1], x_test.shape[2], 3)\n",
    "\n",
    "# Obtaining the test samples class probabilities   \n",
    "y_prob = model.predict(x_test)\n",
    "\n",
    "# Obtaining the binary label from the model output probabilities\n",
    "y_hat = (y_prob > 0.5).astype(int)\n",
    "\n",
    "print(\"\\nClassification performance on the multiframe dataset: \")\n",
    "\n",
    "# Printing the final model classification performance assessment on the multiframe dataset\n",
    "print_classification_report(y_test, y_hat, 'multiframe')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.3 ('virtual-env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 35.394849,
   "end_time": "2022-08-08T15:10:59.982016",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-08-08T15:10:24.587167",
   "version": "2.3.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "91dd42dc31c8286e87f4f857c1cf087015eed96189f5f719a42d322017809b0b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
